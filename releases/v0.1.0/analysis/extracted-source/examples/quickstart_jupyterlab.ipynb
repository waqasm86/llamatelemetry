{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# llamatelemetry v0.1.0 Quick Start (Kaggle Dual T4)\n", "\n", "This notebook is for **Kaggle notebooks only** (GPU T4 x2).\n", "\n", "- Platform: Kaggle dual Tesla T4\n", "- Models: 1B-5B GGUF (Q4_K_M recommended)\n", "- Distribution: GitHub Releases (no PyPI)\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Step 1: Install llamatelemetry v0.1.0\n", "!pip install -q --no-cache-dir --force-reinstall git+https://github.com/llamatelemetry/llamatelemetry.git@v0.1.0\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Step 2: Verify GPUs\n", "!nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Step 3: Download a small GGUF model\n", "from huggingface_hub import hf_hub_download\n", "\n", "model_path = hf_hub_download(\n", "    repo_id='unsloth/gemma-3-1b-it-GGUF',\n", "    filename='gemma-3-1b-it-Q4_K_M.gguf',\n", "    local_dir='/kaggle/working/models',\n", ")\n", "print(model_path)\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Step 4: Start llama-server on GPU 0 (split-GPU)\n", "from llamatelemetry.server import ServerManager\n", "\n", "server = ServerManager()\n", "server.start_server(\n", "    model_path=model_path,\n", "    gpu_layers=99,\n", "    tensor_split='1.0,0.0',\n", "    flash_attn=1,\n", ")\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Step 5: Run inference\n", "import llamatelemetry\n", "\n", "engine = llamatelemetry.InferenceEngine()\n", "engine.load_model(model_path, auto_start=False)\n", "result = engine.infer('What is AI?', max_tokens=100)\n", "print(result.text)\n"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Step 6: Cleanup\n", "server.stop_server()\n", "print('Server stopped')\n"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}, "kaggle": {"accelerator": "nvidiaTeslaT4", "isGpuEnabled": true, "isInternetEnabled": true, "language": "python", "sourceType": "notebook"}}, "nbformat": 4, "nbformat_minor": 4}