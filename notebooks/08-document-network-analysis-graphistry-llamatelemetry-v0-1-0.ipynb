{"cells": [{"cell_type": "markdown", "id": "header_cell", "metadata": {}, "source": ["# 08: Document Network Analysis with Graphistry\n", "\n", "**llamatelemetry v0.1.0** | Kaggle 2Ã— Tesla T4 (30GB Total VRAM)\n", "\n", "---\n", "\n", "## ğŸ¯ Objective\n", "\n", "This notebook demonstrates **document similarity networks** and **community detection** using llamatelemetry v0.1.0 with graphistry[ai] visualization:\n", "\n", "### Architecture:\n", "```\n", "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n", "â”‚  GPU 0: llama-server (LLM)                             â”‚\n", "â”‚         Generate document summaries & extract topics   â”‚\n", "â”‚         tensor_split=\"1.0,0.0\"                         â”‚\n", "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n", "                          â†“\n", "                  Document Similarity Graph\n", "                          â†“\n", "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n", "â”‚  GPU 1: RAPIDS + Graphistry                            â”‚\n", "â”‚         Community detection + cluster visualization    â”‚\n", "â”‚         CUDA_VISIBLE_DEVICES=\"1\"                       â”‚\n", "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n", "```\n", "\n", "### Workflow:\n", "1. Start llama-server on GPU 0\n", "2. Generate document summaries using LLM\n", "3. Build document similarity network on GPU 1\n", "4. Detect communities with Louvain algorithm (cuGraph)\n", "5. Visualize clusters with Graphistry\n", "6. LLM interprets community themes\n", "\n", "---\n", "\n", "**Previous:** [07-knowledge-graph-extraction](07-knowledge-graph-extraction-graphistry-llamatelemetry-v0-1-0.ipynb)  \n", "**Next:** [09-large-models-kaggle](09-large-models-kaggle-llamatelemetry-v0-1-0.ipynb)"]}, {"cell_type": "markdown", "id": "step0_header", "metadata": {}, "source": ["## Step 0: Add Graphistry Secrets in Kaggle\n", "\n", "Go to **Kaggle â†’ Settings â†’ Add-ons â†’ Secrets** and add:\n", "- `Graphistry_Personal_Key_ID`\n", "- `Graphistry_Personal_Secret_Key`"]}, {"cell_type": "markdown", "id": "step1_header", "metadata": {}, "source": ["## Step 1: Verify Dual GPU Environment"]}, {"cell_type": "markdown", "id": "9fb33926", "metadata": {}, "source": ["Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."]}, {"cell_type": "markdown", "id": "41c5e373", "metadata": {}, "source": ["Verifies dual T4 GPU setup for document network analysis combining LLM text processing with GPU-accelerated network analytics and visualization."]}, {"cell_type": "code", "execution_count": 1, "id": "step1_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:23:30.406107Z", "iopub.status.busy": "2026-01-20T22:23:30.405818Z", "iopub.status.idle": "2026-01-20T22:23:30.444144Z", "shell.execute_reply": "2026-01-20T22:23:30.443515Z", "shell.execute_reply.started": "2026-01-20T22:23:30.406079Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ” SPLIT-GPU ENVIRONMENT CHECK\n", "======================================================================\n", "\n", "ğŸ“Š Detected 2 GPU(s):\n", "   0, Tesla T4, 15360 MiB, 15096 MiB\n", "   1, Tesla T4, 15360 MiB, 15096 MiB\n", "\n", "âœ… Dual T4 ready for split-GPU operation!\n", "   GPU 0 â†’ llama-server (LLM for summaries)\n", "   GPU 1 â†’ RAPIDS/Graphistry (community detection)\n"]}], "source": ["import subprocess\n", "import os\n", "\n", "print(\"=\"*70)\n", "print(\"ğŸ” SPLIT-GPU ENVIRONMENT CHECK\")\n", "print(\"=\"*70)\n", "\n", "result = subprocess.run(\n", "    [\"nvidia-smi\", \"--query-gpu=index,name,memory.total,memory.free\", \"--format=csv,noheader\"],\n", "    capture_output=True, text=True\n", ")\n", "\n", "gpus = result.stdout.strip().split('\\n')\n", "print(f\"\\nğŸ“Š Detected {len(gpus)} GPU(s):\")\n", "for gpu in gpus:\n", "    print(f\"   {gpu}\")\n", "\n", "if len(gpus) >= 2:\n", "    print(\"\\nâœ… Dual T4 ready for split-GPU operation!\")\n", "    print(\"   GPU 0 â†’ llama-server (LLM for summaries)\")\n", "    print(\"   GPU 1 â†’ RAPIDS/Graphistry (community detection)\")\n", "else:\n", "    print(\"\\nâš ï¸ Need 2 GPUs for split operation\")"]}, {"cell_type": "markdown", "id": "step2_header", "metadata": {}, "source": ["## Step 2: Install Dependencies"]}, {"cell_type": "markdown", "id": "d4ef124b", "metadata": {}, "source": ["Installs llamatelemetry for LLM inference, RAPIDS for GPU graph analytics, and Graphistry for visualizing document similarity networks."]}, {"cell_type": "markdown", "id": "b946df2a", "metadata": {}, "source": ["Installs llamatelemetry for LLM inference, RAPIDS cuGraph for GPU graph analytics, and Graphistry for visualizing document similarity networks."]}, {"cell_type": "code", "execution_count": 2, "id": "step2_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:23:40.990635Z", "iopub.status.busy": "2026-01-20T22:23:40.990326Z", "iopub.status.idle": "2026-01-20T22:25:05.422772Z", "shell.execute_reply": "2026-01-20T22:25:05.422026Z", "shell.execute_reply.started": "2026-01-20T22:23:40.990608Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ğŸ“¦ Installing dependencies...\n", "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n", "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n", "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n", "  Building wheel for llamatelemetry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n", "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n", "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n", "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n", "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\n", "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n", "datasets 4.4.2 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n", "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n", "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n", "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n", "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.8/439.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h"]}, {"name": "stderr", "output_type": "stream", "text": ["WARNING:root:llamatelemetry: Library directory not found - shared libraries may not load correctly\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "======================================================================\n", "ğŸ¯ llamatelemetry v0.1.0 First-Time Setup - Kaggle 2Ã— T4 Multi-GPU\n", "======================================================================\n", "\n", "ğŸ® GPU Detected: Tesla T4 (Compute 7.5)\n", "  âœ… Tesla T4 detected - Perfect for llamatelemetry v0.1.0!\n", "ğŸŒ Platform: Kaggle\n", "\n", "ğŸ“¦ Downloading Kaggle 2Ã— T4 binaries (~961 MB)...\n", "    Features: FlashAttention + Tensor Cores + Multi-GPU tensor-split\n", "\n", "â¡ï¸  Attempt 1: HuggingFace (llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz)\n", "ğŸ“¥ Downloading v0.1.0 from HuggingFace Hub...\n", "   Repo: waqasm86/llamatelemetry-binaries\n", "   File: v0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n", "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n", "  warnings.warn(\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "dc135bb488824c28b3db3b3bdf3ab51f", "version_major": 2, "version_minor": 0}, "text/plain": ["v0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.(â€¦):   0%|          | 0.00/1.01G [00:00<?, ?B/s]"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["ğŸ” Verifying SHA256 checksum...\n", "   âœ… Checksum verified\n", "ğŸ“¦ Extracting llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz...\n", "Found 21 files in archive\n", "Extracted 21 files to /root/.cache/llamatelemetry/extract_0.1.0\n", "âœ… Extraction complete!\n", "  Found bin/ and lib/ under /root/.cache/llamatelemetry/extract_0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2\n", "  Copied 13 binaries to /usr/local/lib/python3.12/dist-packages/llamatelemetry/binaries/cuda12\n", "  Copied 0 libraries to /usr/local/lib/python3.12/dist-packages/llamatelemetry/lib\n", "âœ… Binaries installed successfully!\n", "\n", "\n", "âœ… llamatelemetry 0.1.0 installed\n", "âœ… cuDF 25.06.00\n", "âœ… cuGraph 25.06.00\n", "âœ… Graphistry 0.50.4\n", "CPU times: user 46.1 s, sys: 10.5 s, total: 56.5 s\n", "Wall time: 1min 24s\n"]}], "source": ["%%time\n", "print(\"ğŸ“¦ Installing dependencies...\")\n", "\n", "# Install llamatelemetry v0.1.0\n", "!pip install -q --no-cache-dir git+https://github.com/llamatelemetry/llamatelemetry.git@v0.1.0\n", "\n", "# Install cuGraph (matching Kaggle RAPIDS 25.6.0)\n", "!pip install -q --extra-index-url=https://pypi.nvidia.com \"cugraph-cu12==25.6.*\"\n", "\n", "# Install Graphistry\n", "!pip install -q \"graphistry[ai]\"\n", "\n", "# Verify\n", "import llamatelemetry\n", "print(f\"\\nâœ… llamatelemetry {llamatelemetry.__version__} installed\")\n", "\n", "try:\n", "    import cudf, cugraph\n", "    print(f\"âœ… cuDF {cudf.__version__}\")\n", "    print(f\"âœ… cuGraph {cugraph.__version__}\")\n", "except ImportError as e:\n", "    print(f\"âš ï¸ RAPIDS: {e}\")\n", "\n", "try:\n", "    import graphistry\n", "    print(f\"âœ… Graphistry {graphistry.__version__}\")\n", "except ImportError as e:\n", "    print(f\"âš ï¸ Graphistry: {e}\")"]}, {"cell_type": "markdown", "id": "ceedeb1e", "metadata": {}, "source": ["Configures Graphistry API authentication using Kaggle secrets for cloud-based document network visualization rendering."]}, {"cell_type": "code", "execution_count": 3, "id": "365e61a3-e832-4e9c-b5b8-55f842d2f4ac", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:25:12.515662Z", "iopub.status.busy": "2026-01-20T22:25:12.514497Z", "iopub.status.idle": "2026-01-20T22:25:13.424498Z", "shell.execute_reply": "2026-01-20T22:25:13.423916Z", "shell.execute_reply.started": "2026-01-20T22:25:12.515627Z"}}, "outputs": [{"data": {"text/plain": ["<graphistry.pygraphistry.GraphistryClient at 0x7aadb9c1b710>"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["from kaggle_secrets import UserSecretsClient\n", "\n", "user_secrets = UserSecretsClient()\n", "graphistry.register(\n", "    api=3,\n", "    protocol=\"https\",\n", "    server=\"hub.graphistry.com\",\n", "    personal_key_id=user_secrets.get_secret(\"Graphistry_Personal_Key_ID\"),\n", "    personal_key_secret=user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n", ")"]}, {"cell_type": "markdown", "id": "step3_header", "metadata": {}, "source": ["## Step 3: Download GGUF Model"]}, {"cell_type": "markdown", "id": "8c66831c", "metadata": {}, "source": ["Downloads embedding or instruction-following model for document analysis, semantic similarity computation, and relationship extraction."]}, {"cell_type": "markdown", "id": "4c34d6a8", "metadata": {}, "source": ["Downloads language model for document embeddings, semantic analysis, and text similarity computation."]}, {"cell_type": "code", "execution_count": 4, "id": "step3_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:25:14.546447Z", "iopub.status.busy": "2026-01-20T22:25:14.546156Z", "iopub.status.idle": "2026-01-20T22:25:44.849071Z", "shell.execute_reply": "2026-01-20T22:25:44.848415Z", "shell.execute_reply.started": "2026-01-20T22:25:14.546419Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ğŸ“¥ Downloading Llama-3.2-3B-Instruct-Q4_K_M.gguf...\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "49b977d6f6534763a67df82b8cb157c2", "version_major": 2, "version_minor": 0}, "text/plain": ["Llama-3.2-3B-Instruct-Q4_K_M.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["\n", "âœ… Model downloaded: /kaggle/working/models/Llama-3.2-3B-Instruct-Q4_K_M.gguf\n", "   Size: 1.88 GB\n", "CPU times: user 5.7 s, sys: 8.99 s, total: 14.7 s\n", "Wall time: 30.3 s\n"]}], "source": ["%%time\n", "from huggingface_hub import hf_hub_download\n", "import os\n", "\n", "MODEL_REPO = \"bartowski/Llama-3.2-3B-Instruct-GGUF\"\n", "MODEL_FILE = \"Llama-3.2-3B-Instruct-Q4_K_M.gguf\"\n", "\n", "print(f\"ğŸ“¥ Downloading {MODEL_FILE}...\")\n", "\n", "model_path = hf_hub_download(\n", "    repo_id=MODEL_REPO,\n", "    filename=MODEL_FILE,\n", "    local_dir=\"/kaggle/working/models\"\n", ")\n", "\n", "size_gb = os.path.getsize(model_path) / (1024**3)\n", "print(f\"\\nâœ… Model downloaded: {model_path}\")\n", "print(f\"   Size: {size_gb:.2f} GB\")"]}, {"cell_type": "markdown", "id": "step4_header", "metadata": {}, "source": ["## Step 4: Start llama-server on GPU 0 Only"]}, {"cell_type": "markdown", "id": "6e5b0b2a", "metadata": {}, "source": ["Deploys llama-server on GPU 0 using tensor-split configuration for document processing while keeping GPU 1 free for graph operations."]}, {"cell_type": "markdown", "id": "411b97e4", "metadata": {}, "source": ["Starts llama-server on GPU 0 using single-GPU configuration (tensor-split 1.0,0.0) while reserving GPU 1 for graph operations."]}, {"cell_type": "code", "execution_count": 5, "id": "step4_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:25:46.594697Z", "iopub.status.busy": "2026-01-20T22:25:46.593966Z", "iopub.status.idle": "2026-01-20T22:25:50.697003Z", "shell.execute_reply": "2026-01-20T22:25:50.696245Z", "shell.execute_reply.started": "2026-01-20T22:25:46.594667Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸš€ STARTING LLAMA-SERVER ON GPU 0\n", "======================================================================\n", "\n", "ğŸ“‹ Configuration:\n", "   GPU 0: 100% (llama-server for document summarization)\n", "   GPU 1: 0% (reserved for RAPIDS/Graphistry)\n", "GPU Check:\n", "  Platform: kaggle\n", "  GPU: Tesla T4\n", "  Compute Capability: 7.5\n", "  Status: âœ“ Compatible\n", "Starting llama-server...\n", "  Executable: /usr/local/lib/python3.12/dist-packages/llamatelemetry/binaries/cuda12/llama-server\n", "  Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf\n", "  GPU Layers: 99\n", "  Context Size: 4096\n", "  Server URL: http://127.0.0.1:8090\n", "Waiting for server to be ready....... âœ“ Ready in 4.0s\n", "\n", "âœ… llama-server running on GPU 0!\n"]}], "source": ["from llamatelemetry.server import ServerManager\n", "\n", "print(\"=\"*70)\n", "print(\"ğŸš€ STARTING LLAMA-SERVER ON GPU 0\")\n", "print(\"=\"*70)\n", "\n", "print(\"\\nğŸ“‹ Configuration:\")\n", "print(\"   GPU 0: 100% (llama-server for document summarization)\")\n", "print(\"   GPU 1: 0% (reserved for RAPIDS/Graphistry)\")\n", "\n", "server = ServerManager()\n", "server.start_server(\n", "    model_path=model_path,\n", "    host=\"127.0.0.1\",\n", "    port=8090,\n", "    gpu_layers=99,\n", "    tensor_split=\"1.0,0.0\",\n", "    ctx_size=4096,\n", ")\n", "\n", "if server.check_server_health():\n", "    print(\"\\nâœ… llama-server running on GPU 0!\")\n", "else:\n", "    print(\"\\nâŒ Server failed to start\")"]}, {"cell_type": "markdown", "id": "step5_header", "metadata": {}, "source": ["## Step 5: Generate Document Summaries and Topics"]}, {"cell_type": "markdown", "id": "8243ced2", "metadata": {}, "source": ["Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."]}, {"cell_type": "markdown", "id": "370fdc25", "metadata": {}, "source": ["Verifies GPU memory allocation showing LLM loaded on GPU 0 with GPU 1 free for document network processing."]}, {"cell_type": "code", "execution_count": 6, "id": "step5_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:25:52.366181Z", "iopub.status.busy": "2026-01-20T22:25:52.365840Z", "iopub.status.idle": "2026-01-20T22:25:55.539221Z", "shell.execute_reply": "2026-01-20T22:25:55.538642Z", "shell.execute_reply.started": "2026-01-20T22:25:52.366154Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ“„ LLM-POWERED DOCUMENT ANALYSIS\n", "======================================================================\n", "doc1: {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}}\n", "doc2: {\"name\": \"TensorFlow Deep Learning Framework\", \"parameters\": {\"\": \"summary\"}}\n", "doc3: {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}}\n", "doc4: {\"name\": \"cuDF\", \"parameters\": {\"key\": \"GPU DataFrame library\"}}\n", "doc5: {\"name\": \"Summary\", \"parameters\": {\"summary\": \"Machine Learning on GPUs\"}}\n", "doc6: {\"name\": \"Spark uses GPUs efficiently\", \"parameters\": {\"\"}}\n", "doc7: {\"name\": \"LLM inference on GPUs\", \"parameters\": {\"\": \"summary\"}}\n", "doc8: {\"name\": \"summarize\", \"parameters\": {\"s\": \"TensorRT optimization for neural\n", "doc9: {\"name\": \"ONNX Runtime Acceleration\", \"parameters\": {\"\": \"machine learning\"}}\n", "doc10: {\"name\": \"graph visualization software\", \"parameters\": {\"scale\": \"at\"}}\n", "doc11: {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}}\n", "\n", "âœ… Generated 11 document summaries\n"]}], "source": ["from llamatelemetry.api.client import LlamaCppClient\n", "\n", "print(\"=\"*70)\n", "print(\"ğŸ“„ LLM-POWERED DOCUMENT ANALYSIS\")\n", "print(\"=\"*70)\n", "\n", "client = LlamaCppClient(base_url=\"http://127.0.0.1:8090\")\n", "\n", "# Sample documents about various GPU computing topics\n", "documents = [\n", "    # Deep Learning cluster\n", "    {\"id\": \"doc1\", \"text\": \"PyTorch provides dynamic computation graphs for deep learning. It integrates seamlessly with CUDA for GPU acceleration. Training neural networks on GPUs is significantly faster than CPUs.\"},\n", "    {\"id\": \"doc2\", \"text\": \"TensorFlow is Google's deep learning framework. It offers distributed training across multiple GPUs. TensorBoard provides visualization for training metrics.\"},\n", "    {\"id\": \"doc3\", \"text\": \"NVIDIA cuDNN accelerates deep neural network training. It provides highly optimized primitives for convolution and pooling operations on GPUs.\"},\n", "    \n", "    # Data Science cluster\n", "    {\"id\": \"doc4\", \"text\": \"RAPIDS cuDF provides a GPU DataFrame library. It accelerates pandas operations by 50-100Ã— using CUDA. Data scientists can process large datasets efficiently.\"},\n", "    {\"id\": \"doc5\", \"text\": \"cuML implements machine learning algorithms on GPUs. It supports classification, regression, and clustering with scikit-learn API compatibility.\"},\n", "    {\"id\": \"doc6\", \"text\": \"Apache Spark can leverage GPUs for distributed computing. RAPIDS Accelerator speeds up Spark SQL and DataFrame operations on GPU clusters.\"},\n", "    \n", "    # Inference cluster\n", "    {\"id\": \"doc7\", \"text\": \"llama.cpp enables efficient LLM inference on GPUs. GGUF quantization reduces model size while maintaining quality. It supports multi-GPU tensor parallelism.\"},\n", "    {\"id\": \"doc8\", \"text\": \"TensorRT optimizes neural network inference. It provides INT8 and FP16 precision for faster inference. Deployed models achieve low latency on NVIDIA GPUs.\"},\n", "    {\"id\": \"doc9\", \"text\": \"ONNX Runtime accelerates machine learning inference. It supports multiple hardware backends including CUDA. Models can be optimized for production deployment.\"},\n", "    \n", "    # Visualization cluster\n", "    {\"id\": \"doc10\", \"text\": \"Graphistry provides GPU-accelerated graph visualization. It handles millions of nodes and edges interactively. RAPIDS integration enables visual analytics at scale.\"},\n", "    {\"id\": \"doc11\", \"text\": \"cuGraph implements graph algorithms on GPUs. PageRank and community detection run 100Ã— faster than NetworkX. It integrates with Graphistry for visualization.\"},\n", "]\n", "\n", "# Extract topics from each document\n", "doc_topics = []\n", "\n", "for doc in documents:\n", "    prompt = f\"\"\"Summarize this document in 5 words maximum, focusing on the main topic:\n", "\n", "{doc['text']}\n", "\n", "5-word summary:\"\"\"\n", "    \n", "    response = client.chat.create(\n", "        messages=[{\"role\": \"user\", \"content\": prompt}],\n", "        max_tokens=20,\n", "        temperature=0.3,\n", "    )\n", "    \n", "    summary = response.choices[0].message.content.strip()\n", "    doc_topics.append({\"id\": doc[\"id\"], \"summary\": summary, \"text\": doc[\"text\"]})\n", "    print(f\"{doc['id']}: {summary}\")\n", "\n", "print(f\"\\nâœ… Generated {len(doc_topics)} document summaries\")"]}, {"cell_type": "markdown", "id": "step6_header", "metadata": {}, "source": ["## Step 6: Initialize RAPIDS on GPU 1"]}, {"cell_type": "markdown", "id": "b179961a", "metadata": {}, "source": ["Initializes RAPIDS on GPU 1 via CUDA_VISIBLE_DEVICES environment variable for GPU-accelerated document graph operations."]}, {"cell_type": "code", "execution_count": 7, "id": "step6_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:00.938586Z", "iopub.status.busy": "2026-01-20T22:26:00.938288Z", "iopub.status.idle": "2026-01-20T22:26:00.944329Z", "shell.execute_reply": "2026-01-20T22:26:00.943449Z", "shell.execute_reply.started": "2026-01-20T22:26:00.938560Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ”¥ INITIALIZING RAPIDS ON GPU 1\n", "======================================================================\n", "\n", "ğŸ“Š RAPIDS GPU Info:\n", "   Device: 0 (filtered view)\n", "   Actual GPU: 1 (Tesla T4)\n", "\n", "âœ… RAPIDS initialized on GPU 1\n"]}], "source": ["import os\n", "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n", "\n", "print(\"=\"*70)\n", "print(\"ğŸ”¥ INITIALIZING RAPIDS ON GPU 1\")\n", "print(\"=\"*70)\n", "\n", "import cudf\n", "import cupy as cp\n", "\n", "print(f\"\\nğŸ“Š RAPIDS GPU Info:\")\n", "device = cp.cuda.Device(0)  # Device 0 in filtered view = actual GPU 1\n", "print(f\"   Device: {device.id} (filtered view)\")\n", "print(f\"   Actual GPU: 1 (Tesla T4)\")\n", "\n", "print(f\"\\nâœ… RAPIDS initialized on GPU 1\")"]}, {"cell_type": "markdown", "id": "step7_header", "metadata": {}, "source": ["## Step 7: Build Document Similarity Network"]}, {"cell_type": "markdown", "id": "6d37148b", "metadata": {}, "source": ["Loads sample document corpus and preprocesses text for similarity analysis and network construction."]}, {"cell_type": "code", "execution_count": 8, "id": "step7_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:03.026850Z", "iopub.status.busy": "2026-01-20T22:26:03.026529Z", "iopub.status.idle": "2026-01-20T22:26:04.069520Z", "shell.execute_reply": "2026-01-20T22:26:04.068902Z", "shell.execute_reply.started": "2026-01-20T22:26:03.026822Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ“Š BUILDING DOCUMENT SIMILARITY NETWORK\n", "======================================================================\n", "\n", "ğŸ“Š Document Similarity Network:\n", "   Nodes (documents): 11\n", "   Edges (similarities > 0.15): 9\n", "   Average similarity: 0.210\n", "\n", "âœ… Document network created on GPU 1\n"]}], "source": ["import cugraph\n", "import numpy as np\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.metrics.pairwise import cosine_similarity\n", "\n", "print(\"=\"*70)\n", "print(\"ğŸ“Š BUILDING DOCUMENT SIMILARITY NETWORK\")\n", "print(\"=\"*70)\n", "\n", "# Calculate TF-IDF similarity between documents\n", "texts = [doc['text'] for doc in doc_topics]\n", "vectorizer = TfidfVectorizer()\n", "tfidf_matrix = vectorizer.fit_transform(texts)\n", "similarity_matrix = cosine_similarity(tfidf_matrix)\n", "\n", "# Create edges for documents with similarity > threshold\n", "threshold = 0.15  # Lower threshold to create more connections\n", "edges_list = []\n", "\n", "for i in range(len(documents)):\n", "    for j in range(i + 1, len(documents)):\n", "        similarity = similarity_matrix[i, j]\n", "        if similarity > threshold:\n", "            edges_list.append({\n", "                'source': i,\n", "                'target': j,\n", "                'weight': float(similarity)\n", "            })\n", "\n", "# Create cuDF edge list\n", "edges_cudf = cudf.DataFrame(edges_list)\n", "\n", "print(f\"\\nğŸ“Š Document Similarity Network:\")\n", "print(f\"   Nodes (documents): {len(documents)}\")\n", "print(f\"   Edges (similarities > {threshold}): {len(edges_cudf)}\")\n", "print(f\"   Average similarity: {edges_cudf['weight'].mean():.3f}\")\n", "\n", "# Create cuGraph\n", "G = cugraph.Graph()\n", "G.from_cudf_edgelist(edges_cudf, source='source', destination='target', edge_attr='weight')\n", "\n", "print(f\"\\nâœ… Document network created on GPU 1\")"]}, {"cell_type": "markdown", "id": "step8_header", "metadata": {}, "source": ["## Step 8: Community Detection with Louvain Algorithm"]}, {"cell_type": "markdown", "id": "e3fd9b2e", "metadata": {}, "source": ["Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."]}, {"cell_type": "markdown", "id": "f59248fb", "metadata": {}, "source": ["Generates document embeddings using LLM on GPU 0, creating vector representations for semantic similarity computation."]}, {"cell_type": "code", "execution_count": 10, "id": "step8_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:13.581734Z", "iopub.status.busy": "2026-01-20T22:26:13.581220Z", "iopub.status.idle": "2026-01-20T22:26:13.599583Z", "shell.execute_reply": "2026-01-20T22:26:13.598894Z", "shell.execute_reply.started": "2026-01-20T22:26:13.581704Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ”¬ COMMUNITY DETECTION (GPU-ACCELERATED)\n", "======================================================================\n", "\n", "ğŸ“Š Detected 3 communities:\n", "   Community 0: doc1, doc3, doc2, doc8\n", "   Community 1: doc11, doc5, doc10\n", "   Community 2: doc4, doc6\n", "\n", "âœ… Community detection complete on GPU 1\n"]}], "source": ["print(\"=\"*70)\n", "print(\"ğŸ”¬ COMMUNITY DETECTION (GPU-ACCELERATED)\")\n", "print(\"=\"*70)\n", "\n", "# Run Louvain community detection\n", "partition_df, modularity_score = cugraph.louvain(G)\n", "\n", "# Map communities back to documents\n", "communities_pd = partition_df.to_pandas()\n", "doc_communities = {}\n", "for _, row in communities_pd.iterrows():\n", "    doc_id = int(row['vertex'])\n", "    community_id = int(row['partition'])\n", "    doc_communities[doc_id] = community_id\n", "\n", "# Group documents by community\n", "community_groups = {}\n", "for doc_id, community_id in doc_communities.items():\n", "    if community_id not in community_groups:\n", "        community_groups[community_id] = []\n", "    community_groups[community_id].append(doc_id)\n", "\n", "print(f\"\\nğŸ“Š Detected {len(community_groups)} communities:\")\n", "for community_id, doc_ids in sorted(community_groups.items()):\n", "    doc_names = [doc_topics[i]['id'] for i in doc_ids]\n", "    print(f\"   Community {community_id}: {', '.join(doc_names)}\")\n", "\n", "print(\"\\nâœ… Community detection complete on GPU 1\")"]}, {"cell_type": "markdown", "id": "step9_header", "metadata": {}, "source": ["## Step 9: Graph Analytics on Communities"]}, {"cell_type": "markdown", "id": "efaf2e09", "metadata": {}, "source": ["Computes network metrics (centrality, clustering coefficient) to identify influential documents and network structure."]}, {"cell_type": "markdown", "id": "04d88e83", "metadata": {}, "source": ["Computes pairwise document similarity matrix using cosine similarity on embeddings, identifying related documents."]}, {"cell_type": "code", "execution_count": 11, "id": "step9_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:17.085739Z", "iopub.status.busy": "2026-01-20T22:26:17.085119Z", "iopub.status.idle": "2026-01-20T22:26:17.438243Z", "shell.execute_reply": "2026-01-20T22:26:17.437636Z", "shell.execute_reply.started": "2026-01-20T22:26:17.085709Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ“Š DOCUMENT NETWORK ANALYTICS\n", "======================================================================\n", "\n", "ğŸ“Š PageRank Analysis (Document Importance):\n", "   doc1: 0.1802 - {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}}\n", "   doc11: 0.1567 - {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}}\n", "   doc3: 0.1392 - {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}}\n", "   doc4: 0.1111 - {\"name\": \"cuDF\", \"parameters\": {\"key\": \"GPU DataFrame library\"}}\n", "   doc6: 0.1111 - {\"name\": \"Spark uses GPUs efficiently\", \"parameters\": {\"\"}}\n", "\n", "ğŸ“Š Betweenness Centrality (Bridge Documents):\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/usr/local/lib/python3.12/dist-packages/cugraph/link_analysis/pagerank.py:232: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n", "  warnings.warn(warning_msg, UserWarning)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["   doc1: 0.3393 - {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}}\n", "   doc11: 0.3214 - {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}}\n", "   doc3: 0.0179 - {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}}\n", "   doc2: 0.0000 - {\"name\": \"TensorFlow Deep Learning Framework\", \"parameters\": {\"\": \"summary\"}}\n", "   doc8: 0.0000 - {\"name\": \"summarize\", \"parameters\": {\"s\": \"TensorRT optimization for neural\n", "\n", "âœ… Graph analytics computed on GPU 1\n"]}], "source": ["print(\"=\"*70)\n", "print(\"ğŸ“Š DOCUMENT NETWORK ANALYTICS\")\n", "print(\"=\"*70)\n", "\n", "# PageRank - identify important documents\n", "print(\"\\nğŸ“Š PageRank Analysis (Document Importance):\")\n", "pagerank = cugraph.pagerank(G)\n", "pagerank = pagerank.sort_values('pagerank', ascending=False)\n", "\n", "for _, row in pagerank.to_pandas().head(5).iterrows():\n", "    doc_id = int(row['vertex'])\n", "    score = row['pagerank']\n", "    doc_name = doc_topics[doc_id]['id']\n", "    summary = doc_topics[doc_id]['summary']\n", "    print(f\"   {doc_name}: {score:.4f} - {summary}\")\n", "\n", "# Betweenness Centrality - bridge documents between communities\n", "print(\"\\nğŸ“Š Betweenness Centrality (Bridge Documents):\")\n", "bc = cugraph.betweenness_centrality(G)\n", "bc = bc.sort_values('betweenness_centrality', ascending=False)\n", "\n", "for _, row in bc.to_pandas().head(5).iterrows():\n", "    doc_id = int(row['vertex'])\n", "    score = row['betweenness_centrality']\n", "    doc_name = doc_topics[doc_id]['id']\n", "    summary = doc_topics[doc_id]['summary']\n", "    print(f\"   {doc_name}: {score:.4f} - {summary}\")\n", "\n", "print(\"\\nâœ… Graph analytics computed on GPU 1\")"]}, {"cell_type": "markdown", "id": "step10_header", "metadata": {}, "source": ["## Step 10: LLM Analysis of Community Themes"]}, {"cell_type": "markdown", "id": "f2c57e7b", "metadata": {}, "source": ["Computes network metrics (centrality, clustering coefficient) to identify influential documents and network structure."]}, {"cell_type": "markdown", "id": "ddf2d838", "metadata": {}, "source": ["Constructs document network graph on GPU 1 where nodes are documents and edges represent similarity above threshold."]}, {"cell_type": "code", "execution_count": 12, "id": "step10_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:20.759697Z", "iopub.status.busy": "2026-01-20T22:26:20.758982Z", "iopub.status.idle": "2026-01-20T22:26:21.579497Z", "shell.execute_reply": "2026-01-20T22:26:21.578903Z", "shell.execute_reply.started": "2026-01-20T22:26:20.759670Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ¤” LLM ANALYSIS OF COMMUNITY THEMES\n", "======================================================================\n", "\n", "ğŸ“Œ Community 0: {\"name\": \"Deep Learning Frameworks\", \"parameters\": {}}\n", "   Documents: doc1, doc3, doc2, doc8\n", "\n", "ğŸ“Œ Community 1: {\"name\": \"Graph Algorithms\", \"parameters\": {}}\n", "   Documents: doc11, doc5, doc10\n", "\n", "ğŸ“Œ Community 2: {\"name\": \"GPU usage\", \"parameters\": {}}\n", "   Documents: doc4, doc6\n", "\n", "âœ… Simultaneous GPU operation:\n", "   GPU 0: LLM inference (theme analysis)\n", "   GPU 1: Graph analytics (previously computed)\n"]}], "source": ["print(\"=\"*70)\n", "print(\"ğŸ¤” LLM ANALYSIS OF COMMUNITY THEMES\")\n", "print(\"=\"*70)\n", "\n", "for community_id, doc_ids in sorted(community_groups.items()):\n", "    # Get summaries for this community\n", "    summaries = [doc_topics[i]['summary'] for i in doc_ids]\n", "    doc_names = [doc_topics[i]['id'] for i in doc_ids]\n", "    \n", "    prompt = f\"\"\"These documents form a cluster based on similarity:\n", "{', '.join([f\"{name}: {summary}\" for name, summary in zip(doc_names, summaries)])}\n", "\n", "What is the common theme? Answer in one phrase (3-5 words):\"\"\"\n", "    \n", "    response = client.chat.create(\n", "        messages=[{\"role\": \"user\", \"content\": prompt}],\n", "        max_tokens=20,\n", "        temperature=0.5\n", "    )\n", "    \n", "    theme = response.choices[0].message.content.strip()\n", "    print(f\"\\nğŸ“Œ Community {community_id}: {theme}\")\n", "    print(f\"   Documents: {', '.join(doc_names)}\")\n", "\n", "print(\"\\nâœ… Simultaneous GPU operation:\")\n", "print(\"   GPU 0: LLM inference (theme analysis)\")\n", "print(\"   GPU 1: Graph analytics (previously computed)\")"]}, {"cell_type": "markdown", "id": "step11_header", "metadata": {}, "source": ["## Step 11: Graphistry Visualization"]}, {"cell_type": "markdown", "id": "11fce365", "metadata": {}, "source": ["Runs GPU-accelerated community detection on document network to discover thematic clusters and topic groups."]}, {"cell_type": "code", "execution_count": 13, "id": "step11_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:28.130187Z", "iopub.status.busy": "2026-01-20T22:26:28.129884Z", "iopub.status.idle": "2026-01-20T22:26:30.352534Z", "shell.execute_reply": "2026-01-20T22:26:30.351971Z", "shell.execute_reply.started": "2026-01-20T22:26:28.130161Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ¨ GRAPHISTRY DOCUMENT NETWORK VISUALIZATION\n", "======================================================================\n", "\n", "ğŸ” Registering with Graphistry...\n", "âœ… Graphistry registered successfully\n", "\n", "ğŸ“Š Preparing document network data...\n", "   Edge data shape: (9, 3)\n", "   Computing degree centrality...\n", "   Classifying document roles...\n", "\n", "ğŸ“Š Document Network Summary:\n", "   Documents: 11\n", "   Similarity Edges: 9\n", "   Communities: 3\n", "   Avg similarity: 0.210\n", "\n", "ğŸ¨ Creating Graphistry visualization...\n", "\n", "ğŸš€ Visualization Created Successfully!\n", "\n", "ğŸ”— Graphistry URL:\n", "   https://hub.graphistry.com/graph/graph.html?dataset=c4dd79ee95ae4a5488d8d0d280704c57&type=arrow&viztoken=d2f845dc-723f-4482-aa1b-f6d4f8c2676b&usertag=03c49df5-pygraphistry-0.50.4&splashAfter=1768948005&info=true&play=0&pointSize=2.5&edgeOpacity=0.4&bg=%23FFFFFF&showArrows=false&showLabels=true\n", "\n", "ğŸ“Œ Features:\n", "   âœ“ Color-coded by community (document clusters)\n", "   âœ“ Size scaled by PageRank (document importance)\n", "   âœ“ Icons show role (Hub â­, Bridge â†”ï¸, Peripheral â—‹)\n", "   âœ“ Edge color intensity = similarity strength\n", "   âœ“ Interactive tooltips with doc summaries\n"]}, {"data": {"text/html": ["<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\"><h3 style=\"margin:0 0 10px 0;\">ğŸ“„ Document Network Dashboard</h3><p style=\"margin:5px 0;\">GPU computing topics clustered by similarity</p><a href=\"https://hub.graphistry.com/graph/graph.html?dataset=c4dd79ee95ae4a5488d8d0d280704c57&type=arrow&viztoken=d2f845dc-723f-4482-aa1b-f6d4f8c2676b&usertag=03c49df5-pygraphistry-0.50.4&splashAfter=1768948005&info=true&play=0&pointSize=2.5&edgeOpacity=0.4&bg=%23FFFFFF&showArrows=false&showLabels=true\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸš€ Open Interactive Visualization</a></div>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["\n", "======================================================================\n", "âœ… Document network visualization complete\n", "======================================================================\n"]}], "source": ["print(\"=\"*70)\n", "print(\"ğŸ¨ GRAPHISTRY DOCUMENT NETWORK VISUALIZATION\")\n", "print(\"=\"*70)\n", "\n", "import graphistry\n", "from kaggle_secrets import UserSecretsClient\n", "import pandas as pd\n", "import numpy as np\n", "\n", "# --- 1. Register Graphistry ---\n", "print(\"\\nğŸ” Registering with Graphistry...\")\n", "try:\n", "    user_secrets = UserSecretsClient()\n", "    graphistry_key_id = user_secrets.get_secret(\"Graphistry_Personal_Key_ID\")\n", "    graphistry_secret = user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n", "\n", "    graphistry.register(\n", "        api=3,\n", "        protocol=\"https\",\n", "        server=\"hub.graphistry.com\",\n", "        personal_key_id=graphistry_key_id,\n", "        personal_key_secret=graphistry_secret\n", "    )\n", "    print(\"âœ… Graphistry registered successfully\")\n", "except Exception as e:\n", "    print(f\"âš ï¸ Graphistry registration failed: {e}\")\n", "    print(\"   Add secrets: Graphistry_Personal_Key_ID, Graphistry_Personal_Secret_Key\")\n", "\n", "# --- 2. Prepare visualization data ---\n", "print(\"\\nğŸ“Š Preparing document network data...\")\n", "\n", "# Ensure edges_pd exists\n", "if 'edges_pd' not in locals() and 'edges_pd' not in globals():\n", "    if 'edges_cudf' in locals() or 'edges_cudf' in globals():\n", "        edges_pd = edges_cudf.to_pandas()\n", "    else:\n", "        raise ValueError(\"No edges data found\")\n", "\n", "print(f\"   Edge data shape: {edges_pd.shape}\")\n", "\n", "# Ensure nodes data with all metrics\n", "if 'pagerank_pd' not in locals():\n", "    pagerank_pd = pagerank.to_pandas()\n", "if 'bc_pd' not in locals():\n", "    bc_pd = bc.to_pandas()\n", "if 'communities_pd' not in locals():\n", "    communities_pd = communities.to_pandas()\n", "\n", "# Build comprehensive nodes DataFrame\n", "nodes_pd = pd.DataFrame({\n", "    'node_id': list(range(len(doc_topics))),\n", "    'doc_id': [doc['id'] for doc in doc_topics],\n", "    'summary': [doc['summary'] for doc in doc_topics],\n", "    'text_preview': [doc['text'][:100] + '...' if len(doc['text']) > 100 else doc['text'] for doc in doc_topics]\n", "})\n", "\n", "# Merge PageRank\n", "nodes_pd = nodes_pd.merge(\n", "    pagerank_pd.rename(columns={'vertex': 'node_id'}),\n", "    on='node_id',\n", "    how='left'\n", ")\n", "\n", "# Merge Betweenness Centrality\n", "nodes_pd = nodes_pd.merge(\n", "    bc_pd.rename(columns={'vertex': 'node_id'}),\n", "    on='node_id',\n", "    how='left'\n", ")\n", "\n", "# Merge Communities\n", "nodes_pd = nodes_pd.merge(\n", "    communities_pd.rename(columns={'vertex': 'node_id', 'partition': 'community'}),\n", "    on='node_id',\n", "    how='left'\n", ")\n", "nodes_pd['community'] = nodes_pd['community'].fillna(0).astype(int)\n", "\n", "# --- 3. Compute degree centrality ---\n", "print(\"   Computing degree centrality...\")\n", "degree_in = edges_pd.groupby('target').size().reset_index(name='degree_in').rename(columns={'target': 'node_id'})\n", "degree_out = edges_pd.groupby('source').size().reset_index(name='degree_out').rename(columns={'source': 'node_id'})\n", "\n", "nodes_pd = nodes_pd.merge(degree_in, on='node_id', how='left')\n", "nodes_pd = nodes_pd.merge(degree_out, on='node_id', how='left')\n", "nodes_pd['degree_in'] = nodes_pd['degree_in'].fillna(0).astype(int)\n", "nodes_pd['degree_out'] = nodes_pd['degree_out'].fillna(0).astype(int)\n", "nodes_pd['total_degree'] = nodes_pd['degree_in'] + nodes_pd['degree_out']\n", "\n", "# --- 4. Role classification ---\n", "print(\"   Classifying document roles...\")\n", "\n", "def classify_doc_role(row):\n", "    \"\"\"Classify documents: Hub (high centrality), Bridge (high betweenness), Peripheral.\"\"\"\n", "    pr = row['pagerank']\n", "    bc = row['betweenness_centrality']\n", "    pr_threshold = nodes_pd['pagerank'].median()\n", "    bc_threshold = nodes_pd['betweenness_centrality'].median()\n", "\n", "    if pr > pr_threshold and bc > bc_threshold:\n", "        return 'Hub'\n", "    elif bc > bc_threshold:\n", "        return 'Bridge'\n", "    else:\n", "        return 'Peripheral'\n", "\n", "nodes_pd['role'] = nodes_pd.apply(classify_doc_role, axis=1)\n", "\n", "# --- 5. Size encoding (normalized PageRank) ---\n", "pr_min = nodes_pd['pagerank'].min()\n", "pr_max = nodes_pd['pagerank'].max()\n", "if pr_max > pr_min:\n", "    nodes_pd['node_size'] = 25 + (nodes_pd['pagerank'] - pr_min) / (pr_max - pr_min) * 75\n", "else:\n", "    nodes_pd['node_size'] = 50\n", "\n", "# --- 6. Rich tooltips ---\n", "nodes_pd['point_title'] = nodes_pd.apply(\n", "    lambda row: f\"{row['doc_id']}: {row['summary']}\\n\" +\n", "                f\"Community: {row['community']}\\n\" +\n", "                f\"Role: {row['role']}\\n\" +\n", "                f\"PageRank: {row['pagerank']:.4f}\\n\" +\n", "                f\"Betweenness: {row['betweenness_centrality']:.4f}\\n\" +\n", "                f\"Degree: {int(row['total_degree'])}\",\n", "    axis=1\n", ")\n", "\n", "edges_pd['edge_title'] = edges_pd.apply(\n", "    lambda row: f\"Similarity: {row['weight']:.3f}\",\n", "    axis=1\n", ")\n", "\n", "print(f\"\\nğŸ“Š Document Network Summary:\")\n", "print(f\"   Documents: {len(nodes_pd)}\")\n", "print(f\"   Similarity Edges: {len(edges_pd)}\")\n", "print(f\"   Communities: {nodes_pd['community'].nunique()}\")\n", "print(f\"   Avg similarity: {edges_pd['weight'].mean():.3f}\")\n", "\n", "# --- 7. Create Graphistry visualization ---\n", "print(\"\\nğŸ¨ Creating Graphistry visualization...\")\n", "\n", "# Color palettes\n", "community_colors = {\n", "    0: '#FF6B6B',  # Red - Deep Learning\n", "    1: '#4ECDC4',  # Teal - Data Science\n", "    2: '#45B7D1',  # Blue - Inference\n", "    3: '#FFA07A',  # Orange - Visualization\n", "    4: '#98D8C8',  # Mint\n", "}\n", "\n", "role_icons = {\n", "    'Hub': 'star',\n", "    'Bridge': 'exchange-alt',\n", "    'Peripheral': 'circle'\n", "}\n", "\n", "# Bind and create visualization\n", "g = graphistry.bind(\n", "    source='source',\n", "    destination='target',\n", "    node='node_id',\n", "    point_title='point_title',\n", "    edge_title='edge_title'\n", ")\n", "\n", "plotter = (\n", "    g.edges(edges_pd)\n", "    .nodes(nodes_pd)\n", "    .encode_point_color('community', categorical_mapping=community_colors, default_mapping='#CCCCCC')\n", "    .encode_point_size('node_size')\n", "    .encode_point_icon('role', categorical_mapping=role_icons, default_mapping='circle')\n", "    .encode_edge_color('weight', ['#E8E8E8', '#6C7A89', '#2C3E50'], as_continuous=True)\n", "    .settings(url_params={\n", "        'play': 0,\n", "        'pointSize': 2.5,\n", "        'edgeOpacity': 0.4,\n", "        'bg': '%23FFFFFF',\n", "        'showArrows': 'false',\n", "        'showLabels': 'true'\n", "    })\n", ")\n", "\n", "# --- 8. Launch visualization ---\n", "try:\n", "    url = plotter.plot(\n", "        render=False,\n", "        name=\"Document Similarity Network - llamatelemetry v0.1.0\",\n", "        description=f\"{len(nodes_pd)} documents clustered into {nodes_pd['community'].nunique()} communities\"\n", "    )\n", "\n", "    print(f\"\\nğŸš€ Visualization Created Successfully!\")\n", "    print(f\"\\nğŸ”— Graphistry URL:\")\n", "    print(f\"   {url}\")\n", "    print(f\"\\nğŸ“Œ Features:\")\n", "    print(f\"   âœ“ Color-coded by community (document clusters)\")\n", "    print(f\"   âœ“ Size scaled by PageRank (document importance)\")\n", "    print(f\"   âœ“ Icons show role (Hub â­, Bridge â†”ï¸, Peripheral â—‹)\")\n", "    print(f\"   âœ“ Edge color intensity = similarity strength\")\n", "    print(f\"   âœ“ Interactive tooltips with doc summaries\")\n", "\n", "    from IPython.display import display, HTML\n", "    display(HTML(\n", "        f'<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); '\n", "        f'border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\">'\n", "        f'<h3 style=\"margin:0 0 10px 0;\">ğŸ“„ Document Network Dashboard</h3>'\n", "        f'<p style=\"margin:5px 0;\">GPU computing topics clustered by similarity</p>'\n", "        f'<a href=\"{url}\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; '\n", "        f'background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; '\n", "        f'box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸš€ Open Interactive Visualization</a>'\n", "        f'</div>'\n", "    ))\n", "\n", "except Exception as e:\n", "    print(f\"\\nâŒ Visualization error: {e}\")\n", "    print(f\"   Data prepared successfully - {len(nodes_pd)} nodes, {len(edges_pd)} edges\")\n", "\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"âœ… Document network visualization complete\")\n", "print(\"=\"*70)"]}, {"cell_type": "markdown", "id": "step12_header", "metadata": {}, "source": ["## Step 12: Detailed Community Report"]}, {"cell_type": "markdown", "id": "8e6091e8", "metadata": {}, "source": ["Computes network metrics (degree centrality, PageRank) on GPU 1 to identify most influential and central documents."]}, {"cell_type": "code", "execution_count": 14, "id": "step12_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:41.482199Z", "iopub.status.busy": "2026-01-20T22:26:41.481894Z", "iopub.status.idle": "2026-01-20T22:26:41.547757Z", "shell.execute_reply": "2026-01-20T22:26:41.547179Z", "shell.execute_reply.started": "2026-01-20T22:26:41.482172Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ“‹ DETAILED COMMUNITY REPORT\n", "======================================================================\n", "\n", "ğŸ“Œ Community 0:\n", "   Size: 4 documents\n", "\n", "   Documents:\n", "      â€¢ doc1: {\"name\": \"PyTorch GPU Acceleration\", \"parameters\": {\"\": \"None\"}} (PageRank: 0.1802)\n", "      â€¢ doc3: {\"name\": \"cuDNN acceleration for deep networks\", \"parameters\": {\"\": \"None\"}} (PageRank: 0.1392)\n", "      â€¢ doc2: {\"name\": \"TensorFlow Deep Learning Framework\", \"parameters\": {\"\": \"summary\"}} (PageRank: 0.0980)\n", "      â€¢ doc8: {\"name\": \"summarize\", \"parameters\": {\"s\": \"TensorRT optimization for neural (PageRank: 0.0881)\n", "\n", "   Avg intra-community similarity: 0.220\n", "\n", "ğŸ“Œ Community 1:\n", "   Size: 3 documents\n", "\n", "   Documents:\n", "      â€¢ doc11: {\"name\": \"cuGraph\", \"parameters\": {\"\": \"graph algorithm\"}} (PageRank: 0.1567)\n", "      â€¢ doc5: {\"name\": \"Summary\", \"parameters\": {\"summary\": \"Machine Learning on GPUs\"}} (PageRank: 0.0639)\n", "      â€¢ doc10: {\"name\": \"graph visualization software\", \"parameters\": {\"scale\": \"at\"}} (PageRank: 0.0516)\n", "\n", "   Avg intra-community similarity: 0.192\n", "\n", "ğŸ“Œ Community 2:\n", "   Size: 2 documents\n", "\n", "   Documents:\n", "      â€¢ doc4: {\"name\": \"cuDF\", \"parameters\": {\"key\": \"GPU DataFrame library\"}} (PageRank: 0.1111)\n", "      â€¢ doc6: {\"name\": \"Spark uses GPUs efficiently\", \"parameters\": {\"\"}} (PageRank: 0.1111)\n", "\n", "   Avg intra-community similarity: 0.166\n", "\n", "âœ… Community analysis complete\n"]}], "source": ["print(\"=\"*70)\n", "print(\"ğŸ“‹ DETAILED COMMUNITY REPORT\")\n", "print(\"=\"*70)\n", "\n", "for community_id, doc_ids in sorted(community_groups.items()):\n", "    print(f\"\\nğŸ“Œ Community {community_id}:\")\n", "    print(f\"   Size: {len(doc_ids)} documents\")\n", "    \n", "    print(f\"\\n   Documents:\")\n", "    for doc_id in doc_ids:\n", "        doc = doc_topics[doc_id]\n", "        pr_score = pagerank_pd[pagerank_pd['vertex'] == doc_id]['pagerank'].values\n", "        pr_score = pr_score[0] if len(pr_score) > 0 else 0\n", "        print(f\"      â€¢ {doc['id']}: {doc['summary']} (PageRank: {pr_score:.4f})\")\n", "    \n", "    # Avg similarity within community\n", "    intra_edges = edges_cudf[\n", "        (edges_cudf['source'].isin(doc_ids)) & \n", "        (edges_cudf['target'].isin(doc_ids))\n", "    ]\n", "    if len(intra_edges) > 0:\n", "        avg_sim = intra_edges['weight'].mean()\n", "        print(f\"\\n   Avg intra-community similarity: {avg_sim:.3f}\")\n", "\n", "print(\"\\nâœ… Community analysis complete\")"]}, {"cell_type": "markdown", "id": "step13_header", "metadata": {}, "source": ["## Step 13: Monitor Both GPUs"]}, {"cell_type": "markdown", "id": "ac8037c9", "metadata": {}, "source": ["Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings."]}, {"cell_type": "markdown", "id": "5dad540f", "metadata": {}, "source": ["Creates Graphistry visualization of document network with community colors, node sizes by centrality, and interactive filtering."]}, {"cell_type": "code", "execution_count": 15, "id": "step13_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:26:44.899645Z", "iopub.status.busy": "2026-01-20T22:26:44.898861Z", "iopub.status.idle": "2026-01-20T22:26:45.155045Z", "shell.execute_reply": "2026-01-20T22:26:45.154012Z", "shell.execute_reply.started": "2026-01-20T22:26:44.899574Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "ğŸ“Š DUAL GPU MONITORING\n", "======================================================================\n", "Tue Jan 20 22:26:44 2026       \n", "+-----------------------------------------------------------------------------------------+\n", "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n", "|-----------------------------------------+------------------------+----------------------+\n", "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n", "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n", "|                                         |                        |               MIG M. |\n", "|=========================================+========================+======================|\n", "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n", "| N/A   55C    P0             28W /   70W |    2679MiB /  15360MiB |      0%      Default |\n", "|                                         |                        |                  N/A |\n", "+-----------------------------------------+------------------------+----------------------+\n", "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n", "| N/A   55C    P0             28W /   70W |     103MiB /  15360MiB |      0%      Default |\n", "|                                         |                        |                  N/A |\n", "+-----------------------------------------+------------------------+----------------------+\n", "                                                                                         \n", "+-----------------------------------------------------------------------------------------+\n", "| Processes:                                                                              |\n", "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n", "|        ID   ID                                                               Usage      |\n", "|=========================================================================================|\n", "+-----------------------------------------------------------------------------------------+\n", "\n", "ğŸ’¡ Split-GPU Operation:\n", "   GPU 0: llama-server (document summarization)\n", "   GPU 1: RAPIDS (community detection, graph analytics)\n"]}], "source": ["print(\"=\"*70)\n", "print(\"ğŸ“Š DUAL GPU MONITORING\")\n", "print(\"=\"*70)\n", "\n", "!nvidia-smi\n", "\n", "print(\"\\nğŸ’¡ Split-GPU Operation:\")\n", "print(\"   GPU 0: llama-server (document summarization)\")\n", "print(\"   GPU 1: RAPIDS (community detection, graph analytics)\")"]}, {"cell_type": "markdown", "id": "step14_header", "metadata": {}, "source": ["## Step 14: Cleanup"]}, {"cell_type": "markdown", "id": "3b1c7a96", "metadata": {}, "source": ["Verifies dual T4 GPU availability for document network analysis workflow combining LLM text processing with GPU-accelerated network analytics."]}, {"cell_type": "markdown", "id": "bf086c76", "metadata": {}, "source": ["Uses LLM on GPU 0 to generate natural language summaries of detected document communities and key themes."]}, {"cell_type": "code", "execution_count": 16, "id": "step14_code", "metadata": {"execution": {"iopub.execute_input": "2026-01-20T22:27:13.981614Z", "iopub.status.busy": "2026-01-20T22:27:13.981270Z", "iopub.status.idle": "2026-01-20T22:27:14.777459Z", "shell.execute_reply": "2026-01-20T22:27:14.776456Z", "shell.execute_reply.started": "2026-01-20T22:27:13.981562Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ğŸ›‘ Stopping llama-server...\n", "\n", "âœ… Resources cleaned up\n", "\n", "ğŸ“Š Final GPU Status:\n", "index, memory.used [MiB], memory.free [MiB]\n", "0, 109 MiB, 14987 MiB\n", "1, 3 MiB, 15093 MiB\n"]}], "source": ["print(\"ğŸ›‘ Stopping llama-server...\")\n", "server.stop_server()\n", "\n", "# Clear RAPIDS memory\n", "import gc\n", "del G, edges_cudf, pagerank, bc, communities\n", "gc.collect()\n", "\n", "print(\"\\nâœ… Resources cleaned up\")\n", "print(\"\\nğŸ“Š Final GPU Status:\")\n", "!nvidia-smi --query-gpu=index,memory.used,memory.free --format=csv"]}, {"cell_type": "markdown", "id": "summary", "metadata": {}, "source": ["## ğŸ“š Summary\n", "\n", "### Document Network Analysis Workflow:\n", "1. **GPU 0**: LLM generates document summaries\n", "2. **CPU**: TF-IDF calculates document similarity\n", "3. **GPU 1**: cuGraph builds similarity network\n", "4. **GPU 1**: Louvain algorithm detects communities\n", "5. **GPU 0**: LLM interprets community themes\n", "6. **Graphistry**: Interactive visualization with communities\n", "\n", "### Key Integration Points:\n", "- âœ… LLM for document summarization and theme extraction\n", "- âœ… cuGraph for GPU-accelerated community detection (Louvain)\n", "- âœ… Graphistry for community-colored network visualization\n", "- âœ… PageRank & Betweenness for document importance ranking\n", "\n", "### Algorithms Used:\n", "- **Louvain**: Community detection (finds document clusters)\n", "- **PageRank**: Document importance (citation-like ranking)\n", "- **Betweenness Centrality**: Bridge documents (connect communities)\n", "- **TF-IDF + Cosine Similarity**: Document similarity metric\n", "\n", "### Split-GPU Architecture:\n", "```python\n", "# GPU 0: llama-server\n", "tensor_split=\"1.0,0.0\"  # 100% on GPU 0\n", "\n", "# GPU 1: RAPIDS\n", "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n", "import cudf, cugraph  # Uses GPU 1\n", "```\n", "\n", "---\n", "\n", "**Next:** [09-large-models-kaggle](09-large-models-kaggle-llamatelemetry-v0-1-0.ipynb)"]}], "metadata": {"kaggle": {"accelerator": "nvidiaTeslaT4", "dataSources": [], "dockerImageVersionId": 31260, "isGpuEnabled": true, "isInternetEnabled": true, "language": "python", "sourceType": "notebook"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.11"}}, "nbformat": 4, "nbformat_minor": 5}