{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "version": "3.12.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kaggle": {"accelerator": "nvidiaTeslaT4", "dataSources": [], "dockerImageVersionId": 31259, "isInternetEnabled": true, "language": "python", "sourceType": "notebook", "isGpuEnabled": true}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session", "metadata": {"_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5", "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19", "trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Graphistry_Personal_Key_ID\")\nsecret_value_1 = user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\nsecret_value_2 = user_secrets.get_secret(\"HF_TOKEN\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:56:28.143018Z", "iopub.execute_input": "2026-01-23T18:56:28.143417Z", "iopub.status.idle": "2026-01-23T18:56:28.398368Z", "shell.execute_reply.started": "2026-01-23T18:56:28.143376Z", "shell.execute_reply": "2026-01-23T18:56:28.397745Z"}}, "outputs": [], "execution_count": 1}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 1: Verify Dual GPU Environment\n# ==============================================================================\n\nimport subprocess\nimport os\n\nprint(\"=\"*70)\nprint(\"ğŸ” SPLIT-GPU ENVIRONMENT CHECK\")\nprint(\"=\"*70)\n\nresult = subprocess.run(\n    [\"nvidia-smi\", \"--query-gpu=index,name,memory.total,memory.free\", \"--format=csv,noheader\"],\n    capture_output=True, text=True\n)\n\ngpus = result.stdout.strip().split('\\n')\nprint(f\"\\nğŸ“Š Detected {len(gpus)} GPU(s):\")\nfor gpu in gpus:\n    print(f\"   {gpu}\")\n\nif len(gpus) >= 2:\n    print(\"\\nâœ… Dual T4 ready for split-GPU operation!\")\n    print(\"   GPU 0 â†’ llama-server (GGUF model inference)\")\n    print(\"   GPU 1 â†’ RAPIDS/Graphistry (architecture visualization)\")\nelse:\n    print(\"\\nâš ï¸ Need 2 GPUs for split operation\")\n", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:56:28.718132Z", "iopub.execute_input": "2026-01-23T18:56:28.718731Z", "iopub.status.idle": "2026-01-23T18:56:28.757927Z", "shell.execute_reply.started": "2026-01-23T18:56:28.718702Z", "shell.execute_reply": "2026-01-23T18:56:28.757234Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ” SPLIT-GPU ENVIRONMENT CHECK\n======================================================================\n\nğŸ“Š Detected 2 GPU(s):\n   0, Tesla T4, 15360 MiB, 15096 MiB\n   1, Tesla T4, 15360 MiB, 15096 MiB\n\nâœ… Dual T4 ready for split-GPU operation!\n   GPU 0 â†’ llama-server (GGUF model inference)\n   GPU 1 â†’ RAPIDS/Graphistry (architecture visualization)\n", "output_type": "stream"}], "execution_count": 2}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 2: Install Dependencies\n# ==============================================================================\n\nprint(\"ğŸ“¦ Installing dependencies...\")\n\n# Install llamatelemetry v0.1.0\n!pip install -q --no-cache-dir git+https://github.com/llamatelemetry/llamatelemetry.git@v0.1.0\n\n# Install cuGraph for GPU-accelerated graph algorithms\n!pip install -q --extra-index-url=https://pypi.nvidia.com \"cugraph-cu12==25.6.*\"\n\n# Install Graphistry for visualization\n!pip install -q \"graphistry[ai]\"\n\n# Install additional utilities\n!pip install -q pyarrow pandas numpy scipy\n\n# Verify installations\nimport llamatelemetry\nprint(f\"\\nâœ… llamatelemetry {llamatelemetry.__version__} installed\")\n\ntry:\n    import cudf, cugraph\n    print(f\"âœ… cuDF {cudf.__version__}\")\n    print(f\"âœ… cuGraph {cugraph.__version__}\")\nexcept ImportError as e:\n    print(f\"âš ï¸ RAPIDS: {e}\")\n\ntry:\n    import graphistry\n    print(f\"âœ… Graphistry {graphistry.__version__}\")\nexcept ImportError as e:\n    print(f\"âš ï¸ Graphistry: {e}\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:56:32.075536Z", "iopub.execute_input": "2026-01-23T18:56:32.075838Z", "iopub.status.idle": "2026-01-23T18:57:59.535204Z", "shell.execute_reply.started": "2026-01-23T18:56:32.075813Z", "shell.execute_reply": "2026-01-23T18:57:59.534417Z"}}, "outputs": [{"name": "stdout", "text": "ğŸ“¦ Installing dependencies...\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for llamatelemetry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.2 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.8/439.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h", "output_type": "stream"}, {"name": "stderr", "text": "WARNING:root:llamatelemetry: Library directory not found - shared libraries may not load correctly\n", "output_type": "stream"}, {"name": "stdout", "text": "\n======================================================================\nğŸ¯ llamatelemetry v0.1.0 First-Time Setup - Kaggle 2Ã— T4 Multi-GPU\n======================================================================\n\nğŸ® GPU Detected: Tesla T4 (Compute 7.5)\n  âœ… Tesla T4 detected - Perfect for llamatelemetry v0.1.0!\nğŸŒ Platform: Kaggle\n\nğŸ“¦ Downloading Kaggle 2Ã— T4 binaries (~961 MB)...\n    Features: FlashAttention + Tensor Cores + Multi-GPU tensor-split\n\nâ¡ï¸  Attempt 1: HuggingFace (llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz)\nğŸ“¥ Downloading v0.1.0 from HuggingFace Hub...\n   Repo: waqasm86/llamatelemetry-binaries\n   File: v0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\nFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  warnings.warn(\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "v0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.(â€¦):   0%|          | 0.00/1.01G [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6a5fba7765394874be66d4adead2fb34"}}, "metadata": {}}, {"name": "stdout", "text": "ğŸ” Verifying SHA256 checksum...\n   âœ… Checksum verified\nğŸ“¦ Extracting llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz...\nFound 21 files in archive\nExtracted 21 files to /root/.cache/llamatelemetry/extract_0.1.0\nâœ… Extraction complete!\n  Found bin/ and lib/ under /root/.cache/llamatelemetry/extract_0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2\n  Copied 13 binaries to /usr/local/lib/python3.12/dist-packages/llamatelemetry/binaries/cuda12\n  Copied 0 libraries to /usr/local/lib/python3.12/dist-packages/llamatelemetry/lib\nâœ… Binaries installed successfully!\n\n\nâœ… llamatelemetry 0.1.0 installed\nâœ… cuDF 25.06.00\nâœ… cuGraph 25.06.00\nâœ… Graphistry 0.50.4\n", "output_type": "stream"}], "execution_count": 3}, {"cell_type": "code", "source": "# First, let's see what's actually available in llamatelemetry\nimport llamatelemetry\nprint(f\"llamatelemetry version: {llamatelemetry.__version__}\")\nprint(\"\\nAvailable attributes in llamatelemetry:\")\nprint([attr for attr in dir(llamatelemetry) if not attr.startswith('_')])", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:11.275011Z", "iopub.execute_input": "2026-01-23T18:58:11.276148Z", "iopub.status.idle": "2026-01-23T18:58:11.281299Z", "shell.execute_reply.started": "2026-01-23T18:58:11.276115Z", "shell.execute_reply": "2026-01-23T18:58:11.280476Z"}}, "outputs": [{"name": "stdout", "text": "llamatelemetry version: 0.1.0\n\nAvailable attributes in llamatelemetry:\n['Any', 'Dict', 'InferResult', 'InferenceEngine', 'List', 'Optional', 'Path', 'ServerManager', 'bootstrap', 'check_cuda_available', 'check_gpu_compatibility', 'create_config_file', 'detect_cuda', 'find_gguf_models', 'get_cuda_device_info', 'get_llama_cpp_cuda_path', 'get_recommended_gpu_layers', 'load_config', 'logging', 'os', 'print_system_info', 'quick_infer', 'requests', 'server', 'setup_environment', 'subprocess', 'sys', 'time', 'utils', 'validate_model_path']\n", "output_type": "stream"}], "execution_count": 4}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 3: Download GGUF Model (Fixed - No GGUF Parsing Errors)\n# ==============================================================================\n\nfrom huggingface_hub import hf_hub_download\nimport os\n\nMODEL_REPO = \"bartowski/Llama-3.2-3B-Instruct-GGUF\"\nMODEL_FILE = \"Llama-3.2-3B-Instruct-Q4_K_M.gguf\"\n\nprint(f\"ğŸ“¥ Downloading {MODEL_FILE}...\")\n\nmodel_path = hf_hub_download(\n    repo_id=MODEL_REPO,\n    filename=MODEL_FILE,\n    local_dir=\"/kaggle/working/models\"\n)\n\nsize_gb = os.path.getsize(model_path) / (1024**3)\nprint(f\"\\nâœ… Model downloaded: {model_path}\")\nprint(f\"   Size: {size_gb:.2f} GB\")\n\n# Show file exists\nprint(f\"\\nğŸ“ File verification:\")\nprint(f\"   File exists: {os.path.exists(model_path)}\")\nprint(f\"   File size: {size_gb:.2f} GB\")\n\n# Instead of parsing GGUF, use known architecture for Llama-3.2-3B\nprint(\"\\nğŸ” Using known architecture for Llama-3.2-3B:\")\n\n# Known architecture for Llama-3.2-3B\nARCHITECTURE = {\n    'model': 'Llama-3.2-3B-Instruct',\n    'format': 'GGUF Q4_K_M',\n    'layers': 28,                 # Number of transformer blocks\n    'attention_heads': 32,        # Attention heads per layer\n    'hidden_dimension': 3072,     # Model dimension\n    'vocabulary_size': 128256,    # Token vocabulary\n    'context_length': 8192,       # Max context length\n    'feedforward_multiplier': 4,  # FFN is 4Ã— hidden_dim (Swiglu)\n    'quantization': 'Q4_K_M',     # Quantization type\n    'estimated_params': 2.8e9,    # Approximately 2.8 billion parameters\n    'file_size_gb': 1.88,         # Actual file size\n    'attention_dim_per_head': 96, # 3072 / 32 = 96\n    'rope_theta': 500000,         # RoPE base frequency\n}\n\nprint(\"\\nğŸ“Š Architecture Summary:\")\nfor key, value in ARCHITECTURE.items():\n    if isinstance(value, (int, float)) and value >= 1000:\n        print(f\"   {key}: {value:,}\")\n    else:\n        print(f\"   {key}: {value}\")\n\n# Derived calculations\nprint(\"\\nğŸ§® Derived Architecture Values:\")\nn_layers = ARCHITECTURE['layers']\nn_heads = ARCHITECTURE['attention_heads']\nhidden_dim = ARCHITECTURE['hidden_dimension']\nvocab_size = ARCHITECTURE['vocabulary_size']\n\nprint(f\"   Total transformer layers: {n_layers}\")\nprint(f\"   Total attention heads: {n_layers} Ã— {n_heads} = {n_layers * n_heads:,}\")\nprint(f\"   Attention dimension per head: {hidden_dim} Ã· {n_heads} = {hidden_dim // n_heads}\")\nprint(f\"   Feed-forward hidden dimension: {hidden_dim} Ã— {ARCHITECTURE['feedforward_multiplier']} = {hidden_dim * ARCHITECTURE['feedforward_multiplier']:,}\")\n\n# Parameter breakdown (simplified)\nprint(\"\\nğŸ“ˆ Parameter Distribution (Approximate):\")\nembedding_params = vocab_size * hidden_dim\nattention_params = 4 * hidden_dim * hidden_dim * n_layers  # Q, K, V, O\nffn_params = 2 * 4 * hidden_dim * hidden_dim * n_layers    # FFN (Swiglu)\noutput_params = hidden_dim * vocab_size                    # Output layer\ntotal_params = embedding_params + attention_params + ffn_params + output_params\n\nprint(f\"   Embedding layer: {embedding_params:,} ({embedding_params/total_params*100:.1f}%)\")\nprint(f\"   Attention layers: {attention_params:,} ({attention_params/total_params*100:.1f}%)\")\nprint(f\"   Feed-forward layers: {ffn_params:,} ({ffn_params/total_params*100:.1f}%)\")\nprint(f\"   Output layer: {output_params:,} ({output_params/total_params*100:.1f}%)\")\nprint(f\"   Total estimated: {total_params:,} parameters\")\n\n# Quantization impact\nprint(f\"\\nâš–ï¸ Quantization Impact (Q4_K_M):\")\nfull_precision_gb = (total_params * 4) / (1024**3)  # 4 bytes per float32\nquantized_gb = size_gb\ncompression_ratio = full_precision_gb / quantized_gb\n\nprint(f\"   Full precision (FP32): {full_precision_gb:.1f} GB\")\nprint(f\"   Quantized (Q4_K_M): {quantized_gb:.1f} GB\")\nprint(f\"   Compression ratio: {compression_ratio:.1f}Ã—\")\nprint(f\"   Average bits per parameter: {32 / compression_ratio:.1f} bits\")\n\nprint(f\"\\nâœ… Architecture ready for visualization\")\nprint(f\"   Will visualize: {n_layers} layers Ã— {n_heads} heads = {n_layers * n_heads:,} attention heads\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:12.616406Z", "iopub.execute_input": "2026-01-23T18:58:12.617238Z", "iopub.status.idle": "2026-01-23T18:58:17.955309Z", "shell.execute_reply.started": "2026-01-23T18:58:12.617196Z", "shell.execute_reply": "2026-01-23T18:58:17.954645Z"}}, "outputs": [{"name": "stdout", "text": "ğŸ“¥ Downloading Llama-3.2-3B-Instruct-Q4_K_M.gguf...\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "Llama-3.2-3B-Instruct-Q4_K_M.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e02f9e121cb243f5bb1de019f53b71f0"}}, "metadata": {}}, {"name": "stdout", "text": "\nâœ… Model downloaded: /kaggle/working/models/Llama-3.2-3B-Instruct-Q4_K_M.gguf\n   Size: 1.88 GB\n\nğŸ“ File verification:\n   File exists: True\n   File size: 1.88 GB\n\nğŸ” Using known architecture for Llama-3.2-3B:\n\nğŸ“Š Architecture Summary:\n   model: Llama-3.2-3B-Instruct\n   format: GGUF Q4_K_M\n   layers: 28\n   attention_heads: 32\n   hidden_dimension: 3,072\n   vocabulary_size: 128,256\n   context_length: 8,192\n   feedforward_multiplier: 4\n   quantization: Q4_K_M\n   estimated_params: 2,800,000,000.0\n   file_size_gb: 1.88\n   attention_dim_per_head: 96\n   rope_theta: 500,000\n\nğŸ§® Derived Architecture Values:\n   Total transformer layers: 28\n   Total attention heads: 28 Ã— 32 = 896\n   Attention dimension per head: 3072 Ã· 32 = 96\n   Feed-forward hidden dimension: 3072 Ã— 4 = 12,288\n\nğŸ“ˆ Parameter Distribution (Approximate):\n   Embedding layer: 394,002,432 (10.0%)\n   Attention layers: 1,056,964,608 (26.7%)\n   Feed-forward layers: 2,113,929,216 (53.4%)\n   Output layer: 394,002,432 (10.0%)\n   Total estimated: 3,958,898,688 parameters\n\nâš–ï¸ Quantization Impact (Q4_K_M):\n   Full precision (FP32): 14.7 GB\n   Quantized (Q4_K_M): 1.9 GB\n   Compression ratio: 7.8Ã—\n   Average bits per parameter: 4.1 bits\n\nâœ… Architecture ready for visualization\n   Will visualize: 28 layers Ã— 32 heads = 896 attention heads\n", "output_type": "stream"}], "execution_count": 5}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 4: Start llama-server on GPU 0 Only\n# ==============================================================================\n\nfrom llamatelemetry.server import ServerManager\n\nprint(\"=\"*70)\nprint(\"ğŸš€ STARTING LLAMA-SERVER ON GPU 0\")\nprint(\"=\"*70)\n\nprint(\"\\nğŸ“‹ Configuration:\")\nprint(\"   GPU 0: 100% (llama-server for model inference)\")\nprint(\"   GPU 1: 0% (reserved for RAPIDS/Graphistry)\")\nprint(\"   Model: Llama-3.2-3B-Instruct (Q4_K_M)\")\nprint(\"   Context: 4096 tokens\")\n\nserver = ServerManager()\nserver.start_server(\n    model_path=model_path,\n    host=\"127.0.0.1\",\n    port=8090,\n    gpu_layers=99,          # Load all layers to GPU\n    tensor_split=\"1.0,0.0\", # 100% GPU 0, 0% GPU 1\n    ctx_size=4096,\n    verbose=False\n)\n\nif server.check_server_health():\n    print(\"\\nâœ… llama-server running on GPU 0!\")\n    print(\"   URL: http://127.0.0.1:8090\")\nelse:\n    print(\"\\nâŒ Server failed to start\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:22.660707Z", "iopub.execute_input": "2026-01-23T18:58:22.661331Z", "iopub.status.idle": "2026-01-23T18:58:26.790880Z", "shell.execute_reply.started": "2026-01-23T18:58:22.661301Z", "shell.execute_reply": "2026-01-23T18:58:26.790241Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸš€ STARTING LLAMA-SERVER ON GPU 0\n======================================================================\n\nğŸ“‹ Configuration:\n   GPU 0: 100% (llama-server for model inference)\n   GPU 1: 0% (reserved for RAPIDS/Graphistry)\n   Model: Llama-3.2-3B-Instruct (Q4_K_M)\n   Context: 4096 tokens\n\nâœ… llama-server running on GPU 0!\n   URL: http://127.0.0.1:8090\n", "output_type": "stream"}], "execution_count": 6}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 5: Extract Model Architecture Information\n# ==============================================================================\n\nfrom llamatelemetry.api.client import LlamaCppClient\nimport pandas as pd\nimport numpy as np\nimport json\n\nprint(\"=\"*70)\nprint(\"ğŸ§  EXTRACTING MODEL ARCHITECTURE\")\nprint(\"=\"*70)\n\nclient = LlamaCppClient(base_url=\"http://127.0.0.1:8090\")\n\n# Query model for architecture details\nprompt = \"\"\"You are a neural network analyzer. Describe your architecture in JSON format including:\n1. Number of transformer layers\n2. Attention heads per layer\n3. Hidden dimension size\n4. Vocabulary size\n5. Quantization type\n6. Parameter count\n\nFormat the response as valid JSON only:\"\"\"\n\nresponse = client.chat.create(\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    max_tokens=500,\n    temperature=0.1\n)\n\ntry:\n    # Parse the JSON response\n    content = response.choices[0].message.content\n    json_start = content.find('{')\n    json_end = content.rfind('}') + 1\n    if json_start != -1 and json_end > json_start:\n        arch_json = content[json_start:json_end]\n        arch_data = json.loads(arch_json)\n        print(\"\\nğŸ“Š Model Architecture:\")\n        for key, value in arch_data.items():\n            print(f\"   {key}: {value}\")\n        \n        # Use known values for Llama-3.2-3B if parsing fails\n        n_layers = arch_data.get('layers', 28)\n        n_heads = arch_data.get('attention_heads', 32)\n        hidden_dim = arch_data.get('hidden_dimension', 3072)\n        vocab_size = arch_data.get('vocabulary_size', 128256)\n        \nexcept Exception as e:\n    print(f\"âš ï¸ Could not parse architecture from LLM: {e}\")\n    print(\"   Using known architecture for Llama-3.2-3B...\")\n    n_layers = 28      # Llama-3.2-3B has 28 layers\n    n_heads = 32       # 32 attention heads\n    hidden_dim = 3072  # Hidden dimension\n    vocab_size = 128256 # Vocabulary size\n\nprint(f\"\\nğŸ“ Derived Architecture:\")\nprint(f\"   Layers: {n_layers}\")\nprint(f\"   Attention Heads: {n_heads}\")\nprint(f\"   Hidden Dimension: {hidden_dim}\")\nprint(f\"   Vocabulary Size: {vocab_size}\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:26.791981Z", "iopub.execute_input": "2026-01-23T18:58:26.792248Z", "iopub.status.idle": "2026-01-23T18:58:27.912829Z", "shell.execute_reply.started": "2026-01-23T18:58:26.792224Z", "shell.execute_reply": "2026-01-23T18:58:27.912057Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ§  EXTRACTING MODEL ARCHITECTURE\n======================================================================\n\nğŸ“Š Model Architecture:\n   name: neural_network_architecture\n   parameters: {'num_transformer_layers': 6, 'attention_heads_per_layer': 8, 'hidden_dimension_size': 1024, 'vocabulary_size': 10000, 'quantization_type': 'int8', 'parameter_count': 175776000}\n\nğŸ“ Derived Architecture:\n   Layers: 28\n   Attention Heads: 32\n   Hidden Dimension: 3072\n   Vocabulary Size: 128256\n", "output_type": "stream"}], "execution_count": 7}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 6: Build Neural Network Graph Structure\n# ==============================================================================\n\nprint(\"=\"*70)\nprint(\"ğŸ—ï¸ BUILDING NEURAL NETWORK GRAPH\")\nprint(\"=\"*70)\n\n# Create node data representing neural network components\nnodes_data = []\nedges_data = []\n\n# 1. Input/Output nodes\nnodes_data.append({\"node_id\": 0, \"name\": \"Input\", \"type\": \"input\", \"layer\": -1})\nnodes_data.append({\"node_id\": 1, \"name\": \"Output\", \"type\": \"output\", \"layer\": n_layers + 1})\n\n# 2. Embedding layer\nembedding_id = 2\nnodes_data.append({\n    \"node_id\": embedding_id,\n    \"name\": \"Embedding\",\n    \"type\": \"embedding\",\n    \"layer\": 0,\n    \"parameters\": vocab_size * hidden_dim,\n    \"size_mb\": (vocab_size * hidden_dim * 2) / (1024**2)  # Approx size in MB\n})\n\n# 3. Transformer layers\ncurrent_id = embedding_id + 1\nfor layer in range(1, n_layers + 1):\n    # Layer node\n    layer_id = current_id\n    nodes_data.append({\n        \"node_id\": layer_id,\n        \"name\": f\"Layer_{layer}\",\n        \"type\": \"transformer\",\n        \"layer\": layer,\n        \"parameters\": (4 * hidden_dim**2 + 4 * hidden_dim),  # Approx\n        \"size_mb\": (4 * hidden_dim**2 * 2) / (1024**2) / 4  # Q4_K_M quantization\n    })\n    \n    # Attention heads within layer\n    for head in range(n_heads):\n        head_id = current_id + 1 + head\n        nodes_data.append({\n            \"node_id\": head_id,\n            \"name\": f\"L{layer}_H{head}\",\n            \"type\": \"attention_head\",\n            \"layer\": layer,\n            \"head\": head,\n            \"parameters\": (hidden_dim * hidden_dim // n_heads),\n            \"size_mb\": (hidden_dim * hidden_dim * 2) / (1024**2) / n_heads / 4\n        })\n        \n        # Connect head to its layer\n        edges_data.append({\n            \"source\": layer_id,\n            \"target\": head_id,\n            \"type\": \"contains\",\n            \"weight\": 1.0\n        })\n    \n    current_id = current_id + 1 + n_heads\n\n# 4. Layer Normalization and FFN nodes\nln_id = current_id\nnodes_data.append({\n    \"node_id\": ln_id,\n    \"name\": \"LayerNorm\",\n    \"type\": \"normalization\",\n    \"layer\": \"all\",\n    \"parameters\": 2 * hidden_dim,\n    \"size_mb\": (2 * hidden_dim * 2) / (1024**2)\n})\n\nffn_id = ln_id + 1\nnodes_data.append({\n    \"node_id\": ffn_id,\n    \"name\": \"FeedForward\",\n    \"type\": \"feedforward\",\n    \"layer\": \"all\",\n    \"parameters\": 2 * hidden_dim * 4 * hidden_dim,\n    \"size_mb\": (2 * hidden_dim * 4 * hidden_dim * 2) / (1024**2) / 4\n})\n\n# 5. Connect layers sequentially\nfor i in range(n_layers):\n    source_layer = 3 + i * (n_heads + 1)  # Skip embedding, find each layer\n    target_layer = source_layer + (n_heads + 1) if i < n_layers - 1 else 1  # Output\n    \n    edges_data.append({\n        \"source\": source_layer,\n        \"target\": target_layer,\n        \"type\": \"feeds_into\",\n        \"weight\": 1.0\n    })\n\n# Connect embedding to first layer\nedges_data.append({\n    \"source\": embedding_id,\n    \"target\": 3,\n    \"type\": \"feeds_into\",\n    \"weight\": 1.0\n})\n\n# Connect normalization and FFN to each layer\nfor layer in range(1, n_layers + 1):\n    layer_id = 2 + (layer - 1) * (n_heads + 1) + 1\n    edges_data.append({\n        \"source\": layer_id,\n        \"target\": ln_id,\n        \"type\": \"uses\",\n        \"weight\": 0.5\n    })\n    edges_data.append({\n        \"source\": layer_id,\n        \"target\": ffn_id,\n        \"type\": \"uses\",\n        \"weight\": 0.5\n    })\n\nprint(f\"\\nğŸ“Š Neural Network Graph Built:\")\nprint(f\"   Total Nodes: {len(nodes_data)}\")\nprint(f\"   Total Edges: {len(edges_data)}\")\nprint(f\"   Transformer Layers: {n_layers}\")\nprint(f\"   Attention Heads: {n_layers * n_heads}\")\n\n# Convert to DataFrames\nnodes_df = pd.DataFrame(nodes_data)\nedges_df = pd.DataFrame(edges_data)\n\nprint(\"\\nğŸ“‹ Node Types Distribution:\")\nprint(nodes_df['type'].value_counts())", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:30.203436Z", "iopub.execute_input": "2026-01-23T18:58:30.203714Z", "iopub.status.idle": "2026-01-23T18:58:30.235987Z", "shell.execute_reply.started": "2026-01-23T18:58:30.203690Z", "shell.execute_reply": "2026-01-23T18:58:30.235377Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ—ï¸ BUILDING NEURAL NETWORK GRAPH\n======================================================================\n\nğŸ“Š Neural Network Graph Built:\n   Total Nodes: 929\n   Total Edges: 981\n   Transformer Layers: 28\n   Attention Heads: 896\n\nğŸ“‹ Node Types Distribution:\ntype\nattention_head    896\ntransformer        28\ninput               1\nembedding           1\noutput              1\nnormalization       1\nfeedforward         1\nName: count, dtype: int64\n", "output_type": "stream"}], "execution_count": 8}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 7: Initialize RAPIDS on GPU 1\n# ==============================================================================\n\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\nprint(\"=\"*70)\nprint(\"ğŸ”¥ INITIALIZING RAPIDS ON GPU 1\")\nprint(\"=\"*70)\n\nimport cudf\nimport cupy as cp\nimport cugraph\n\nprint(f\"\\nğŸ“Š RAPIDS GPU Info:\")\ndevice = cp.cuda.Device(0)  # Device 0 in filtered view = actual GPU 1\nprint(f\"   Device: {device.id} (filtered view)\")\nprint(f\"   Actual GPU: 1 (Tesla T4)\")\nprint(f\"   Memory: {device.mem_info[1] / 1e9:.1f} GB free\")\n\nprint(f\"\\nâœ… RAPIDS initialized on GPU 1\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:36.211781Z", "iopub.execute_input": "2026-01-23T18:58:36.212657Z", "iopub.status.idle": "2026-01-23T18:58:36.297725Z", "shell.execute_reply.started": "2026-01-23T18:58:36.212616Z", "shell.execute_reply": "2026-01-23T18:58:36.297074Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ”¥ INITIALIZING RAPIDS ON GPU 1\n======================================================================\n\nğŸ“Š RAPIDS GPU Info:\n   Device: 0 (filtered view)\n   Actual GPU: 1 (Tesla T4)\n   Memory: 15.8 GB free\n\nâœ… RAPIDS initialized on GPU 1\n", "output_type": "stream"}], "execution_count": 9}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 8: GPU-Accelerated Graph Analytics\n# ==============================================================================\n\nprint(\"=\"*70)\nprint(\"ğŸ”¬ GPU-ACCELERATED GRAPH ANALYTICS\")\nprint(\"=\"*70)\n\n# Convert to cuDF for GPU processing\nedges_cudf = cudf.DataFrame(edges_df)\nnodes_cudf = cudf.DataFrame(nodes_df[['node_id']])  # Minimal for graph\n\n# Create cuGraph\nG = cugraph.Graph()\nG.from_cudf_edgelist(edges_cudf, source='source', destination='target', edge_attr='weight')\n\nprint(\"\\nğŸ“Š Graph Statistics:\")\nprint(f\"   Number of vertices: {G.number_of_vertices()}\")\nprint(f\"   Number of edges: {G.number_of_edges()}\")\nprint(f\"   Directed: {G.is_directed()}\")\n\n# PageRank - Identify important components\nprint(\"\\nğŸ“Š PageRank Analysis (Component Importance):\")\npagerank = cugraph.pagerank(G)\npagerank = pagerank.sort_values('pagerank', ascending=False)\n\n# Merge PageRank back to nodes\npagerank_pd = pagerank.to_pandas().rename(columns={'vertex': 'node_id', 'pagerank': 'importance'})\nnodes_df = nodes_df.merge(pagerank_pd, on='node_id', how='left')\nnodes_df['importance'] = nodes_df['importance'].fillna(nodes_df['importance'].mean())\n\n# Betweenness Centrality - Identify critical connections\nprint(\"\\nğŸ“Š Betweenness Centrality (Critical Connections):\")\nbc = cugraph.betweenness_centrality(G)\nbc_pd = bc.to_pandas().rename(columns={'vertex': 'node_id', 'betweenness_centrality': 'centrality'})\nnodes_df = nodes_df.merge(bc_pd, on='node_id', how='left')\nnodes_df['centrality'] = nodes_df['centrality'].fillna(0)\n\n# Degree Centrality\nprint(\"\\nğŸ“Š Degree Centrality (Connectivity):\")\ndegree_df = cudf.DataFrame({\n    'node_id': cudf.Series(range(G.number_of_vertices())),\n})\n\n# Calculate in/out degree\nfor i in range(G.number_of_vertices()):\n    # Simplified degree calculation\n    pass\n\nprint(\"\\nâœ… Graph analytics computed on GPU 1\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:41.463105Z", "iopub.execute_input": "2026-01-23T18:58:41.463396Z", "iopub.status.idle": "2026-01-23T18:58:44.521956Z", "shell.execute_reply.started": "2026-01-23T18:58:41.463375Z", "shell.execute_reply": "2026-01-23T18:58:44.521034Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ”¬ GPU-ACCELERATED GRAPH ANALYTICS\n======================================================================\n\nğŸ“Š Graph Statistics:\n   Number of vertices: 928\n   Number of edges: 981\n   Directed: False\n\nğŸ“Š PageRank Analysis (Component Importance):\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/cugraph/link_analysis/pagerank.py:232: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n  warnings.warn(warning_msg, UserWarning)\n", "output_type": "stream"}, {"name": "stdout", "text": "\nğŸ“Š Betweenness Centrality (Critical Connections):\n\nğŸ“Š Degree Centrality (Connectivity):\n\nâœ… Graph analytics computed on GPU 1\n", "output_type": "stream"}], "execution_count": 10}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 9: Register Graphistry\n# ==============================================================================\n\nprint(\"=\"*70)\nprint(\"ğŸ” REGISTERING GRAPHISTRY\")\nprint(\"=\"*70)\n\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    user_secrets = UserSecretsClient()\n    graphistry_key_id = user_secrets.get_secret(\"Graphistry_Personal_Key_ID\")\n    graphistry_secret = user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n    \n    graphistry.register(\n        api=3,\n        protocol=\"https\",\n        server=\"hub.graphistry.com\",\n        personal_key_id=graphistry_key_id,\n        personal_key_secret=graphistry_secret\n    )\n    print(\"âœ… Graphistry registered successfully\")\nexcept Exception as e:\n    print(f\"âš ï¸ Graphistry registration failed: {e}\")\n    print(\"   Add secrets: Graphistry_Personal_Key_ID, Graphistry_Personal_Secret_Key\")\n    # Continue with offline mode for demonstration\n    graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:50.620522Z", "iopub.execute_input": "2026-01-23T18:58:50.621076Z", "iopub.status.idle": "2026-01-23T18:58:51.486550Z", "shell.execute_reply.started": "2026-01-23T18:58:50.621045Z", "shell.execute_reply": "2026-01-23T18:58:51.485709Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ” REGISTERING GRAPHISTRY\n======================================================================\nâœ… Graphistry registered successfully\n", "output_type": "stream"}], "execution_count": 11}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 10: Create Neural Network Visualization Dashboard\n# ==============================================================================\n\nprint(\"=\"*70)\nprint(\"ğŸ¨ CREATING NEURAL NETWORK VISUALIZATION DASHBOARD\")\nprint(\"=\"*70)\n\n# Prepare enhanced node data\nprint(\"\\nğŸ“Š Preparing visualization data...\")\n\n# Calculate component metrics\nnodes_df['layer_norm'] = nodes_df['layer'].apply(lambda x: x if isinstance(x, int) and x >= 0 else -1)\nnodes_df['size_scaled'] = np.log10(nodes_df.get('size_mb', 1) + 1) * 20\n\n# Color coding by component type\ntype_colors = {\n    'input': '#FF6B6B',        # Red\n    'output': '#4ECDC4',       # Teal\n    'embedding': '#FFD166',    # Yellow\n    'transformer': '#06D6A0',  # Green\n    'attention_head': '#118AB2', # Blue\n    'normalization': '#EF476F', # Pink\n    'feedforward': '#073B4C'   # Dark Blue\n}\n\n# Icon mapping\ntype_icons = {\n    'input': 'sign-in-alt',\n    'output': 'sign-out-alt',\n    'embedding': 'layer-group',\n    'transformer': 'microchip',\n    'attention_head': 'eye',\n    'normalization': 'balance-scale',\n    'feedforward': 'arrows-alt-h'\n}\n\n# Create rich tooltips\ndef create_tooltip(row):\n    tooltip = f\"<b>{row['name']}</b><br>\"\n    tooltip += f\"Type: {row['type']}<br>\"\n    if row['layer'] != 'all' and row['layer'] >= 0:\n        tooltip += f\"Layer: {row['layer']}<br>\"\n    if 'head' in row and not pd.isna(row['head']):\n        tooltip += f\"Head: {int(row['head'])}<br>\"\n    if 'parameters' in row and not pd.isna(row['parameters']):\n        tooltip += f\"Parameters: {row['parameters']:,}<br>\"\n    if 'size_mb' in row and not pd.isna(row['size_mb']):\n        tooltip += f\"Size: {row['size_mb']:.1f} MB<br>\"\n    if 'importance' in row and not pd.isna(row['importance']):\n        tooltip += f\"Importance: {row['importance']:.4f}<br>\"\n    if 'centrality' in row and not pd.isna(row['centrality']):\n        tooltip += f\"Centrality: {row['centrality']:.4f}<br>\"\n    return tooltip\n\nnodes_df['tooltip'] = nodes_df.apply(create_tooltip, axis=1)\n\n# Edge tooltips\nedges_df['edge_tooltip'] = edges_df.apply(\n    lambda row: f\"<b>{row['type']}</b><br>Weight: {row['weight']}\", axis=1\n)\n\nprint(f\"ğŸ“Š Graph Summary:\")\nprint(f\"   Nodes: {len(nodes_df)} neural network components\")\nprint(f\"   Edges: {len(edges_df)} connections\")\nprint(f\"   Component Types: {len(type_colors)} distinct types\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:58:53.017727Z", "iopub.execute_input": "2026-01-23T18:58:53.018292Z", "iopub.status.idle": "2026-01-23T18:58:53.070828Z", "shell.execute_reply.started": "2026-01-23T18:58:53.018264Z", "shell.execute_reply": "2026-01-23T18:58:53.070071Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ¨ CREATING NEURAL NETWORK VISUALIZATION DASHBOARD\n======================================================================\n\nğŸ“Š Preparing visualization data...\nğŸ“Š Graph Summary:\n   Nodes: 929 neural network components\n   Edges: 981 connections\n   Component Types: 7 distinct types\n", "output_type": "stream"}], "execution_count": 12}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 11: SIMPLER VERSION - Create Main Architecture Visualization\n# ==============================================================================\n\nprint(\"\\nğŸ¨ Creating main architecture visualization (simpler version)...\")\n\ntry:\n    # 1. Apply colors directly to DataFrame columns\n    nodes_df['color'] = nodes_df['type'].map(type_colors).fillna('#95A5A6')\n    nodes_df['icon'] = nodes_df['type'].map(type_icons).fillna('circle')\n    \n    # 2. Apply edge colors\n    edge_color_map = {'contains': '#BDC3C7', 'feeds_into': '#3498DB', 'uses': '#E74C3C'}\n    edges_df['edge_color'] = edges_df['type'].map(edge_color_map).fillna('#CCCCCC')\n    \n    # 3. Scale importance for point size (0-1 range)\n    if nodes_df['importance'].max() > nodes_df['importance'].min():\n        nodes_df['point_size'] = 15 + (nodes_df['importance'] - nodes_df['importance'].min()) / \\\n                                 (nodes_df['importance'].max() - nodes_df['importance'].min()) * 65\n    else:\n        nodes_df['point_size'] = 40\n    \n    # 4. Create the graph with direct binding\n    g = graphistry.bind(\n        source='source',\n        destination='target',\n        node='node_id',\n        point_title='tooltip',\n        point_color='color',\n        point_size='point_size',\n        point_icon='icon',\n        edge_title='edge_tooltip',\n        edge_color='edge_color',\n        edge_weight='weight'\n    )\n    \n    # 5. Apply settings\n    g = g.settings(url_params={\n        'play': 0,\n        'pointSize': 2.5,\n        'edgeOpacity': 0.6,\n        'bg': '%23FFFFFF',\n        'strongGravity': 'true',\n        'edgeInfluence': 1.0,\n        'scalingRatio': 10.0\n    })\n    \n    # 6. Create visualization\n    plotter = g.edges(edges_df).nodes(nodes_df)\n    \n    main_url = plotter.plot(\n        render=False,\n        name=f\"GGUF Neural Network Architecture - {MODEL_FILE}\",\n        description=f\"Visualization of {MODEL_FILE} with {n_layers} layers, {n_heads} heads per layer\"\n    )\n    \n    print(f\"\\nğŸš€ Main Visualization Created!\")\n    print(f\"ğŸ”— URL: {main_url}\")\n    \n    from IPython.display import display, HTML\n    display(HTML(\n        f'<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); '\n        f'border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\">'\n        f'<h3 style=\"margin:0 0 10px 0;\">ğŸ§  GGUF Neural Network Architecture</h3>'\n        f'<p style=\"margin:5px 0;\">Interactive visualization of {MODEL_FILE}</p>'\n        f'<a href=\"{main_url}\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; '\n        f'background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; '\n        f'box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸš€ Open Main Visualization</a>'\n        f'</div>'\n    ))\n    \nexcept Exception as e:\n    print(f\"âŒ Visualization error: {e}\")\n    import traceback\n    traceback.print_exc()", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:59:01.055453Z", "iopub.execute_input": "2026-01-23T18:59:01.055749Z", "iopub.status.idle": "2026-01-23T18:59:02.642489Z", "shell.execute_reply.started": "2026-01-23T18:59:01.055724Z", "shell.execute_reply": "2026-01-23T18:59:02.641576Z"}}, "outputs": [{"name": "stdout", "text": "\nğŸ¨ Creating main architecture visualization (simpler version)...\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "\nğŸš€ Main Visualization Created!\nğŸ”— URL: https://hub.graphistry.com/graph/graph.html?dataset=db33bdcae73d4420bc97304709921d57&type=arrow&viztoken=43b3b95a-e6ae-4d67-944d-73b810b7541a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194757&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\"><h3 style=\"margin:0 0 10px 0;\">ğŸ§  GGUF Neural Network Architecture</h3><p style=\"margin:5px 0;\">Interactive visualization of Llama-3.2-3B-Instruct-Q4_K_M.gguf</p><a href=\"https://hub.graphistry.com/graph/graph.html?dataset=db33bdcae73d4420bc97304709921d57&type=arrow&viztoken=43b3b95a-e6ae-4d67-944d-73b810b7541a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194757&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸš€ Open Main Visualization</a></div>"}, "metadata": {}}], "execution_count": 13}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 12: Create Layer-by-Layer Subgraph Visualizations (FIXED)\n# ==============================================================================\n\nprint(\"\\nğŸ” Creating layer-by-layer visualizations...\")\n\nlayer_urls = {}\n\nfor layer_num in range(1, min(n_layers + 1, 6)):  # First 5 layers only\n    # Filter nodes for this layer\n    layer_nodes = nodes_df[\n        (nodes_df['layer'] == layer_num) | \n        (nodes_df['layer'] == 'all') |\n        (nodes_df['name'].str.contains(f'L{layer_num}_'))\n    ].copy()  # Use copy() to avoid SettingWithCopyWarning\n    \n    if len(layer_nodes) > 0:\n        # Scale importance for point size (0-1 range) - same as Step 11\n        if layer_nodes['importance'].max() > layer_nodes['importance'].min():\n            layer_nodes['point_size'] = 20 + (layer_nodes['importance'] - layer_nodes['importance'].min()) / \\\n                                     (layer_nodes['importance'].max() - layer_nodes['importance'].min()) * 40\n        else:\n            layer_nodes['point_size'] = 40\n        \n        # Apply colors and icons\n        layer_nodes['color'] = layer_nodes['type'].map(type_colors).fillna('#95A5A6')\n        layer_nodes['icon'] = layer_nodes['type'].map(type_icons).fillna('circle')\n    \n    layer_node_ids = layer_nodes['node_id'].tolist()\n    \n    # Filter edges connecting these nodes\n    layer_edges = edges_df[\n        edges_df['source'].isin(layer_node_ids) & \n        edges_df['target'].isin(layer_node_ids)\n    ]\n    \n    if len(layer_nodes) > 0 and len(layer_edges) > 0:\n        # Create layer-specific visualization with direct binding like Step 11\n        layer_g = graphistry.bind(\n            source='source',\n            destination='target',\n            node='node_id',\n            point_title='name',\n            point_color='color',\n            point_size='point_size',\n            point_icon='icon'\n        )\n        \n        layer_plotter = layer_g.edges(layer_edges).nodes(layer_nodes)\n        \n        # Apply settings\n        layer_plotter = layer_plotter.settings(url_params={\n            'play': 0,\n            'pointSize': 3.0,\n            'edgeOpacity': 0.7,\n            'bg': '%23F8F9FA',\n            'strongGravity': 'true',\n            'edgeInfluence': 1.0,\n            'scalingRatio': 8.0,\n            'showLabels': True\n        })\n        \n        try:\n            layer_url = layer_plotter.plot(\n                render=False,\n                name=f\"Layer {layer_num} - {MODEL_FILE}\",\n                description=f\"Detailed view of transformer layer {layer_num}\"\n            )\n            layer_urls[f\"Layer {layer_num}\"] = layer_url\n            print(f\"   âœ… Layer {layer_num}: {len(layer_nodes)} nodes, {len(layer_edges)} edges\")\n        except Exception as e:\n            print(f\"   âš ï¸ Layer {layer_num} visualization failed: {e}\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:59:11.933403Z", "iopub.execute_input": "2026-01-23T18:59:11.933688Z", "iopub.status.idle": "2026-01-23T18:59:18.917105Z", "shell.execute_reply.started": "2026-01-23T18:59:11.933665Z", "shell.execute_reply": "2026-01-23T18:59:18.916452Z"}}, "outputs": [{"name": "stdout", "text": "\nğŸ” Creating layer-by-layer visualizations...\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "   âœ… Layer 1: 35 nodes, 34 edges\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "   âœ… Layer 2: 35 nodes, 34 edges\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "   âœ… Layer 3: 35 nodes, 34 edges\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "   âœ… Layer 4: 35 nodes, 34 edges\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "   âœ… Layer 5: 35 nodes, 34 edges\n", "output_type": "stream"}], "execution_count": 14}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 12b: Create Interactive Layer Switcher Visualization\n# ==============================================================================\n\nprint(\"\\nğŸ”„ Creating interactive layer switcher visualization...\")\n\ntry:\n    # Add a 'layer_group' column for filtering\n    nodes_df['layer_group'] = nodes_df['layer'].astype(str)\n    \n    # Create a unified visualization with layer filtering\n    interactive_g = graphistry.bind(\n        source='source',\n        destination='target',\n        node='node_id',\n        point_title='name',\n        point_color='color',\n        point_size='point_size',\n        point_icon='icon',\n        point_label='layer_group'  # Use for filtering\n    )\n    \n    # Create a combined visualization with all layers\n    interactive_plotter = interactive_g.edges(edges_df).nodes(nodes_df)\n    \n    # Add filter controls for layers\n    interactive_plotter = interactive_plotter.settings(url_params={\n        'play': 0,\n        'pointSize': 2.5,\n        'edgeOpacity': 0.6,\n        'bg': '%23FFFFFF',\n        'strongGravity': 'true',\n        'edgeInfluence': 1.0,\n        'scalingRatio': 10.0,\n        'showFilters': 'true',  # Enable filters panel\n        'showLabels': 'true',\n        'sidebarMode': 'full'  # Show full sidebar with filters\n    })\n    \n    interactive_url = interactive_plotter.plot(\n        render=False,\n        name=f\"Interactive Layers - {MODEL_FILE}\",\n        description=f\"Interactive visualization of {MODEL_FILE} with layer filtering\"\n    )\n    \n    print(f\"\\nğŸš€ Interactive Layer Switcher Created!\")\n    print(f\"ğŸ”— URL: {interactive_url}\")\n    \n    from IPython.display import display, HTML\n    display(HTML(\n        f'<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #00b09b 0%, #96c93d 100%); '\n        f'border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\">'\n        f'<h3 style=\"margin:0 0 10px 0;\">ğŸ”€ Interactive Layer Explorer</h3>'\n        f'<p style=\"margin:5px 0;\">Filter layers using the sidebar controls in Graphistry</p>'\n        f'<ul style=\"margin:10px 0 15px 0; padding-left:20px;\">'\n        f'<li>Use the <strong>Filters panel</strong> on the right</li>'\n        f'<li>Filter by <strong>layer_group</strong> to show specific layers</li>'\n        f'<li>Click nodes to see detailed information</li>'\n        f'</ul>'\n        f'<a href=\"{interactive_url}\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; '\n        f'background:white; color:#00b09b; text-decoration:none; border-radius:6px; font-weight:bold; '\n        f'box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸ”€ Open Interactive Explorer</a>'\n        f'</div>'\n    ))\n    \nexcept Exception as e:\n    print(f\"âŒ Interactive visualization error: {e}\")\n    import traceback\n    traceback.print_exc()", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T18:59:22.021827Z", "iopub.execute_input": "2026-01-23T18:59:22.022574Z", "iopub.status.idle": "2026-01-23T18:59:24.621233Z", "shell.execute_reply.started": "2026-01-23T18:59:22.022545Z", "shell.execute_reply": "2026-01-23T18:59:24.620608Z"}}, "outputs": [{"name": "stdout", "text": "\nğŸ”„ Creating interactive layer switcher visualization...\n", "output_type": "stream"}, {"name": "stderr", "text": "/usr/local/lib/python3.12/dist-packages/graphistry/util.py:241: RuntimeWarning: Coerced mixed-type columns to string for Arrow conversion: ['layer']. Convert explicitly before plot() for better control.\n  warnings.warn(RuntimeWarning(msg))\n", "output_type": "stream"}, {"name": "stdout", "text": "\nğŸš€ Interactive Layer Switcher Created!\nğŸ”— URL: https://hub.graphistry.com/graph/graph.html?dataset=0b3fa715857d463cb9bf3f4ceedbc86a&type=arrow&viztoken=167362cd-161e-4fef-922f-b332970f5628&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194779&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0&showFilters=true&showLabels=true&sidebarMode=full\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #00b09b 0%, #96c93d 100%); border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\"><h3 style=\"margin:0 0 10px 0;\">ğŸ”€ Interactive Layer Explorer</h3><p style=\"margin:5px 0;\">Filter layers using the sidebar controls in Graphistry</p><ul style=\"margin:10px 0 15px 0; padding-left:20px;\"><li>Use the <strong>Filters panel</strong> on the right</li><li>Filter by <strong>layer_group</strong> to show specific layers</li><li>Click nodes to see detailed information</li></ul><a href=\"https://hub.graphistry.com/graph/graph.html?dataset=0b3fa715857d463cb9bf3f4ceedbc86a&type=arrow&viztoken=167362cd-161e-4fef-922f-b332970f5628&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194779&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0&showFilters=true&showLabels=true&sidebarMode=full\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; background:white; color:#00b09b; text-decoration:none; border-radius:6px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸ”€ Open Interactive Explorer</a></div>"}, "metadata": {}}], "execution_count": 15}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 13: Create Attention Head Visualization (FIXED)\n# ==============================================================================\n\nprint(\"\\nğŸ‘ï¸ Creating attention head visualization...\")\n\n# Focus on attention heads\nattention_nodes = nodes_df[nodes_df['type'] == 'attention_head']\nif len(attention_nodes) > 0:\n    # Get first layer's attention heads\n    first_layer_heads = attention_nodes[attention_nodes['layer'] == 1].copy()\n    \n    if len(first_layer_heads) > 0:\n        # Find the layer node ID for layer 1\n        # In your graph, layer nodes have type 'transformer' and layer = 1\n        layer_1_node = nodes_df[(nodes_df['type'] == 'transformer') & (nodes_df['layer'] == 1)]\n        \n        if len(layer_1_node) > 0:\n            layer_1_id = layer_1_node.iloc[0]['node_id']\n            print(f\"   Found Layer 1 node ID: {layer_1_id}\")\n        else:\n            # If not found, use the first node that contains \"Layer_1\" in name\n            layer_1_node = nodes_df[nodes_df['name'].str.contains('Layer_1')]\n            if len(layer_1_node) > 0:\n                layer_1_id = layer_1_node.iloc[0]['node_id']\n                print(f\"   Found Layer 1 node ID (by name): {layer_1_id}\")\n            else:\n                print(\"   âš ï¸ Could not find Layer 1 node\")\n                layer_1_id = None\n        \n        # Pre-process data in DataFrame\n        if len(first_layer_heads['head'].unique()) > 1:\n            # Create a continuous color mapping for heads\n            unique_heads = sorted(first_layer_heads['head'].unique())\n            head_palette = ['#FF6B6B', '#4ECDC4', '#FFD166', '#95E1D3', '#F38181', '#A8D8EA', \n                           '#AA96DA', '#FCBAD3', '#FFFFD2', '#A8E6CF', '#DCEDC1', '#FFD3B6',\n                           '#FFAAA5', '#FF8B94', '#CCF6C8', '#F9F3DF', '#CDF0EA', '#FAEEE7']\n            \n            # Map head numbers to colors\n            head_color_map = {}\n            for i, head_num in enumerate(unique_heads):\n                color_idx = i % len(head_palette)\n                head_color_map[head_num] = head_palette[color_idx]\n            \n            first_layer_heads['color'] = first_layer_heads['head'].map(head_color_map)\n        else:\n            first_layer_heads['color'] = '#667eea'  # Default color\n        \n        # Scale importance for point size\n        if first_layer_heads['importance'].max() > first_layer_heads['importance'].min():\n            first_layer_heads['point_size'] = 25 + (\n                (first_layer_heads['importance'] - first_layer_heads['importance'].min()) / \n                (first_layer_heads['importance'].max() - first_layer_heads['importance'].min()) * 25\n            )\n        else:\n            first_layer_heads['point_size'] = 40\n        \n        # Add tooltip\n        first_layer_heads['tooltip'] = first_layer_heads.apply(\n            lambda row: f\"<b>Head {int(row['head'])}</b><br>\"\n                       f\"Layer: {row['layer']}<br>\"\n                       f\"Importance: {row['importance']:.4f}<br>\"\n                       f\"Parameters: ~{row.get('parameters', 'N/A'):,}\", \n            axis=1\n        )\n        \n        head_ids = first_layer_heads['node_id'].tolist()\n        \n        # Find edges between these heads and their layer\n        if layer_1_id:\n            # Look for edges where attention heads are connected to their layer\n            head_edges = edges_df[\n                ((edges_df['source'].isin(head_ids)) & (edges_df['target'] == layer_1_id)) |\n                ((edges_df['target'].isin(head_ids)) & (edges_df['source'] == layer_1_id)) |\n                ((edges_df['source'].isin(head_ids)) & edges_df['target'].isin(head_ids))  # Connections between heads\n            ]\n            \n            if len(head_edges) == 0:\n                print(\"   âš ï¸ No edges found between attention heads and layer\")\n                print(\"   Creating artificial edges for visualization...\")\n                \n                # Create artificial edges connecting heads to layer\n                artificial_edges = []\n                for head_id in head_ids:\n                    # Connect each head to the layer\n                    artificial_edges.append({\n                        'source': layer_1_id,\n                        'target': head_id,\n                        'type': 'contains',\n                        'weight': 1.0,\n                        'edge_tooltip': f'Layer 1 â†’ Head {head_ids.index(head_id)}'\n                    })\n                    \n                    # Connect heads in a ring for better visualization\n                    if len(head_ids) > 1:\n                        next_head_idx = (head_ids.index(head_id) + 1) % len(head_ids)\n                        artificial_edges.append({\n                            'source': head_id,\n                            'target': head_ids[next_head_idx],\n                            'type': 'attention_flow',\n                            'weight': 0.3,\n                            'edge_tooltip': f'Attention flow between heads'\n                        })\n                \n                head_edges = pd.DataFrame(artificial_edges)\n                print(f\"   Created {len(head_edges)} artificial edges\")\n        else:\n            print(\"   âš ï¸ No layer ID found, showing heads without connections\")\n            head_edges = pd.DataFrame(columns=edges_df.columns)\n        \n        # Add the layer node to the visualization\n        if layer_1_id:\n            layer_node_data = layer_1_node.copy()\n            layer_node_data['color'] = '#06D6A0'  # Green for transformer\n            layer_node_data['point_size'] = 50\n            layer_node_data['tooltip'] = f\"<b>Layer 1</b><br>Type: transformer<br>Parameters: ~{layer_node_data.iloc[0].get('parameters', 'N/A'):,}\"\n            \n            # Combine layer node with heads\n            all_nodes = pd.concat([first_layer_heads, layer_node_data], ignore_index=True)\n        else:\n            all_nodes = first_layer_heads\n        \n        heads_g = graphistry.bind(\n            source='source',\n            destination='target',\n            node='node_id',\n            point_title='tooltip',\n            point_color='color',\n            point_size='point_size',\n            point_label='name'\n        )\n        \n        heads_plotter = heads_g.edges(head_edges).nodes(all_nodes)\n        \n        # Apply settings\n        heads_plotter = heads_plotter.settings(url_params={\n            'play': 0,\n            'pointSize': 3.5,\n            'edgeOpacity': 0.8,\n            'bg': '%23FFFFFF',\n            'layout': 'concentric',\n            'strongGravity': 'true',\n            'edgeInfluence': 1.0,\n            'scalingRatio': 6.0,\n            'showLabels': 'true',\n            'gravity': 0.1,\n            'linkDistance': 100\n        })\n        \n        try:\n            heads_url = heads_plotter.plot(\n                render=False,\n                name=f\"Attention Heads - {MODEL_FILE}\",\n                description=f\"Visualization of {len(first_layer_heads)} attention heads in layer 1\"\n            )\n            layer_urls[\"Attention Heads\"] = heads_url\n            print(f\"   âœ… Attention Heads: {len(first_layer_heads)} heads visualized\")\n            print(f\"   ğŸ”— URL: {heads_url}\")\n\n            from IPython.display import display, HTML\n            display(HTML(\n                f'<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #FF6B6B 0%, #FFD166 100%); '\n                f'border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\">'\n                f'<h3 style=\"margin:0 0 10px 0;\">ğŸ‘ï¸ Attention Heads Visualization</h3>'\n                f'<p style=\"margin:5px 0;\">Interactive visualization of {len(first_layer_heads)} attention heads in Layer 1</p>'\n                f'<ul style=\"margin:10px 0 15px 0; padding-left:20px;\">'\n                f'<li><strong>Layer 1</strong>: {len(first_layer_heads)} attention heads</li>'\n                f'<li>Color-coded by head number</li>'\n                f'<li>Central transformer layer node in green</li>'\n                f'</ul>'\n                f'<a href=\"{heads_url}\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; '\n                f'background:white; color:#FF6B6B; text-decoration:none; border-radius:6px; font-weight:bold; '\n                f'box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸ‘ï¸ Open Attention Heads Visualization</a>'\n                f'</div>'\n            ))\n        except Exception as e:\n            print(f\"   âš ï¸ Attention heads visualization failed: {e}\")\n            import traceback\n            traceback.print_exc()\nelse:\n    print(\"   âš ï¸ No attention head nodes found in the data\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T19:31:44.731031Z", "iopub.execute_input": "2026-01-23T19:31:44.731689Z", "iopub.status.idle": "2026-01-23T19:31:46.193809Z", "shell.execute_reply.started": "2026-01-23T19:31:44.731660Z", "shell.execute_reply": "2026-01-23T19:31:46.193223Z"}}, "outputs": [{"name": "stdout", "text": "\nğŸ‘ï¸ Creating attention head visualization...\n   Found Layer 1 node ID: 3\n   âœ… Attention Heads: 32 heads visualized\n   ğŸ”— URL: https://hub.graphistry.com/graph/graph.html?dataset=24da5c1158324e69940716b6d95e9fe5&type=arrow&viztoken=28009142-f96e-4e3a-b2ed-ed8a058575bd&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769196721&info=true&play=0&pointSize=3.5&edgeOpacity=0.8&bg=%23FFFFFF&layout=concentric&strongGravity=true&edgeInfluence=1.0&scalingRatio=6.0&showLabels=true&gravity=0.1&linkDistance=100\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #FF6B6B 0%, #FFD166 100%); border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\"><h3 style=\"margin:0 0 10px 0;\">ğŸ‘ï¸ Attention Heads Visualization</h3><p style=\"margin:5px 0;\">Interactive visualization of 32 attention heads in Layer 1</p><ul style=\"margin:10px 0 15px 0; padding-left:20px;\"><li><strong>Layer 1</strong>: 32 attention heads</li><li>Color-coded by head number</li><li>Central transformer layer node in green</li></ul><a href=\"https://hub.graphistry.com/graph/graph.html?dataset=24da5c1158324e69940716b6d95e9fe5&type=arrow&viztoken=28009142-f96e-4e3a-b2ed-ed8a058575bd&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769196721&info=true&play=0&pointSize=3.5&edgeOpacity=0.8&bg=%23FFFFFF&layout=concentric&strongGravity=true&edgeInfluence=1.0&scalingRatio=6.0&showLabels=true&gravity=0.1&linkDistance=100\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; background:white; color:#FF6B6B; text-decoration:none; border-radius:6px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸ‘ï¸ Open Attention Heads Visualization</a></div>"}, "metadata": {}}], "execution_count": 24}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 13b: Create and Display Attention Head Dashboard (FIXED for Kaggle)\n# ==============================================================================\n\nprint(\"\\nğŸ“Š Creating attention head dashboard...\")\n\ntry:\n    # Check if we have attention heads\n    if len(attention_nodes) > 0:\n        # Calculate statistics\n        total_heads = len(attention_nodes)\n        head_layers = attention_nodes['layer'].nunique()\n        avg_heads_per_layer = total_heads / head_layers if head_layers > 0 else 0\n        max_importance = attention_nodes['importance'].max() if total_heads > 0 else 0\n        \n        # Create a simpler HTML dashboard that can be displayed inline\n        dashboard_html = f'''\n        <!DOCTYPE html>\n        <html>\n        <head>\n            <style>\n                body {{\n                    font-family: Arial, sans-serif;\n                    margin: 20px;\n                    background: #f5f7fa;\n                    color: #333;\n                }}\n                .dashboard {{\n                    max-width: 1200px;\n                    margin: 0 auto;\n                }}\n                .header {{\n                    background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);\n                    color: white;\n                    padding: 25px;\n                    border-radius: 12px;\n                    margin-bottom: 25px;\n                    text-align: center;\n                }}\n                .stats-container {{\n                    display: grid;\n                    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n                    gap: 20px;\n                    margin-bottom: 30px;\n                }}\n                .stat-card {{\n                    background: white;\n                    padding: 20px;\n                    border-radius: 10px;\n                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n                    text-align: center;\n                }}\n                .stat-value {{\n                    font-size: 36px;\n                    font-weight: bold;\n                    color: #2c5364;\n                    margin: 10px 0;\n                }}\n                .stat-label {{\n                    color: #666;\n                    font-size: 14px;\n                    text-transform: uppercase;\n                }}\n                .btn-container {{\n                    display: grid;\n                    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n                    gap: 15px;\n                    margin: 25px 0;\n                }}\n                .btn {{\n                    display: block;\n                    padding: 18px;\n                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n                    color: white;\n                    text-decoration: none;\n                    border-radius: 8px;\n                    font-weight: bold;\n                    text-align: center;\n                    font-size: 16px;\n                    transition: transform 0.3s;\n                }}\n                .btn:hover {{\n                    transform: translateY(-2px);\n                    box-shadow: 0 6px 12px rgba(0,0,0,0.15);\n                }}\n                .btn.attention {{\n                    background: linear-gradient(135deg, #FF6B6B 0%, #FFD166 100%);\n                }}\n                .btn.full {{\n                    background: linear-gradient(135deg, #00b09b 0%, #96c93d 100%);\n                }}\n                .info-box {{\n                    background: #e8f4fc;\n                    border-left: 4px solid #4ECDC4;\n                    padding: 15px;\n                    margin: 20px 0;\n                    border-radius: 0 8px 8px 0;\n                }}\n                .color-legend {{\n                    display: flex;\n                    flex-wrap: wrap;\n                    gap: 15px;\n                    margin: 15px 0;\n                    padding: 15px;\n                    background: white;\n                    border-radius: 8px;\n                    border: 1px solid #eee;\n                }}\n                .color-item {{\n                    display: flex;\n                    align-items: center;\n                    gap: 8px;\n                }}\n                .color-dot {{\n                    width: 16px;\n                    height: 16px;\n                    border-radius: 50%;\n                }}\n                .layer-grid {{\n                    display: grid;\n                    grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));\n                    gap: 10px;\n                    margin: 20px 0;\n                }}\n                .layer-btn {{\n                    padding: 12px;\n                    background: #f8f9fa;\n                    border: 1px solid #dee2e6;\n                    border-radius: 6px;\n                    text-align: center;\n                    text-decoration: none;\n                    color: #495057;\n                    transition: all 0.2s;\n                }}\n                .layer-btn:hover {{\n                    background: #667eea;\n                    color: white;\n                    border-color: #667eea;\n                }}\n            </style>\n        </head>\n        <body>\n            <div class=\"dashboard\">\n                <div class=\"header\">\n                    <h1 style=\"margin: 0; font-size: 32px;\">ğŸ§  Attention Head Dashboard</h1>\n                    <p style=\"margin: 10px 0 0 0; font-size: 16px; opacity: 0.9;\">\n                        Model: {MODEL_FILE} â€¢ {pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n                    </p>\n                </div>\n                \n                <div class=\"stats-container\">\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Total Attention Heads</div>\n                        <div class=\"stat-value\">{total_heads}</div>\n                        <p>Across all layers</p>\n                    </div>\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Layers with Heads</div>\n                        <div class=\"stat-value\">{head_layers}</div>\n                        <p>Layers containing attention</p>\n                    </div>\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Avg Heads/Layer</div>\n                        <div class=\"stat-value\">{avg_heads_per_layer:.1f}</div>\n                        <p>Average per layer</p>\n                    </div>\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Max Importance</div>\n                        <div class=\"stat-value\">{max_importance:.3f}</div>\n                        <p>Highest attention weight</p>\n                    </div>\n                </div>\n                \n                <div class=\"info-box\">\n                    <p><strong>ğŸ“Š Dashboard Overview:</strong> This dashboard provides insights into the attention mechanism of your transformer model. Attention heads are the core components that allow the model to focus on different parts of the input sequence.</p>\n                </div>\n                \n                <h2>ğŸ”— Quick Links</h2>\n                <div class=\"btn-container\">\n                    <a href=\"{heads_url}\" class=\"btn attention\" target=\"_blank\">\n                        ğŸ¯ Attention Heads Visualization\n                    </a>\n                    <a href=\"{main_url}\" class=\"btn\" target=\"_blank\">\n                        ğŸŒ Full Architecture\n                    </a>\n        '''\n        \n        # Add interactive URL if available\n        if 'interactive_url' in locals():\n            dashboard_html += f'''\n                    <a href=\"{interactive_url}\" class=\"btn full\" target=\"_blank\">\n                        ğŸ”„ Interactive Explorer\n                    </a>\n            '''\n        \n        dashboard_html += '''\n                </div>\n                \n                <h2>ğŸ¨ Layer Visualizations</h2>\n                <div class=\"layer-grid\">\n        '''\n        \n        # Add layer buttons (first 5)\n        for i in range(1, min(6, n_layers + 1)):\n            if f\"Layer {i}\" in layer_urls:\n                dashboard_html += f'''\n                    <a href=\"{layer_urls[f'Layer {i}']}\" class=\"layer-btn\" target=\"_blank\">\n                        Layer {i}\n                    </a>\n                '''\n        \n        dashboard_html += '''\n                </div>\n                \n                <div class=\"info-box\">\n                    <p><strong>ğŸ’¡ How to use:</strong> Click on any visualization link to open it in a new tab. Use the Graphistry interface to explore, zoom, and interact with the neural network structure.</p>\n                </div>\n            </div>\n        </body>\n        </html>\n        '''\n        \n        # Display the dashboard directly in the notebook\n        from IPython.display import display, HTML\n        display(HTML(dashboard_html))\n        \n        # Also save to file\n        attention_dashboard_path = '/kaggle/working/attention_dashboard.html'\n        with open(attention_dashboard_path, 'w') as f:\n            f.write(dashboard_html)\n        \n        print(f\"\\nâœ… Dashboard created and displayed above\")\n        print(f\"ğŸ“ Dashboard also saved to: {attention_dashboard_path}\")\n        \n        # Provide direct download link\n        print(f\"\\nğŸ“¥ To download the dashboard HTML file:\")\n        print(f\"   1. Click on the 'Data' tab in Kaggle\")\n        print(f\"   2. Navigate to '/kaggle/working/'\")\n        print(f\"   3. Download 'attention_dashboard.html'\")\n        \n    else:\n        print(\"   âš ï¸ No attention head nodes available for dashboard creation\")\n        \nexcept Exception as e:\n    print(f\"âŒ Dashboard creation error: {e}\")\n    import traceback\n    traceback.print_exc()", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T19:02:46.620513Z", "iopub.execute_input": "2026-01-23T19:02:46.621278Z", "iopub.status.idle": "2026-01-23T19:02:46.637014Z", "shell.execute_reply.started": "2026-01-23T19:02:46.621241Z", "shell.execute_reply": "2026-01-23T19:02:46.636140Z"}}, "outputs": [{"name": "stdout", "text": "\nğŸ“Š Creating attention head dashboard...\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "\n        <!DOCTYPE html>\n        <html>\n        <head>\n            <style>\n                body {\n                    font-family: Arial, sans-serif;\n                    margin: 20px;\n                    background: #f5f7fa;\n                    color: #333;\n                }\n                .dashboard {\n                    max-width: 1200px;\n                    margin: 0 auto;\n                }\n                .header {\n                    background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);\n                    color: white;\n                    padding: 25px;\n                    border-radius: 12px;\n                    margin-bottom: 25px;\n                    text-align: center;\n                }\n                .stats-container {\n                    display: grid;\n                    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n                    gap: 20px;\n                    margin-bottom: 30px;\n                }\n                .stat-card {\n                    background: white;\n                    padding: 20px;\n                    border-radius: 10px;\n                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n                    text-align: center;\n                }\n                .stat-value {\n                    font-size: 36px;\n                    font-weight: bold;\n                    color: #2c5364;\n                    margin: 10px 0;\n                }\n                .stat-label {\n                    color: #666;\n                    font-size: 14px;\n                    text-transform: uppercase;\n                }\n                .btn-container {\n                    display: grid;\n                    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n                    gap: 15px;\n                    margin: 25px 0;\n                }\n                .btn {\n                    display: block;\n                    padding: 18px;\n                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n                    color: white;\n                    text-decoration: none;\n                    border-radius: 8px;\n                    font-weight: bold;\n                    text-align: center;\n                    font-size: 16px;\n                    transition: transform 0.3s;\n                }\n                .btn:hover {\n                    transform: translateY(-2px);\n                    box-shadow: 0 6px 12px rgba(0,0,0,0.15);\n                }\n                .btn.attention {\n                    background: linear-gradient(135deg, #FF6B6B 0%, #FFD166 100%);\n                }\n                .btn.full {\n                    background: linear-gradient(135deg, #00b09b 0%, #96c93d 100%);\n                }\n                .info-box {\n                    background: #e8f4fc;\n                    border-left: 4px solid #4ECDC4;\n                    padding: 15px;\n                    margin: 20px 0;\n                    border-radius: 0 8px 8px 0;\n                }\n                .color-legend {\n                    display: flex;\n                    flex-wrap: wrap;\n                    gap: 15px;\n                    margin: 15px 0;\n                    padding: 15px;\n                    background: white;\n                    border-radius: 8px;\n                    border: 1px solid #eee;\n                }\n                .color-item {\n                    display: flex;\n                    align-items: center;\n                    gap: 8px;\n                }\n                .color-dot {\n                    width: 16px;\n                    height: 16px;\n                    border-radius: 50%;\n                }\n                .layer-grid {\n                    display: grid;\n                    grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));\n                    gap: 10px;\n                    margin: 20px 0;\n                }\n                .layer-btn {\n                    padding: 12px;\n                    background: #f8f9fa;\n                    border: 1px solid #dee2e6;\n                    border-radius: 6px;\n                    text-align: center;\n                    text-decoration: none;\n                    color: #495057;\n                    transition: all 0.2s;\n                }\n                .layer-btn:hover {\n                    background: #667eea;\n                    color: white;\n                    border-color: #667eea;\n                }\n            </style>\n        </head>\n        <body>\n            <div class=\"dashboard\">\n                <div class=\"header\">\n                    <h1 style=\"margin: 0; font-size: 32px;\">ğŸ§  Attention Head Dashboard</h1>\n                    <p style=\"margin: 10px 0 0 0; font-size: 16px; opacity: 0.9;\">\n                        Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf â€¢ 2026-01-23 19:02:46\n                    </p>\n                </div>\n                \n                <div class=\"stats-container\">\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Total Attention Heads</div>\n                        <div class=\"stat-value\">896</div>\n                        <p>Across all layers</p>\n                    </div>\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Layers with Heads</div>\n                        <div class=\"stat-value\">28</div>\n                        <p>Layers containing attention</p>\n                    </div>\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Avg Heads/Layer</div>\n                        <div class=\"stat-value\">32.0</div>\n                        <p>Average per layer</p>\n                    </div>\n                    <div class=\"stat-card\">\n                        <div class=\"stat-label\">Max Importance</div>\n                        <div class=\"stat-value\">0.001</div>\n                        <p>Highest attention weight</p>\n                    </div>\n                </div>\n                \n                <div class=\"info-box\">\n                    <p><strong>ğŸ“Š Dashboard Overview:</strong> This dashboard provides insights into the attention mechanism of your transformer model. Attention heads are the core components that allow the model to focus on different parts of the input sequence.</p>\n                </div>\n                \n                <h2>ğŸ”— Quick Links</h2>\n                <div class=\"btn-container\">\n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=e63c4f5d08194f138c3ca9b2595d2bb5&type=arrow&viztoken=e464b74b-8f93-4a04-a20b-01c11dfd711a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194953&info=true&play=0&pointSize=3.5&edgeOpacity=0.8&bg=%23FFFFFF&layout=concentric&strongGravity=true&edgeInfluence=1.0&scalingRatio=6.0&showLabels=true&gravity=0.1&linkDistance=100\" class=\"btn attention\" target=\"_blank\">\n                        ğŸ¯ Attention Heads Visualization\n                    </a>\n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=db33bdcae73d4420bc97304709921d57&type=arrow&viztoken=43b3b95a-e6ae-4d67-944d-73b810b7541a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194757&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0\" class=\"btn\" target=\"_blank\">\n                        ğŸŒ Full Architecture\n                    </a>\n        \n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=0b3fa715857d463cb9bf3f4ceedbc86a&type=arrow&viztoken=167362cd-161e-4fef-922f-b332970f5628&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194779&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0&showFilters=true&showLabels=true&sidebarMode=full\" class=\"btn full\" target=\"_blank\">\n                        ğŸ”„ Interactive Explorer\n                    </a>\n            \n                </div>\n                \n                <h2>ğŸ¨ Layer Visualizations</h2>\n                <div class=\"layer-grid\">\n        \n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=378abb6cf1ca4bdea5c43d02c302630c&type=arrow&viztoken=4c1e627d-6def-4ca7-be65-42ee999f54f8&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194768&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" class=\"layer-btn\" target=\"_blank\">\n                        Layer 1\n                    </a>\n                \n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=d3a3b0d045aa4246a097de6180160245&type=arrow&viztoken=227e1290-9768-41b1-970f-f4b80193a04f&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194769&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" class=\"layer-btn\" target=\"_blank\">\n                        Layer 2\n                    </a>\n                \n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=789b08576d4d4e5c808f0e5e2f8ec578&type=arrow&viztoken=d12a58d1-44d0-4e59-b0be-a8538487a6f0&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194771&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" class=\"layer-btn\" target=\"_blank\">\n                        Layer 3\n                    </a>\n                \n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=b4f0efd9e3c14723bbe83c93fb3cbb65&type=arrow&viztoken=111a0dc0-3b11-4ea3-a432-a0d57b0bd746&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194772&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" class=\"layer-btn\" target=\"_blank\">\n                        Layer 4\n                    </a>\n                \n                    <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=07ea42d536e04f91a5e785ca86b6160e&type=arrow&viztoken=bcbacb06-1cce-4dc5-9567-e1856458ff23&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194773&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" class=\"layer-btn\" target=\"_blank\">\n                        Layer 5\n                    </a>\n                \n                </div>\n                \n                <div class=\"info-box\">\n                    <p><strong>ğŸ’¡ How to use:</strong> Click on any visualization link to open it in a new tab. Use the Graphistry interface to explore, zoom, and interact with the neural network structure.</p>\n                </div>\n            </div>\n        </body>\n        </html>\n        "}, "metadata": {}}, {"name": "stdout", "text": "\nâœ… Dashboard created and displayed above\nğŸ“ Dashboard also saved to: /kaggle/working/attention_dashboard.html\n\nğŸ“¥ To download the dashboard HTML file:\n   1. Click on the 'Data' tab in Kaggle\n   2. Navigate to '/kaggle/working/'\n   3. Download 'attention_dashboard.html'\n", "output_type": "stream"}], "execution_count": 18}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 14: Create Quantization Block Visualization (FIXED v2)\n# ==============================================================================\n\nprint(\"\\nâš–ï¸ Creating quantization block visualization...\")\n\n# Simulate quantization blocks (Q4_K_M has specific block structure)\nquantization_blocks = []\nblock_id = 1000  # Starting ID for quantization blocks\n\n# GGUF Q4_K_M uses blocks of weights\nfor layer in range(1, n_layers + 1):\n    for block in range(4):  # 4 quantization blocks per layer (simplified)\n        block_node = {\n            'node_id': block_id,\n            'name': f'QBlock_L{layer}_{block}',\n            'type': 'quantization',\n            'layer': layer,\n            'block': block,\n            'parameters': hidden_dim * hidden_dim // 16,  # Approx for Q4\n            'size_mb': (hidden_dim * hidden_dim * 0.5) / (1024**2)  # 0.5 bytes per param for Q4\n        }\n        quantization_blocks.append(block_node)\n        block_id += 1\n\nif quantization_blocks:\n    quant_df = pd.DataFrame(quantization_blocks).copy()  # Use copy()\n    \n    # Pre-process data in DataFrame\n    # Create color mapping for layers\n    unique_layers = sorted(quant_df['layer'].unique())\n    layer_palette = ['#FF6B6B', '#4ECDC4', '#FFD166', '#95E1D3', '#F38181', '#A8D8EA', '#C86B85', '#6B8CFF']\n    \n    # Map layer numbers to colors\n    layer_color_map = {}\n    for i, layer_num in enumerate(unique_layers):\n        color_idx = i % len(layer_palette)\n        layer_color_map[layer_num] = layer_palette[color_idx]\n    \n    quant_df['color'] = quant_df['layer'].map(layer_color_map)\n    \n    # Scale size_mb for point size\n    if quant_df['size_mb'].max() > quant_df['size_mb'].min():\n        quant_df['point_size'] = 20 + (\n            (quant_df['size_mb'] - quant_df['size_mb'].min()) / \n            (quant_df['size_mb'].max() - quant_df['size_mb'].min()) * 40\n        )\n    else:\n        quant_df['point_size'] = 40\n    \n    # Add tooltip\n    quant_df['tooltip'] = quant_df.apply(\n        lambda row: f\"Quant Block L{row['layer']}.{row['block']}<br>\"\n                   f\"Size: {row['size_mb']:.2f} MB<br>\"\n                   f\"Params: {row['parameters']:,}<br>\"\n                   f\"Type: {row['type']}\", \n        axis=1\n    )\n    \n    # Connect quantization blocks to their layers\n    quant_edges = []\n    for _, block in quant_df.iterrows():\n        # Try to find the corresponding layer node\n        # Look for layer nodes (assuming they have IDs like 'L1', 'L2' or numeric IDs)\n        layer_pattern = f\"L{int(block['layer'])}\"\n        layer_nodes = nodes_df[nodes_df['name'].str.contains(layer_pattern, na=False)]\n        \n        if len(layer_nodes) > 0:\n            layer_id = layer_nodes.iloc[0]['node_id']\n        else:\n            # Fallback: use layer number as ID\n            layer_id = int(block['layer'])\n        \n        quant_edges.append({\n            'source': layer_id,\n            'target': int(block['node_id']),\n            'type': 'quantizes',\n            'weight': 0.8,\n            'edge_tooltip': f\"Layer {int(block['layer'])} â†’ Quant Block {int(block['block'])}\",\n            'edge_color': '#9B59B6'  # Add color as column in edges DataFrame\n        })\n    \n    quant_edges_df = pd.DataFrame(quant_edges)\n    \n    # Create visualization - IMPORTANT: edge_color now refers to column name\n    quant_g = graphistry.bind(\n        source='source',\n        destination='target',\n        node='node_id',\n        point_title='tooltip',\n        point_color='color',\n        point_size='point_size',\n        point_label='name',\n        edge_title='edge_tooltip',\n        edge_color='edge_color'  # This now refers to the column we added\n    )\n    \n    quant_plotter = quant_g.edges(quant_edges_df).nodes(quant_df)\n    \n    # Apply settings\n    quant_plotter = quant_plotter.settings(url_params={\n        'play': 0,\n        'pointSize': 3.0,\n        'edgeOpacity': 0.6,\n        'bg': '%23F0F4FF',\n        'layout': 'grid',\n        'strongGravity': 'true',\n        'edgeInfluence': 1.2,\n        'scalingRatio': 5.0,\n        'showLabels': 'true'\n    })\n    \n    try:\n        quant_url = quant_plotter.plot(\n            render=False,\n            name=f\"Quantization Blocks - {MODEL_FILE}\",\n            description=f\"Q4_K_M quantization blocks across {n_layers} layers\"\n        )\n        layer_urls[\"Quantization Blocks\"] = quant_url\n        print(f\"   âœ… Quantization Blocks: {len(quant_df)} blocks visualized\")\n        print(f\"   ğŸ“Š Block size range: {quant_df['size_mb'].min():.2f} - {quant_df['size_mb'].max():.2f} MB per block\")\n        print(f\"   ğŸ”— Total quantization blocks: {len(quant_df)} across {n_layers} layers\")\n    except Exception as e:\n        print(f\"   âš ï¸ Quantization visualization failed: {e}\")\n        import traceback\n        traceback.print_exc()\nelse:\n    print(\"   âš ï¸ No quantization blocks created\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T19:07:18.732385Z", "iopub.execute_input": "2026-01-23T19:07:18.733184Z", "iopub.status.idle": "2026-01-23T19:07:20.234727Z", "shell.execute_reply.started": "2026-01-23T19:07:18.733137Z", "shell.execute_reply": "2026-01-23T19:07:20.234104Z"}}, "outputs": [{"name": "stdout", "text": "\nâš–ï¸ Creating quantization block visualization...\n   âœ… Quantization Blocks: 112 blocks visualized\n   ğŸ“Š Block size range: 4.50 - 4.50 MB per block\n   ğŸ”— Total quantization blocks: 112 across 28 layers\n", "output_type": "stream"}], "execution_count": 19}, {"cell_type": "code", "source": "# ==============================================================================\n# Step 15: Create Interactive Dashboard (FIXED)\n# ==============================================================================\n\nprint(\"=\"*70)\nprint(\"ğŸ“Š CREATING INTERACTIVE DASHBOARD\")\nprint(\"=\"*70)\n\n# Collect all visualization URLs\nall_visualizations = {\"Main Architecture\": main_url}\nall_visualizations.update(layer_urls)\n\n# Add quantization visualization if it exists\nif \"Quantization Blocks\" in layer_urls:\n    all_visualizations[\"Quantization Blocks\"] = layer_urls[\"Quantization Blocks\"]\n\n# Count attention heads\nattention_heads_count = len(nodes_df[nodes_df['type'] == 'attention_head']) if 'nodes_df' in locals() else 0\ntotal_nodes = len(nodes_df) if 'nodes_df' in locals() else 0\ntotal_edges = len(edges_df) if 'edges_df' in locals() else 0\n\n# Define description function\ndef get_viz_description(viz_name):\n    descriptions = {\n        \"Main Architecture\": \"Complete overview of the entire neural network architecture with all layers and connections.\",\n        \"Interactive Explorer\": \"Filter and explore different components interactively with sidebar controls.\",\n        \"Attention Heads\": \"Visualization of multi-head attention mechanisms colored by head number.\",\n        \"Quantization Blocks\": \"Q4_K_M quantization blocks showing memory distribution across layers.\",\n        \"Layer 1\": \"Detailed view of transformer layer 1 with attention heads and feed-forward networks.\",\n        \"Layer 2\": \"Detailed view of transformer layer 2 showing internal connections.\",\n        \"Layer 3\": \"Detailed view of transformer layer 3 architecture and components.\",\n        \"Layer 4\": \"Detailed view of transformer layer 4 structure and connections.\",\n        \"Layer 5\": \"Detailed view of transformer layer 5 with component visualization.\",\n    }\n    return descriptions.get(viz_name, f\"Detailed visualization of {viz_name.lower()}.\")\n\n# Create dashboard HTML\ndashboard_html = f'''\n<div style=\"margin:25px 0; padding:30px; background:linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%); border-radius:16px; box-shadow:0 20px 60px rgba(0,0,0,0.3); color:white;\">\n    <div style=\"text-align:center; margin-bottom:35px;\">\n        <h2 style=\"margin:0 0 10px 0; font-size:32px; color:white;\">ğŸ§  GGUF Neural Network Visualization Dashboard</h2>\n        <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:16px;\">Interactive visualizations of {MODEL_FILE} architecture</p>\n    </div>\n    \n    <!-- Statistics Overview -->\n    <div style=\"background:rgba(255,255,255,0.1); border-radius:12px; padding:25px; margin-bottom:30px; backdrop-filter:blur(10px);\">\n        <h3 style=\"margin:0 0 20px 0; color:white; text-align:center;\">ğŸ“Š Model Statistics</h3>\n        <div style=\"display:grid; grid-template-columns:repeat(auto-fit, minmax(200px, 1fr)); gap:20px;\">\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Total Layers</div>\n                <div style=\"font-size:36px; font-weight:700; color:#4ECDC4;\">{n_layers}</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Attention Heads</div>\n                <div style=\"font-size:36px; font-weight:700; color:#FF6B6B;\">{attention_heads_count}</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Total Nodes</div>\n                <div style=\"font-size:36px; font-weight:700; color:#FFD166;\">{total_nodes}</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Total Edges</div>\n                <div style=\"font-size:36px; font-weight:700; color:#95E1D3;\">{total_edges}</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Heads/Layer</div>\n                <div style=\"font-size:36px; font-weight:700; color:#A8D8EA;\">{n_heads}</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Quant Blocks</div>\n                <div style=\"font-size:36px; font-weight:700; color:#9B59B6;\">{len(quant_df) if 'quant_df' in locals() else 0}</div>\n            </div>\n        </div>\n    </div>\n    \n    <!-- Visualization Grid -->\n    <h3 style=\"margin:0 0 20px 0; color:white; text-align:center;\">ğŸš€ Available Visualizations</h3>\n    <div style=\"display:grid; grid-template-columns:repeat(auto-fill, minmax(320px, 1fr)); gap:25px;\">\n'''\n\n# Define category colors and icons\ncategory_info = {\n    \"Main Architecture\": {\"color\": \"#667eea\", \"icon\": \"ğŸŒ\"},\n    \"Interactive Explorer\": {\"color\": \"#10b981\", \"icon\": \"ğŸ”\"},\n    \"Attention Heads\": {\"color\": \"#FF6B6B\", \"icon\": \"ğŸ¯\"},\n    \"Quantization Blocks\": {\"color\": \"#9B59B6\", \"icon\": \"âš–ï¸\"},\n}\n\n# Add cards for each visualization\nfor viz_name, viz_url in all_visualizations.items():\n    if viz_url:\n        # Determine category\n        if viz_name == \"Main Architecture\":\n            category = \"Main Architecture\"\n        elif \"Interactive\" in viz_name or \"Explorer\" in viz_name:\n            category = \"Interactive Explorer\"\n        elif \"Attention\" in viz_name:\n            category = \"Attention Heads\"\n        elif \"Quantization\" in viz_name:\n            category = \"Quantization Blocks\"\n        else:\n            category = \"Layer Detail\"\n        \n        # Get styling\n        if category in category_info:\n            accent_color = category_info[category][\"color\"]\n            icon = category_info[category][\"icon\"]\n        else:\n            accent_color = \"#6b7280\"\n            icon = \"ğŸ”§\"\n        \n        # Get description\n        description = get_viz_description(viz_name)\n        \n        dashboard_html += f'''\n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid {accent_color};\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">{icon}</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">{viz_name}</h3>\n                <span style=\"background:{accent_color}20; color:{accent_color}; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    {category}\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                {description}\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"{viz_url}\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:{accent_color}; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('{viz_url}')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"{viz_url}\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        '''\n\ndashboard_html += f'''\n    </div>\n    \n    <!-- Usage Instructions -->\n    <div style=\"margin-top:40px; background:rgba(255,255,255,0.1); border-radius:12px; padding:25px; backdrop-filter:blur(10px);\">\n        <h3 style=\"margin:0 0 15px 0; color:white;\">ğŸ“– How to Use This Dashboard</h3>\n        <div style=\"display:grid; grid-template-columns:repeat(auto-fit, minmax(250px, 1fr)); gap:20px;\">\n            <div style=\"background:rgba(255,255,255,0.1); padding:20px; border-radius:8px;\">\n                <div style=\"font-size:24px; margin-bottom:10px;\">ğŸ”</div>\n                <h4 style=\"margin:0 0 10px 0; color:white;\">Explore Visualizations</h4>\n                <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:0.9em;\">\n                    Click any \"Open Visualization\" button to explore different aspects of the neural network.\n                </p>\n            </div>\n            <div style=\"background:rgba(255,255,255,0.1); padding:20px; border-radius:8px;\">\n                <div style=\"font-size:24px; margin-bottom:10px;\">ğŸ¨</div>\n                <h4 style=\"margin:0 0 10px 0; color:white;\">Interactive Features</h4>\n                <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:0.9em;\">\n                    Use Graphistry's tools to zoom, pan, filter, and inspect individual nodes and edges.\n                </p>\n            </div>\n            <div style=\"background:rgba(255,255,255,0.1); padding:20px; border-radius:8px;\">\n                <div style=\"font-size:24px; margin-bottom:10px;\">ğŸ’¾</div>\n                <h4 style=\"margin:0 0 10px 0; color:white;\">Share & Save</h4>\n                <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:0.9em;\">\n                    Use \"Copy Link\" to share visualizations or bookmark them for later reference.\n                </p>\n            </div>\n        </div>\n    </div>\n    \n    <div style=\"margin-top:30px; text-align:center; color:rgba(255,255,255,0.7); font-size:0.9em;\">\n        <p>Generated with Graphistry â€¢ Model: {MODEL_FILE} â€¢ {pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n    </div>\n</div>\n'''\n\n# Add JavaScript for copy functionality\njs_code = '''\n<script>\nfunction copyToClipboard(url) {\n    navigator.clipboard.writeText(url).then(() => {\n        const button = event.target;\n        const originalText = button.textContent;\n        button.textContent = 'âœ“ Copied!';\n        button.style.background = '#10b981';\n        button.style.color = 'white';\n        setTimeout(() => {\n            button.textContent = originalText;\n            button.style.background = '#f1f5f9';\n            button.style.color = '#64748b';\n        }, 2000);\n    }).catch(err => {\n        console.error('Failed to copy: ', err);\n    });\n}\n\n// Add event listeners to all copy buttons\ndocument.addEventListener('DOMContentLoaded', function() {\n    const buttons = document.querySelectorAll('button[data-url]');\n    buttons.forEach(button => {\n        button.addEventListener('click', function() {\n            const url = this.getAttribute('data-url');\n            copyToClipboard(url);\n        });\n    });\n});\n</script>\n'''\n\n# Display the dashboard\nfrom IPython.display import display, HTML\ndisplay(HTML(dashboard_html + js_code))\n\n# Save dashboard to file\ndashboard_path = '/kaggle/working/complete_dashboard.html'\nwith open(dashboard_path, 'w') as f:\n    final_html = f'''<!DOCTYPE html>\n<html>\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>GGUF Visualization Dashboard - {MODEL_FILE}</title>\n    <style>\n        body {{\n            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n            margin: 0;\n            padding: 20px;\n            background: linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%);\n            min-height: 100vh;\n        }}\n        button:hover {{\n            background: #e2e8f0 !important;\n        }}\n    </style>\n</head>\n<body>\n{dashboard_html}\n{js_code}\n</body>\n</html>'''\n    f.write(final_html)\n\nprint(f\"\\nâœ… Interactive Dashboard Created!\")\nprint(f\"ğŸ“ Dashboard saved to: {dashboard_path}\")\nprint(f\"\\nğŸ“‹ Dashboard Summary:\")\nprint(f\"   â€¢ Total Visualizations: {len(all_visualizations)}\")\nprint(f\"   â€¢ Model: {MODEL_FILE}\")\nprint(f\"   â€¢ Layers: {n_layers}\")\nprint(f\"   â€¢ Attention Heads: {attention_heads_count}\")\nprint(f\"   â€¢ Quantization Blocks: {len(quant_df) if 'quant_df' in locals() else 0}\")\n\n# Display download instructions\nprint(f\"\\nğŸ“¥ To download the dashboard:\")\nprint(f\"   1. Click on the 'Data' tab in Kaggle\")\nprint(f\"   2. Navigate to '/kaggle/working/'\")\nprint(f\"   3. Download 'complete_dashboard.html'\")", "metadata": {"trusted": true, "execution": {"iopub.status.busy": "2026-01-23T19:07:35.403518Z", "iopub.execute_input": "2026-01-23T19:07:35.404128Z", "iopub.status.idle": "2026-01-23T19:07:35.433096Z", "shell.execute_reply.started": "2026-01-23T19:07:35.404101Z", "shell.execute_reply": "2026-01-23T19:07:35.432307Z"}}, "outputs": [{"name": "stdout", "text": "======================================================================\nğŸ“Š CREATING INTERACTIVE DASHBOARD\n======================================================================\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "\n<div style=\"margin:25px 0; padding:30px; background:linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%); border-radius:16px; box-shadow:0 20px 60px rgba(0,0,0,0.3); color:white;\">\n    <div style=\"text-align:center; margin-bottom:35px;\">\n        <h2 style=\"margin:0 0 10px 0; font-size:32px; color:white;\">ğŸ§  GGUF Neural Network Visualization Dashboard</h2>\n        <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:16px;\">Interactive visualizations of Llama-3.2-3B-Instruct-Q4_K_M.gguf architecture</p>\n    </div>\n    \n    <!-- Statistics Overview -->\n    <div style=\"background:rgba(255,255,255,0.1); border-radius:12px; padding:25px; margin-bottom:30px; backdrop-filter:blur(10px);\">\n        <h3 style=\"margin:0 0 20px 0; color:white; text-align:center;\">ğŸ“Š Model Statistics</h3>\n        <div style=\"display:grid; grid-template-columns:repeat(auto-fit, minmax(200px, 1fr)); gap:20px;\">\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Total Layers</div>\n                <div style=\"font-size:36px; font-weight:700; color:#4ECDC4;\">28</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Attention Heads</div>\n                <div style=\"font-size:36px; font-weight:700; color:#FF6B6B;\">896</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Total Nodes</div>\n                <div style=\"font-size:36px; font-weight:700; color:#FFD166;\">929</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Total Edges</div>\n                <div style=\"font-size:36px; font-weight:700; color:#95E1D3;\">981</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Heads/Layer</div>\n                <div style=\"font-size:36px; font-weight:700; color:#A8D8EA;\">32</div>\n            </div>\n            <div style=\"text-align:center;\">\n                <div style=\"font-size:14px; color:rgba(255,255,255,0.7); margin-bottom:8px;\">Quant Blocks</div>\n                <div style=\"font-size:36px; font-weight:700; color:#9B59B6;\">112</div>\n            </div>\n        </div>\n    </div>\n    \n    <!-- Visualization Grid -->\n    <h3 style=\"margin:0 0 20px 0; color:white; text-align:center;\">ğŸš€ Available Visualizations</h3>\n    <div style=\"display:grid; grid-template-columns:repeat(auto-fill, minmax(320px, 1fr)); gap:25px;\">\n\n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #667eea;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸŒ</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Main Architecture</h3>\n                <span style=\"background:#667eea20; color:#667eea; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Main Architecture\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Complete overview of the entire neural network architecture with all layers and connections.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=db33bdcae73d4420bc97304709921d57&type=arrow&viztoken=43b3b95a-e6ae-4d67-944d-73b810b7541a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194757&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#667eea; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=db33bdcae73d4420bc97304709921d57&type=arrow&viztoken=43b3b95a-e6ae-4d67-944d-73b810b7541a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194757&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=db33bdcae73d4420bc97304709921d57&type=arrow&viztoken=43b3b95a-e6ae-4d67-944d-73b810b7541a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194757&info=true&play=0&pointSize=2.5&edgeOpacity=0.6&bg=%23FFFFFF&strongGravity=true&edgeInfluence=1.0&scalingRatio=10.0\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #6b7280;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸ”§</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Layer 1</h3>\n                <span style=\"background:#6b728020; color:#6b7280; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Layer Detail\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Detailed view of transformer layer 1 with attention heads and feed-forward networks.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=378abb6cf1ca4bdea5c43d02c302630c&type=arrow&viztoken=4c1e627d-6def-4ca7-be65-42ee999f54f8&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194768&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#6b7280; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=378abb6cf1ca4bdea5c43d02c302630c&type=arrow&viztoken=4c1e627d-6def-4ca7-be65-42ee999f54f8&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194768&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=378abb6cf1ca4bdea5c43d02c302630c&type=arrow&viztoken=4c1e627d-6def-4ca7-be65-42ee999f54f8&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194768&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #6b7280;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸ”§</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Layer 2</h3>\n                <span style=\"background:#6b728020; color:#6b7280; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Layer Detail\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Detailed view of transformer layer 2 showing internal connections.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=d3a3b0d045aa4246a097de6180160245&type=arrow&viztoken=227e1290-9768-41b1-970f-f4b80193a04f&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194769&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#6b7280; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=d3a3b0d045aa4246a097de6180160245&type=arrow&viztoken=227e1290-9768-41b1-970f-f4b80193a04f&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194769&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=d3a3b0d045aa4246a097de6180160245&type=arrow&viztoken=227e1290-9768-41b1-970f-f4b80193a04f&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194769&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #6b7280;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸ”§</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Layer 3</h3>\n                <span style=\"background:#6b728020; color:#6b7280; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Layer Detail\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Detailed view of transformer layer 3 architecture and components.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=789b08576d4d4e5c808f0e5e2f8ec578&type=arrow&viztoken=d12a58d1-44d0-4e59-b0be-a8538487a6f0&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194771&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#6b7280; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=789b08576d4d4e5c808f0e5e2f8ec578&type=arrow&viztoken=d12a58d1-44d0-4e59-b0be-a8538487a6f0&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194771&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=789b08576d4d4e5c808f0e5e2f8ec578&type=arrow&viztoken=d12a58d1-44d0-4e59-b0be-a8538487a6f0&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194771&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #6b7280;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸ”§</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Layer 4</h3>\n                <span style=\"background:#6b728020; color:#6b7280; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Layer Detail\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Detailed view of transformer layer 4 structure and connections.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=b4f0efd9e3c14723bbe83c93fb3cbb65&type=arrow&viztoken=111a0dc0-3b11-4ea3-a432-a0d57b0bd746&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194772&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#6b7280; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=b4f0efd9e3c14723bbe83c93fb3cbb65&type=arrow&viztoken=111a0dc0-3b11-4ea3-a432-a0d57b0bd746&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194772&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=b4f0efd9e3c14723bbe83c93fb3cbb65&type=arrow&viztoken=111a0dc0-3b11-4ea3-a432-a0d57b0bd746&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194772&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #6b7280;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸ”§</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Layer 5</h3>\n                <span style=\"background:#6b728020; color:#6b7280; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Layer Detail\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Detailed view of transformer layer 5 with component visualization.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=07ea42d536e04f91a5e785ca86b6160e&type=arrow&viztoken=bcbacb06-1cce-4dc5-9567-e1856458ff23&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194773&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#6b7280; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=07ea42d536e04f91a5e785ca86b6160e&type=arrow&viztoken=bcbacb06-1cce-4dc5-9567-e1856458ff23&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194773&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=07ea42d536e04f91a5e785ca86b6160e&type=arrow&viztoken=bcbacb06-1cce-4dc5-9567-e1856458ff23&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194773&info=true&play=0&pointSize=3.0&edgeOpacity=0.7&bg=%23F8F9FA&strongGravity=true&edgeInfluence=1.0&scalingRatio=8.0&showLabels=True\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #FF6B6B;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">ğŸ¯</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Attention Heads</h3>\n                <span style=\"background:#FF6B6B20; color:#FF6B6B; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Attention Heads\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Visualization of multi-head attention mechanisms colored by head number.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=e63c4f5d08194f138c3ca9b2595d2bb5&type=arrow&viztoken=e464b74b-8f93-4a04-a20b-01c11dfd711a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194953&info=true&play=0&pointSize=3.5&edgeOpacity=0.8&bg=%23FFFFFF&layout=concentric&strongGravity=true&edgeInfluence=1.0&scalingRatio=6.0&showLabels=true&gravity=0.1&linkDistance=100\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#FF6B6B; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=e63c4f5d08194f138c3ca9b2595d2bb5&type=arrow&viztoken=e464b74b-8f93-4a04-a20b-01c11dfd711a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194953&info=true&play=0&pointSize=3.5&edgeOpacity=0.8&bg=%23FFFFFF&layout=concentric&strongGravity=true&edgeInfluence=1.0&scalingRatio=6.0&showLabels=true&gravity=0.1&linkDistance=100')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=e63c4f5d08194f138c3ca9b2595d2bb5&type=arrow&viztoken=e464b74b-8f93-4a04-a20b-01c11dfd711a&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769194953&info=true&play=0&pointSize=3.5&edgeOpacity=0.8&bg=%23FFFFFF&layout=concentric&strongGravity=true&edgeInfluence=1.0&scalingRatio=6.0&showLabels=true&gravity=0.1&linkDistance=100\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n        <div style=\"background:rgba(255,255,255,0.95); border-radius:12px; padding:25px; box-shadow:0 8px 25px rgba(0,0,0,0.1); transition:all 0.3s; border-top:4px solid #9B59B6;\">\n            <div style=\"display:flex; align-items:center; margin-bottom:15px;\">\n                <div style=\"font-size:24px; margin-right:12px;\">âš–ï¸</div>\n                <h3 style=\"margin:0; font-size:1.2em; color:#1e293b; flex-grow:1;\">Quantization Blocks</h3>\n                <span style=\"background:#9B59B620; color:#9B59B6; padding:4px 12px; border-radius:20px; font-size:0.85em; font-weight:600;\">\n                    Quantization Blocks\n                </span>\n            </div>\n            <p style=\"margin:0 0 20px 0; color:#64748b; font-size:0.95em; line-height:1.5;\">\n                Q4_K_M quantization blocks showing memory distribution across layers.\n            </p>\n            <div style=\"display:flex; gap:10px;\">\n                <a href=\"https://hub.graphistry.com/graph/graph.html?dataset=4008a69277884883bca47e2a253b6256&type=arrow&viztoken=7d94a8df-3ca4-477b-a7ba-7c9ae03dbf94&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769195255&info=true&play=0&pointSize=3.0&edgeOpacity=0.6&bg=%23F0F4FF&layout=grid&strongGravity=true&edgeInfluence=1.2&scalingRatio=5.0&showLabels=true\" target=\"_blank\" \n                   style=\"flex:1; text-align:center; padding:12px; \n                          background:#9B59B6; color:white; border-radius:8px; \n                          text-decoration:none; font-weight:600; font-size:0.95em;\n                          transition:all 0.2s;\">\n                    ğŸš€ Open Visualization\n                </a>\n                <button onclick=\"copyToClipboard('https://hub.graphistry.com/graph/graph.html?dataset=4008a69277884883bca47e2a253b6256&type=arrow&viztoken=7d94a8df-3ca4-477b-a7ba-7c9ae03dbf94&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769195255&info=true&play=0&pointSize=3.0&edgeOpacity=0.6&bg=%23F0F4FF&layout=grid&strongGravity=true&edgeInfluence=1.2&scalingRatio=5.0&showLabels=true')\" \n                        style=\"padding:12px 20px; background:#f1f5f9; color:#64748b; \n                               border:1px solid #e2e8f0; border-radius:8px; cursor:pointer;\n                               font-weight:600; font-size:0.95em; transition:all 0.2s;\"\n                        data-url=\"https://hub.graphistry.com/graph/graph.html?dataset=4008a69277884883bca47e2a253b6256&type=arrow&viztoken=7d94a8df-3ca4-477b-a7ba-7c9ae03dbf94&usertag=438152b6-pygraphistry-0.50.4&splashAfter=1769195255&info=true&play=0&pointSize=3.0&edgeOpacity=0.6&bg=%23F0F4FF&layout=grid&strongGravity=true&edgeInfluence=1.2&scalingRatio=5.0&showLabels=true\">\n                    ğŸ“‹ Copy Link\n                </button>\n            </div>\n        </div>\n        \n    </div>\n    \n    <!-- Usage Instructions -->\n    <div style=\"margin-top:40px; background:rgba(255,255,255,0.1); border-radius:12px; padding:25px; backdrop-filter:blur(10px);\">\n        <h3 style=\"margin:0 0 15px 0; color:white;\">ğŸ“– How to Use This Dashboard</h3>\n        <div style=\"display:grid; grid-template-columns:repeat(auto-fit, minmax(250px, 1fr)); gap:20px;\">\n            <div style=\"background:rgba(255,255,255,0.1); padding:20px; border-radius:8px;\">\n                <div style=\"font-size:24px; margin-bottom:10px;\">ğŸ”</div>\n                <h4 style=\"margin:0 0 10px 0; color:white;\">Explore Visualizations</h4>\n                <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:0.9em;\">\n                    Click any \"Open Visualization\" button to explore different aspects of the neural network.\n                </p>\n            </div>\n            <div style=\"background:rgba(255,255,255,0.1); padding:20px; border-radius:8px;\">\n                <div style=\"font-size:24px; margin-bottom:10px;\">ğŸ¨</div>\n                <h4 style=\"margin:0 0 10px 0; color:white;\">Interactive Features</h4>\n                <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:0.9em;\">\n                    Use Graphistry's tools to zoom, pan, filter, and inspect individual nodes and edges.\n                </p>\n            </div>\n            <div style=\"background:rgba(255,255,255,0.1); padding:20px; border-radius:8px;\">\n                <div style=\"font-size:24px; margin-bottom:10px;\">ğŸ’¾</div>\n                <h4 style=\"margin:0 0 10px 0; color:white;\">Share & Save</h4>\n                <p style=\"margin:0; color:rgba(255,255,255,0.8); font-size:0.9em;\">\n                    Use \"Copy Link\" to share visualizations or bookmark them for later reference.\n                </p>\n            </div>\n        </div>\n    </div>\n    \n    <div style=\"margin-top:30px; text-align:center; color:rgba(255,255,255,0.7); font-size:0.9em;\">\n        <p>Generated with Graphistry â€¢ Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf â€¢ 2026-01-23 19:07:35</p>\n    </div>\n</div>\n\n<script>\nfunction copyToClipboard(url) {\n    navigator.clipboard.writeText(url).then(() => {\n        const button = event.target;\n        const originalText = button.textContent;\n        button.textContent = 'âœ“ Copied!';\n        button.style.background = '#10b981';\n        button.style.color = 'white';\n        setTimeout(() => {\n            button.textContent = originalText;\n            button.style.background = '#f1f5f9';\n            button.style.color = '#64748b';\n        }, 2000);\n    }).catch(err => {\n        console.error('Failed to copy: ', err);\n    });\n}\n\n// Add event listeners to all copy buttons\ndocument.addEventListener('DOMContentLoaded', function() {\n    const buttons = document.querySelectorAll('button[data-url]');\n    buttons.forEach(button => {\n        button.addEventListener('click', function() {\n            const url = this.getAttribute('data-url');\n            copyToClipboard(url);\n        });\n    });\n});\n</script>\n"}, "metadata": {}}, {"name": "stdout", "text": "\nâœ… Interactive Dashboard Created!\nğŸ“ Dashboard saved to: /kaggle/working/complete_dashboard.html\n\nğŸ“‹ Dashboard Summary:\n   â€¢ Total Visualizations: 8\n   â€¢ Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf\n   â€¢ Layers: 28\n   â€¢ Attention Heads: 896\n   â€¢ Quantization Blocks: 112\n\nğŸ“¥ To download the dashboard:\n   1. Click on the 'Data' tab in Kaggle\n   2. Navigate to '/kaggle/working/'\n   3. Download 'complete_dashboard.html'\n", "output_type": "stream"}], "execution_count": 20}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}]}