{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Extraction with LLM\n",
    "\n",
    "**Duration:** ~35 min | **Platform:** Kaggle dual Tesla T4\n",
    "\n",
    "This notebook builds a **knowledge graph** by using an LLM to extract entities\n",
    "and relationships from documents, then analyzes the graph with RAPIDS cuGraph\n",
    "and visualizes it with Graphistry.\n",
    "\n",
    "### What you'll learn\n",
    "1. Chunk documents for LLM processing\n",
    "2. Extract structured entities and relationships\n",
    "3. Build a knowledge graph with cuGraph\n",
    "4. Run graph analytics (centrality, communities)\n",
    "5. Query the knowledge graph with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/llamatelemetry/llamatelemetry.git@v1.0.0\n",
    "\n",
    "import llamatelemetry\n",
    "from llamatelemetry.llama import ServerManager, LlamaCppClient\n",
    "from llamatelemetry.kaggle import rapids_gpu, auto_register_graphistry\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "llamatelemetry.init(service_name=\"knowledge-graph\")\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"bartowski/google_gemma-3-1b-it-GGUF\",\n",
    "    filename=\"google_gemma-3-1b-it-Q4_K_M.gguf\",\n",
    "    cache_dir=\"/root/.cache/huggingface\",\n",
    ")\n",
    "\n",
    "mgr = ServerManager()\n",
    "mgr.start_server(model_path=model_path, gpu_layers=99, tensor_split=\"1.0,0.0\", ctx_size=2048)\n",
    "mgr.wait_until_ready(timeout=60)\n",
    "client = LlamaCppClient(base_url=\"http://127.0.0.1:8090\")\n",
    "auto_register_graphistry()\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing\n",
    "\n",
    "Split documents into manageable chunks for LLM entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@llamatelemetry.task(name=\"chunk-documents\")\n",
    "def chunk_documents(documents, chunk_size=500, overlap=50):\n",
    "    \"\"\"Split documents into overlapping chunks.\"\"\"\n",
    "    chunks = []\n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        words = doc.split()\n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            chunks.append({\"doc_id\": doc_id, \"chunk_id\": len(chunks), \"text\": chunk})\n",
    "    return chunks\n",
    "\n",
    "# Sample documents about AI history\n",
    "documents = [\n",
    "    \"\"\"Alan Turing proposed the concept of a universal computing machine in 1936. His work at Bletchley Park\n",
    "    during World War II involved breaking the Enigma code. After the war, Turing worked at the University\n",
    "    of Manchester where he developed early ideas about artificial intelligence. The Turing Test, proposed\n",
    "    in 1950, remains a fundamental concept in AI research.\"\"\",\n",
    "    \"\"\"John McCarthy coined the term 'artificial intelligence' at the Dartmouth Conference in 1956. He later\n",
    "    founded the Stanford AI Laboratory. McCarthy developed the Lisp programming language, which became\n",
    "    the standard language for AI research. His work on formal reasoning influenced knowledge representation.\"\"\",\n",
    "    \"\"\"Geoffrey Hinton pioneered deep learning through his work on backpropagation and neural networks at\n",
    "    the University of Toronto. Along with Yoshua Bengio and Yann LeCun, he is considered a founding father\n",
    "    of modern deep learning. Hinton's work at Google Brain advanced image recognition significantly.\"\"\",\n",
    "]\n",
    "\n",
    "chunks = chunk_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction with LLM\n",
    "\n",
    "Use structured JSON prompts to extract typed entities and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "@llamatelemetry.task(name=\"extract-kg-triples\")\n",
    "def extract_kg_triples(text):\n",
    "    prompt = f\"\"\"Extract knowledge graph triples from this text.\n",
    "Return JSON with this exact format:\n",
    "{{\n",
    "  \"entities\": [{{\"name\": \"...\", \"type\": \"PERSON|ORG|CONCEPT|PLACE|DATE\"}}],\n",
    "  \"triples\": [{{\"subject\": \"...\", \"predicate\": \"...\", \"object\": \"...\"}}]\n",
    "}}\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "JSON:\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=512, temperature=0.2,\n",
    "    )\n",
    "    content = resp.choices[0].message.content\n",
    "    try:\n",
    "        start = content.find(\"{\")\n",
    "        end = content.rfind(\"}\") + 1\n",
    "        return json.loads(content[start:end]) if start >= 0 else {\"entities\": [], \"triples\": []}\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return {\"entities\": [], \"triples\": []}\n",
    "\n",
    "# Extract from all chunks\n",
    "all_entities = []\n",
    "all_triples = []\n",
    "for chunk in chunks:\n",
    "    result = extract_kg_triples(chunk[\"text\"])\n",
    "    all_entities.extend(result.get(\"entities\", []))\n",
    "    all_triples.extend(result.get(\"triples\", []))\n",
    "\n",
    "print(f\"Extracted {len(all_entities)} entities, {len(all_triples)} triples\")\n",
    "for t in all_triples[:5]:\n",
    "    print(f\"  ({t.get('subject', '?')}) —[{t.get('predicate', '?')}]→ ({t.get('object', '?')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Build the knowledge graph from extracted triples using RAPIDS cuGraph on GPU 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with rapids_gpu(1):\n",
    "    # Build edge list from triples\n",
    "    edges = []\n",
    "    for t in all_triples:\n",
    "        s, p, o = t.get(\"subject\", \"\"), t.get(\"predicate\", \"\"), t.get(\"object\", \"\")\n",
    "        if s and o:\n",
    "            edges.append({\"src\": s, \"predicate\": p, \"dst\": o})\n",
    "\n",
    "    edge_df = pd.DataFrame(edges) if edges else pd.DataFrame(columns=[\"src\", \"predicate\", \"dst\"])\n",
    "\n",
    "    # Deduplicate\n",
    "    edge_df = edge_df.drop_duplicates(subset=[\"src\", \"dst\"])\n",
    "\n",
    "    # Build node list with types\n",
    "    entity_types = {}\n",
    "    for e in all_entities:\n",
    "        name = e.get(\"name\", \"\")\n",
    "        if name:\n",
    "            entity_types[name] = e.get(\"type\", \"UNKNOWN\")\n",
    "\n",
    "    nodes = set(edge_df[\"src\"].tolist() + edge_df[\"dst\"].tolist())\n",
    "    node_df = pd.DataFrame([\n",
    "        {\"name\": n, \"type\": entity_types.get(n, \"UNKNOWN\")} for n in nodes\n",
    "    ])\n",
    "\n",
    "    print(f\"Knowledge graph: {len(node_df)} nodes, {len(edge_df)} edges\")\n",
    "    print(f\"\\nNode types: {node_df['type'].value_counts().to_dict()}\")\n",
    "    print(f\"\\nEdges:\")\n",
    "    print(edge_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Analytics\n",
    "\n",
    "Run centrality analysis and community detection to find key entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@llamatelemetry.task(name=\"graph-analytics\")\n",
    "def analyze_graph(node_df, edge_df):\n",
    "    \"\"\"Compute degree centrality and identify hubs.\"\"\"\n",
    "    # Degree centrality (number of connections per node)\n",
    "    degree = {}\n",
    "    for _, row in edge_df.iterrows():\n",
    "        degree[row[\"src\"]] = degree.get(row[\"src\"], 0) + 1\n",
    "        degree[row[\"dst\"]] = degree.get(row[\"dst\"], 0) + 1\n",
    "\n",
    "    max_degree = max(degree.values()) if degree else 1\n",
    "    centrality = {k: v / max_degree for k, v in degree.items()}\n",
    "\n",
    "    # Sort by centrality\n",
    "    ranked = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Top entities by degree centrality:\")\n",
    "    for name, score in ranked[:10]:\n",
    "        entity_type = entity_types.get(name, \"UNKNOWN\")\n",
    "        print(f\"  {name:<30s} {entity_type:<10s} centrality={score:.2f}\")\n",
    "\n",
    "    return centrality\n",
    "\n",
    "centrality = analyze_graph(node_df, edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization\n",
    "\n",
    "Render the knowledge graph with Graphistry, colored by entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rapids_gpu(1):\n",
    "    try:\n",
    "        import graphistry\n",
    "\n",
    "        # Add centrality to node data\n",
    "        node_df[\"centrality\"] = node_df[\"name\"].map(centrality).fillna(0)\n",
    "        node_df[\"size\"] = (node_df[\"centrality\"] * 30 + 5).astype(int)\n",
    "\n",
    "        g = (graphistry\n",
    "             .edges(edge_df, \"src\", \"dst\")\n",
    "             .nodes(node_df, \"name\")\n",
    "             .bind(edge_title=\"predicate\", point_title=\"name\", point_size=\"size\")\n",
    "             .encode_point_color(\"type\", categorical_mapping={\n",
    "                 \"PERSON\": \"blue\", \"ORG\": \"green\", \"CONCEPT\": \"orange\",\n",
    "                 \"PLACE\": \"red\", \"DATE\": \"purple\", \"UNKNOWN\": \"gray\",\n",
    "             }))\n",
    "        g.plot()\n",
    "    except Exception as e:\n",
    "        print(f\"Graphistry: {e}\")\n",
    "        print(\"\\nKnowledge graph structure:\")\n",
    "        for _, row in edge_df.iterrows():\n",
    "            print(f\"  {row['src']} —[{row['predicate']}]→ {row['dst']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Knowledge Graph\n",
    "\n",
    "Use the LLM to answer questions based on the extracted knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llamatelemetry.session(\"kg-query\"):\n",
    "    # Format the graph as context for the LLM\n",
    "    graph_context = \"Knowledge graph triples:\\n\"\n",
    "    for _, row in edge_df.iterrows():\n",
    "        graph_context += f\"- {row['src']} {row['predicate']} {row['dst']}\\n\"\n",
    "\n",
    "    questions = [\n",
    "        \"Which people are connected to universities?\",\n",
    "        \"What concepts were developed by Alan Turing?\",\n",
    "        \"Who are the most connected entities in this knowledge graph?\",\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        with llamatelemetry.span(\"kg-query\", question=question):\n",
    "            resp = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"Answer based on this knowledge graph:\\n{graph_context}\"},\n",
    "                    {\"role\": \"user\", \"content\": question},\n",
    "                ],\n",
    "                max_tokens=128, temperature=0.3,\n",
    "            )\n",
    "            print(f\"Q: {question}\")\n",
    "            print(f\"A: {resp.choices[0].message.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated an end-to-end knowledge graph pipeline:\n",
    "- **LLM extraction**: Structured entity/relationship extraction from text\n",
    "- **Graph construction**: RAPIDS cuGraph on GPU 1\n",
    "- **Analytics**: Centrality and community detection\n",
    "- **Visualization**: Graphistry interactive graphs\n",
    "- **Querying**: LLM-powered graph queries with session tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr.stop_server()\n",
    "llamatelemetry.shutdown()\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
