{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"header_cell","cell_type":"markdown","source":"# 08: Document Network Analysis with Graphistry\n\n**llamatelemetry v0.1.0** | Kaggle 2Ã— Tesla T4 (30GB Total VRAM)\n\n---\n\n## ğŸ¯ Objective\n\nThis notebook demonstrates **document similarity networks** and **community detection** using llamatelemetry v0.1.0 with graphistry[ai] visualization:\n\n### Architecture:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  GPU 0: llama-server (LLM)                             â”‚\nâ”‚         Generate document summaries & extract topics   â”‚\nâ”‚         tensor_split=\"1.0,0.0\"                         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                          â†“\n                  Document Similarity Graph\n                          â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  GPU 1: RAPIDS + Graphistry                            â”‚\nâ”‚         Community detection + cluster visualization    â”‚\nâ”‚         CUDA_VISIBLE_DEVICES=\"1\"                       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Workflow:\n1. Start llama-server on GPU 0\n2. Generate document summaries using LLM\n3. Build document similarity network on GPU 1\n4. Detect communities with Louvain algorithm (cuGraph)\n5. Visualize clusters with Graphistry\n6. LLM interprets community themes\n\n---\n\n**Previous:** [07-knowledge-graph-extraction](07-knowledge-graph-extraction-graphistry-llamatelemetry-v0-1-0.ipynb)  \n**Next:** [09-large-models-kaggle](09-large-models-kaggle-llamatelemetry-v0-1-0.ipynb)","metadata":{}},{"id":"step0_header","cell_type":"markdown","source":"## Step 0: Add Graphistry Secrets in Kaggle\n\nGo to **Kaggle â†’ Settings â†’ Add-ons â†’ Secrets** and add:\n- `Graphistry_Personal_Key_ID`\n- `Graphistry_Personal_Secret_Key`","metadata":{}},{"id":"step1_header","cell_type":"markdown","source":"## Step 1: Verify Dual GPU Environment","metadata":{}},{"id":"9fb33926","cell_type":"markdown","source":"Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings.","metadata":{}},{"id":"41c5e373","cell_type":"markdown","source":"Verifies dual T4 GPU setup for document network analysis combining LLM text processing with GPU-accelerated network analytics and visualization.","metadata":{}},{"id":"step1_code","cell_type":"code","source":"import subprocess\nimport os\n\nprint(\"=\"*70)\nprint(\"ğŸ” SPLIT-GPU ENVIRONMENT CHECK\")\nprint(\"=\"*70)\n\nresult = subprocess.run(\n    [\"nvidia-smi\", \"--query-gpu=index,name,memory.total,memory.free\", \"--format=csv,noheader\"],\n    capture_output=True, text=True\n)\n\ngpus = result.stdout.strip().split('\\n')\nprint(f\"\\nğŸ“Š Detected {len(gpus)} GPU(s):\")\nfor gpu in gpus:\n    print(f\"   {gpu}\")\n\nif len(gpus) >= 2:\n    print(\"\\nâœ… Dual T4 ready for split-GPU operation!\")\n    print(\"   GPU 0 â†’ llama-server (LLM for summaries)\")\n    print(\"   GPU 1 â†’ RAPIDS/Graphistry (community detection)\")\nelse:\n    print(\"\\nâš ï¸ Need 2 GPUs for split operation\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:45:41.919722Z","iopub.execute_input":"2026-02-05T02:45:41.920587Z","iopub.status.idle":"2026-02-05T02:45:41.965667Z","shell.execute_reply.started":"2026-02-05T02:45:41.920546Z","shell.execute_reply":"2026-02-05T02:45:41.964942Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ” SPLIT-GPU ENVIRONMENT CHECK\n======================================================================\n\nğŸ“Š Detected 2 GPU(s):\n   0, Tesla T4, 15360 MiB, 14913 MiB\n   1, Tesla T4, 15360 MiB, 14913 MiB\n\nâœ… Dual T4 ready for split-GPU operation!\n   GPU 0 â†’ llama-server (LLM for summaries)\n   GPU 1 â†’ RAPIDS/Graphistry (community detection)\n","output_type":"stream"}],"execution_count":1},{"id":"step2_header","cell_type":"markdown","source":"## Step 2: Install Dependencies","metadata":{}},{"id":"d4ef124b","cell_type":"markdown","source":"Installs llamatelemetry for LLM inference, RAPIDS for GPU graph analytics, and Graphistry for visualizing document similarity networks.","metadata":{}},{"id":"b946df2a","cell_type":"markdown","source":"Installs llamatelemetry for LLM inference, RAPIDS cuGraph for GPU graph analytics, and Graphistry for visualizing document similarity networks.","metadata":{}},{"id":"step2_code","cell_type":"code","source":"%%time\nprint(\"ğŸ“¦ Installing dependencies...\")\n\n\n!pip install -q huggingface-hub sseclient-py\n\n# Install llamatelemetry v0.1.0\n!pip install -q --no-cache-dir git+https://github.com/llamatelemetry/llamatelemetry.git@v0.1.0\n\n# Install cuGraph (matching Kaggle RAPIDS 25.6.0)\n!pip install -q --extra-index-url=https://pypi.nvidia.com \"cugraph-cu12==25.6.*\"\n\n# Install Graphistry\n!pip install -q \"graphistry[ai]\"\n\n# Verify\nimport llamatelemetry\nprint(f\"\\nâœ… llamatelemetry {llamatelemetry.__version__} installed\")\n\ntry:\n    import cudf, cugraph\n    print(f\"âœ… cuDF {cudf.__version__}\")\n    print(f\"âœ… cuGraph {cugraph.__version__}\")\nexcept ImportError as e:\n    print(f\"âš ï¸ RAPIDS: {e}\")\n\ntry:\n    import graphistry\n    print(f\"âœ… Graphistry {graphistry.__version__}\")\nexcept ImportError as e:\n    print(f\"âš ï¸ Graphistry: {e}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:46:14.454053Z","iopub.execute_input":"2026-02-05T02:46:14.454346Z","iopub.status.idle":"2026-02-05T02:47:52.601246Z","shell.execute_reply.started":"2026-02-05T02:46:14.454321Z","shell.execute_reply":"2026-02-05T02:47:52.600560Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ“¦ Installing dependencies...\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for llamatelemetry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.2 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.8/439.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"WARNING:root:llamatelemetry: Library directory not found - shared libraries may not load correctly\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nğŸ¯ llamatelemetry v0.1.0 First-Time Setup - Kaggle 2Ã— T4 Multi-GPU\n======================================================================\n\nğŸ® GPU Detected: Tesla T4 (Compute 7.5)\n  âœ… Tesla T4 detected - Perfect for llamatelemetry v0.1.0!\nğŸŒ Platform: Colab\n\nğŸ“¦ Downloading Kaggle 2Ã— T4 binaries (~961 MB)...\n    Features: FlashAttention + Tensor Cores + Multi-GPU tensor-split\n\nâ¡ï¸  Attempt 1: HuggingFace (llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz)\nğŸ“¥ Downloading v0.1.0 from HuggingFace Hub...\n   Repo: waqasm86/llamatelemetry-binaries\n   File: v0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\nFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"v0.1.0/llamatelemetry-v0.1.0-cuda12-kagg(â€¦):   0%|          | 0.00/1.40G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac08fff31bb4eb3bda99c3448a362ea"}},"metadata":{}},{"name":"stdout","text":"ğŸ” Verifying SHA256 checksum...\n   âœ… Checksum verified\nğŸ“¦ Extracting llamatelemetry-v0.1.0-cuda12-kaggle-t4x2.tar.gz...\nFound 21 files in archive\nExtracted 21 files to /root/.cache/llamatelemetry/extract_0.1.0\nâœ… Extraction complete!\n  Found bin/ and lib/ under /root/.cache/llamatelemetry/extract_0.1.0/llamatelemetry-v0.1.0-cuda12-kaggle-t4x2\n  Copied 13 binaries to /usr/local/lib/python3.12/dist-packages/llamatelemetry/binaries/cuda12\n  Copied 2 libraries to /usr/local/lib/python3.12/dist-packages/llamatelemetry/lib\nâœ… Binaries installed successfully!\n\n\nâœ… llamatelemetry 0.1.0 installed\nâœ… cuDF 25.06.00\nâœ… cuGraph 25.06.00\nâœ… Graphistry 0.50.6\nCPU times: user 54.2 s, sys: 13.4 s, total: 1min 7s\nWall time: 1min 38s\n","output_type":"stream"}],"execution_count":2},{"id":"ceedeb1e","cell_type":"markdown","source":"Configures Graphistry API authentication using Kaggle secrets for cloud-based document network visualization rendering.","metadata":{}},{"id":"365e61a3-e832-4e9c-b5b8-55f842d2f4ac","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\ngraphistry.register(\n    api=3,\n    protocol=\"https\",\n    server=\"hub.graphistry.com\",\n    personal_key_id=user_secrets.get_secret(\"Graphistry_Personal_Key_ID\"),\n    personal_key_secret=user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:48:32.792962Z","iopub.execute_input":"2026-02-05T02:48:32.793983Z","iopub.status.idle":"2026-02-05T02:48:33.677003Z","shell.execute_reply.started":"2026-02-05T02:48:32.793950Z","shell.execute_reply":"2026-02-05T02:48:33.676397Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<graphistry.pygraphistry.GraphistryClient at 0x7ecd54eb1e80>"},"metadata":{}}],"execution_count":3},{"id":"e31e02d0-b684-4266-b9b1-b98fa5af774e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"step3_header","cell_type":"markdown","source":"## Step 3: Download GGUF Model","metadata":{}},{"id":"8c66831c","cell_type":"markdown","source":"Downloads embedding or instruction-following model for document analysis, semantic similarity computation, and relationship extraction.","metadata":{}},{"id":"4c34d6a8","cell_type":"markdown","source":"Downloads language model for document embeddings, semantic analysis, and text similarity computation.","metadata":{}},{"id":"step3_code","cell_type":"code","source":"%%time\nfrom huggingface_hub import hf_hub_download\nimport os\n\nMODEL_REPO = \"bartowski/Llama-3.2-3B-Instruct-GGUF\"\nMODEL_FILE = \"Llama-3.2-3B-Instruct-Q4_K_M.gguf\"\n\nprint(f\"ğŸ“¥ Downloading {MODEL_FILE}...\")\n\nmodel_path = hf_hub_download(\n    repo_id=MODEL_REPO,\n    filename=MODEL_FILE,\n    local_dir=\"/kaggle/working/models\"\n)\n\nsize_gb = os.path.getsize(model_path) / (1024**3)\nprint(f\"\\nâœ… Model downloaded: {model_path}\")\nprint(f\"   Size: {size_gb:.2f} GB\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:02.876003Z","iopub.execute_input":"2026-02-05T02:49:02.876578Z","iopub.status.idle":"2026-02-05T02:49:07.058583Z","shell.execute_reply.started":"2026-02-05T02:49:02.876547Z","shell.execute_reply":"2026-02-05T02:49:07.057883Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ“¥ Downloading Llama-3.2-3B-Instruct-Q4_K_M.gguf...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Llama-3.2-3B-Instruct-Q4_K_M.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc78dd75f09f4eba81e07ce3c63c8c07"}},"metadata":{}},{"name":"stdout","text":"\nâœ… Model downloaded: /kaggle/working/models/Llama-3.2-3B-Instruct-Q4_K_M.gguf\n   Size: 1.88 GB\nCPU times: user 3.85 s, sys: 7.3 s, total: 11.2 s\nWall time: 4.18 s\n","output_type":"stream"}],"execution_count":4},{"id":"step4_header","cell_type":"markdown","source":"## Step 4: Start llama-server on GPU 0 Only","metadata":{}},{"id":"6e5b0b2a","cell_type":"markdown","source":"Deploys llama-server on GPU 0 using tensor-split configuration for document processing while keeping GPU 1 free for graph operations.","metadata":{}},{"id":"411b97e4","cell_type":"markdown","source":"Starts llama-server on GPU 0 using single-GPU configuration (tensor-split 1.0,0.0) while reserving GPU 1 for graph operations.","metadata":{}},{"id":"step4_code","cell_type":"code","source":"from llamatelemetry.server import ServerManager\n\nprint(\"=\"*70)\nprint(\"ğŸš€ STARTING LLAMA-SERVER ON GPU 0\")\nprint(\"=\"*70)\n\nprint(\"\\nğŸ“‹ Configuration:\")\nprint(\"   GPU 0: 100% (llama-server for document summarization)\")\nprint(\"   GPU 1: 0% (reserved for RAPIDS/Graphistry)\")\n\nserver = ServerManager()\nserver.start_server(\n    model_path=model_path,\n    host=\"127.0.0.1\",\n    port=8090,\n    gpu_layers=99,\n    tensor_split=\"1.0,0.0\",\n    ctx_size=4096,\n)\n\nif server.check_server_health():\n    print(\"\\nâœ… llama-server running on GPU 0!\")\nelse:\n    print(\"\\nâŒ Server failed to start\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:10.928136Z","iopub.execute_input":"2026-02-05T02:49:10.928448Z","iopub.status.idle":"2026-02-05T02:49:14.011484Z","shell.execute_reply.started":"2026-02-05T02:49:10.928422Z","shell.execute_reply":"2026-02-05T02:49:14.010846Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸš€ STARTING LLAMA-SERVER ON GPU 0\n======================================================================\n\nğŸ“‹ Configuration:\n   GPU 0: 100% (llama-server for document summarization)\n   GPU 1: 0% (reserved for RAPIDS/Graphistry)\nGPU Check:\n  Platform: kaggle\n  GPU: Tesla T4\n  Compute Capability: 7.5\n  Status: âœ“ Compatible\nStarting llama-server...\n  Executable: /usr/local/lib/python3.12/dist-packages/llamatelemetry/binaries/cuda12/llama-server\n  Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf\n  GPU Layers: 99\n  Context Size: 4096\n  Server URL: http://127.0.0.1:8090\nWaiting for server to be ready...... âœ“ Ready in 3.0s\n\nâœ… llama-server running on GPU 0!\n","output_type":"stream"}],"execution_count":5},{"id":"step5_header","cell_type":"markdown","source":"## Step 5: Generate Document Summaries and Topics","metadata":{}},{"id":"8243ced2","cell_type":"markdown","source":"Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings.","metadata":{}},{"id":"370fdc25","cell_type":"markdown","source":"Verifies GPU memory allocation showing LLM loaded on GPU 0 with GPU 1 free for document network processing.","metadata":{}},{"id":"step5_code","cell_type":"code","source":"from llamatelemetry.api.client import LlamaCppClient\n\nprint(\"=\"*70)\nprint(\"ğŸ“„ LLM-POWERED DOCUMENT ANALYSIS\")\nprint(\"=\"*70)\n\nclient = LlamaCppClient(base_url=\"http://127.0.0.1:8090\")\n\n# Sample documents about various GPU computing topics\ndocuments = [\n    # Deep Learning cluster\n    {\"id\": \"doc1\", \"text\": \"PyTorch provides dynamic computation graphs for deep learning. It integrates seamlessly with CUDA for GPU acceleration. Training neural networks on GPUs is significantly faster than CPUs.\"},\n    {\"id\": \"doc2\", \"text\": \"TensorFlow is Google's deep learning framework. It offers distributed training across multiple GPUs. TensorBoard provides visualization for training metrics.\"},\n    {\"id\": \"doc3\", \"text\": \"NVIDIA cuDNN accelerates deep neural network training. It provides highly optimized primitives for convolution and pooling operations on GPUs.\"},\n    \n    # Data Science cluster\n    {\"id\": \"doc4\", \"text\": \"RAPIDS cuDF provides a GPU DataFrame library. It accelerates pandas operations by 50-100Ã— using CUDA. Data scientists can process large datasets efficiently.\"},\n    {\"id\": \"doc5\", \"text\": \"cuML implements machine learning algorithms on GPUs. It supports classification, regression, and clustering with scikit-learn API compatibility.\"},\n    {\"id\": \"doc6\", \"text\": \"Apache Spark can leverage GPUs for distributed computing. RAPIDS Accelerator speeds up Spark SQL and DataFrame operations on GPU clusters.\"},\n    \n    # Inference cluster\n    {\"id\": \"doc7\", \"text\": \"llama.cpp enables efficient LLM inference on GPUs. GGUF quantization reduces model size while maintaining quality. It supports multi-GPU tensor parallelism.\"},\n    {\"id\": \"doc8\", \"text\": \"TensorRT optimizes neural network inference. It provides INT8 and FP16 precision for faster inference. Deployed models achieve low latency on NVIDIA GPUs.\"},\n    {\"id\": \"doc9\", \"text\": \"ONNX Runtime accelerates machine learning inference. It supports multiple hardware backends including CUDA. Models can be optimized for production deployment.\"},\n    \n    # Visualization cluster\n    {\"id\": \"doc10\", \"text\": \"Graphistry provides GPU-accelerated graph visualization. It handles millions of nodes and edges interactively. RAPIDS integration enables visual analytics at scale.\"},\n    {\"id\": \"doc11\", \"text\": \"cuGraph implements graph algorithms on GPUs. PageRank and community detection run 100Ã— faster than NetworkX. It integrates with Graphistry for visualization.\"},\n]\n\n# Extract topics from each document\ndoc_topics = []\n\nfor doc in documents:\n    prompt = f\"\"\"Summarize this document in 5 words maximum, focusing on the main topic:\n\n{doc['text']}\n\n5-word summary:\"\"\"\n    \n    response = client.chat.create(\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        max_tokens=20,\n        temperature=0.3,\n    )\n    \n    summary = response.choices[0].message.content.strip()\n    doc_topics.append({\"id\": doc[\"id\"], \"summary\": summary, \"text\": doc[\"text\"]})\n    print(f\"{doc['id']}: {summary}\")\n\nprint(f\"\\nâœ… Generated {len(doc_topics)} document summaries\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:21.691449Z","iopub.execute_input":"2026-02-05T02:49:21.692297Z","iopub.status.idle":"2026-02-05T02:49:23.367219Z","shell.execute_reply.started":"2026-02-05T02:49:21.692254Z","shell.execute_reply":"2026-02-05T02:49:23.366620Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ“„ LLM-POWERED DOCUMENT ANALYSIS\n======================================================================\ndoc1: PyTorch accelerates deep learning computations.\ndoc2: Google's Deep Learning Framework TensorFlow\ndoc3: Optimized GPU acceleration for NNS.\ndoc4: GPU-accelerated data processing library.\ndoc5: Machine Learning on GPU Acceleration\ndoc6: Spark uses GPUs for speed.\ndoc7: Efficient GPU-based LLM inference tool\ndoc8: TensorRT accelerates neural network inference.\ndoc9: ONNX Runtime for Machine Learning\ndoc10: GPU-accelerated graph visualization software.\ndoc11: cuGraph accelerates GPU-based graph processing.\n\nâœ… Generated 11 document summaries\n","output_type":"stream"}],"execution_count":6},{"id":"step6_header","cell_type":"markdown","source":"## Step 6: Initialize RAPIDS on GPU 1","metadata":{}},{"id":"b179961a","cell_type":"markdown","source":"Initializes RAPIDS on GPU 1 via CUDA_VISIBLE_DEVICES environment variable for GPU-accelerated document graph operations.","metadata":{}},{"id":"step6_code","cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\nprint(\"=\"*70)\nprint(\"ğŸ”¥ INITIALIZING RAPIDS ON GPU 1\")\nprint(\"=\"*70)\n\nimport cudf\nimport cupy as cp\n\nprint(f\"\\nğŸ“Š RAPIDS GPU Info:\")\ndevice = cp.cuda.Device(0)  # Device 0 in filtered view = actual GPU 1\nprint(f\"   Device: {device.id} (filtered view)\")\nprint(f\"   Actual GPU: 1 (Tesla T4)\")\n\nprint(f\"\\nâœ… RAPIDS initialized on GPU 1\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:27.266142Z","iopub.execute_input":"2026-02-05T02:49:27.266770Z","iopub.status.idle":"2026-02-05T02:49:27.271814Z","shell.execute_reply.started":"2026-02-05T02:49:27.266743Z","shell.execute_reply":"2026-02-05T02:49:27.271214Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ”¥ INITIALIZING RAPIDS ON GPU 1\n======================================================================\n\nğŸ“Š RAPIDS GPU Info:\n   Device: 0 (filtered view)\n   Actual GPU: 1 (Tesla T4)\n\nâœ… RAPIDS initialized on GPU 1\n","output_type":"stream"}],"execution_count":7},{"id":"step7_header","cell_type":"markdown","source":"## Step 7: Build Document Similarity Network","metadata":{}},{"id":"6d37148b","cell_type":"markdown","source":"Loads sample document corpus and preprocesses text for similarity analysis and network construction.","metadata":{}},{"id":"step7_code","cell_type":"code","source":"import cugraph\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nprint(\"=\"*70)\nprint(\"ğŸ“Š BUILDING DOCUMENT SIMILARITY NETWORK\")\nprint(\"=\"*70)\n\n# Calculate TF-IDF similarity between documents\ntexts = [doc['text'] for doc in doc_topics]\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(texts)\nsimilarity_matrix = cosine_similarity(tfidf_matrix)\n\n# Create edges for documents with similarity > threshold\nthreshold = 0.15  # Lower threshold to create more connections\nedges_list = []\n\nfor i in range(len(documents)):\n    for j in range(i + 1, len(documents)):\n        similarity = similarity_matrix[i, j]\n        if similarity > threshold:\n            edges_list.append({\n                'source': i,\n                'target': j,\n                'weight': float(similarity)\n            })\n\n# Create cuDF edge list\nedges_cudf = cudf.DataFrame(edges_list)\n\nprint(f\"\\nğŸ“Š Document Similarity Network:\")\nprint(f\"   Nodes (documents): {len(documents)}\")\nprint(f\"   Edges (similarities > {threshold}): {len(edges_cudf)}\")\nprint(f\"   Average similarity: {edges_cudf['weight'].mean():.3f}\")\n\n# Create cuGraph\nG = cugraph.Graph()\nG.from_cudf_edgelist(edges_cudf, source='source', destination='target', edge_attr='weight')\n\nprint(f\"\\nâœ… Document network created on GPU 1\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:31.414709Z","iopub.execute_input":"2026-02-05T02:49:31.415323Z","iopub.status.idle":"2026-02-05T02:49:32.582485Z","shell.execute_reply.started":"2026-02-05T02:49:31.415295Z","shell.execute_reply":"2026-02-05T02:49:32.581900Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ“Š BUILDING DOCUMENT SIMILARITY NETWORK\n======================================================================\n\nğŸ“Š Document Similarity Network:\n   Nodes (documents): 11\n   Edges (similarities > 0.15): 9\n   Average similarity: 0.210\n\nâœ… Document network created on GPU 1\n","output_type":"stream"}],"execution_count":8},{"id":"step8_header","cell_type":"markdown","source":"## Step 8: Community Detection with Louvain Algorithm","metadata":{}},{"id":"e3fd9b2e","cell_type":"markdown","source":"Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings.","metadata":{}},{"id":"f59248fb","cell_type":"markdown","source":"Generates document embeddings using LLM on GPU 0, creating vector representations for semantic similarity computation.","metadata":{}},{"id":"step8_code","cell_type":"code","source":"print(\"=\"*70)\nprint(\"ğŸ”¬ COMMUNITY DETECTION (GPU-ACCELERATED)\")\nprint(\"=\"*70)\n\n# Run Louvain community detection\npartition_df, modularity_score = cugraph.louvain(G)\n\n# Map communities back to documents\ncommunities_pd = partition_df.to_pandas()\ndoc_communities = {}\nfor _, row in communities_pd.iterrows():\n    doc_id = int(row['vertex'])\n    community_id = int(row['partition'])\n    doc_communities[doc_id] = community_id\n\n# Group documents by community\ncommunity_groups = {}\nfor doc_id, community_id in doc_communities.items():\n    if community_id not in community_groups:\n        community_groups[community_id] = []\n    community_groups[community_id].append(doc_id)\n\nprint(f\"\\nğŸ“Š Detected {len(community_groups)} communities:\")\nfor community_id, doc_ids in sorted(community_groups.items()):\n    doc_names = [doc_topics[i]['id'] for i in doc_ids]\n    print(f\"   Community {community_id}: {', '.join(doc_names)}\")\n\nprint(\"\\nâœ… Community detection complete on GPU 1\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:36.114130Z","iopub.execute_input":"2026-02-05T02:49:36.115273Z","iopub.status.idle":"2026-02-05T02:49:36.244962Z","shell.execute_reply.started":"2026-02-05T02:49:36.115241Z","shell.execute_reply":"2026-02-05T02:49:36.244162Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ”¬ COMMUNITY DETECTION (GPU-ACCELERATED)\n======================================================================\n\nğŸ“Š Detected 3 communities:\n   Community 0: doc1, doc3, doc2, doc8\n   Community 1: doc11, doc5, doc10\n   Community 2: doc4, doc6\n\nâœ… Community detection complete on GPU 1\n","output_type":"stream"}],"execution_count":9},{"id":"step9_header","cell_type":"markdown","source":"## Step 9: Graph Analytics on Communities","metadata":{}},{"id":"efaf2e09","cell_type":"markdown","source":"Computes network metrics (centrality, clustering coefficient) to identify influential documents and network structure.","metadata":{}},{"id":"04d88e83","cell_type":"markdown","source":"Computes pairwise document similarity matrix using cosine similarity on embeddings, identifying related documents.","metadata":{}},{"id":"step9_code","cell_type":"code","source":"print(\"=\"*70)\nprint(\"ğŸ“Š DOCUMENT NETWORK ANALYTICS\")\nprint(\"=\"*70)\n\n# PageRank - identify important documents\nprint(\"\\nğŸ“Š PageRank Analysis (Document Importance):\")\npagerank = cugraph.pagerank(G)\npagerank = pagerank.sort_values('pagerank', ascending=False)\n\nfor _, row in pagerank.to_pandas().head(5).iterrows():\n    doc_id = int(row['vertex'])\n    score = row['pagerank']\n    doc_name = doc_topics[doc_id]['id']\n    summary = doc_topics[doc_id]['summary']\n    print(f\"   {doc_name}: {score:.4f} - {summary}\")\n\n# Betweenness Centrality - bridge documents between communities\nprint(\"\\nğŸ“Š Betweenness Centrality (Bridge Documents):\")\nbc = cugraph.betweenness_centrality(G)\nbc = bc.sort_values('betweenness_centrality', ascending=False)\n\nfor _, row in bc.to_pandas().head(5).iterrows():\n    doc_id = int(row['vertex'])\n    score = row['betweenness_centrality']\n    doc_name = doc_topics[doc_id]['id']\n    summary = doc_topics[doc_id]['summary']\n    print(f\"   {doc_name}: {score:.4f} - {summary}\")\n\nprint(\"\\nâœ… Graph analytics computed on GPU 1\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:49:41.569688Z","iopub.execute_input":"2026-02-05T02:49:41.570181Z","iopub.status.idle":"2026-02-05T02:49:41.829326Z","shell.execute_reply.started":"2026-02-05T02:49:41.570154Z","shell.execute_reply":"2026-02-05T02:49:41.828714Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ“Š DOCUMENT NETWORK ANALYTICS\n======================================================================\n\nğŸ“Š PageRank Analysis (Document Importance):\n   doc1: 0.1802 - PyTorch accelerates deep learning computations.\n   doc11: 0.1567 - cuGraph accelerates GPU-based graph processing.\n   doc3: 0.1392 - Optimized GPU acceleration for NNS.\n   doc4: 0.1111 - GPU-accelerated data processing library.\n   doc6: 0.1111 - Spark uses GPUs for speed.\n\nğŸ“Š Betweenness Centrality (Bridge Documents):\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/cugraph/link_analysis/pagerank.py:232: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n  warnings.warn(warning_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"   doc1: 0.3393 - PyTorch accelerates deep learning computations.\n   doc11: 0.3214 - cuGraph accelerates GPU-based graph processing.\n   doc3: 0.0179 - Optimized GPU acceleration for NNS.\n   doc2: 0.0000 - Google's Deep Learning Framework TensorFlow\n   doc8: 0.0000 - TensorRT accelerates neural network inference.\n\nâœ… Graph analytics computed on GPU 1\n","output_type":"stream"}],"execution_count":10},{"id":"step10_header","cell_type":"markdown","source":"## Step 10: LLM Analysis of Community Themes","metadata":{}},{"id":"f2c57e7b","cell_type":"markdown","source":"Computes network metrics (centrality, clustering coefficient) to identify influential documents and network structure.","metadata":{}},{"id":"ddf2d838","cell_type":"markdown","source":"Constructs document network graph on GPU 1 where nodes are documents and edges represent similarity above threshold.","metadata":{}},{"id":"step10_code","cell_type":"code","source":"print(\"=\"*70)\nprint(\"ğŸ¤” LLM ANALYSIS OF COMMUNITY THEMES\")\nprint(\"=\"*70)\n\nfor community_id, doc_ids in sorted(community_groups.items()):\n    # Get summaries for this community\n    summaries = [doc_topics[i]['summary'] for i in doc_ids]\n    doc_names = [doc_topics[i]['id'] for i in doc_ids]\n    \n    prompt = f\"\"\"These documents form a cluster based on similarity:\n{', '.join([f\"{name}: {summary}\" for name, summary in zip(doc_names, summaries)])}\n\nWhat is the common theme? Answer in one phrase (3-5 words):\"\"\"\n    \n    response = client.chat.create(\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        max_tokens=20,\n        temperature=0.5\n    )\n    \n    theme = response.choices[0].message.content.strip()\n    print(f\"\\nğŸ“Œ Community {community_id}: {theme}\")\n    print(f\"   Documents: {', '.join(doc_names)}\")\n\nprint(\"\\nâœ… Simultaneous GPU operation:\")\nprint(\"   GPU 0: LLM inference (theme analysis)\")\nprint(\"   GPU 1: Graph analytics (previously computed)\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:50:03.489325Z","iopub.execute_input":"2026-02-05T02:50:03.489633Z","iopub.status.idle":"2026-02-05T02:50:03.913836Z","shell.execute_reply.started":"2026-02-05T02:50:03.489606Z","shell.execute_reply":"2026-02-05T02:50:03.913287Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ¤” LLM ANALYSIS OF COMMUNITY THEMES\n======================================================================\n\nğŸ“Œ Community 0: Deep learning and acceleration.\n   Documents: doc1, doc3, doc2, doc8\n\nğŸ“Œ Community 1: GPU-based graph processing.\n   Documents: doc11, doc5, doc10\n\nğŸ“Œ Community 2: GPU acceleration technology.\n   Documents: doc4, doc6\n\nâœ… Simultaneous GPU operation:\n   GPU 0: LLM inference (theme analysis)\n   GPU 1: Graph analytics (previously computed)\n","output_type":"stream"}],"execution_count":11},{"id":"step11_header","cell_type":"markdown","source":"## Step 11: Graphistry Visualization","metadata":{}},{"id":"11fce365","cell_type":"markdown","source":"Runs GPU-accelerated community detection on document network to discover thematic clusters and topic groups.","metadata":{}},{"id":"step11_code","cell_type":"code","source":"print(\"=\"*70)\nprint(\"ğŸ¨ GRAPHISTRY DOCUMENT NETWORK VISUALIZATION\")\nprint(\"=\"*70)\n\nimport graphistry\nfrom kaggle_secrets import UserSecretsClient\nimport pandas as pd\nimport numpy as np\n\n# --- 1. Register Graphistry ---\nprint(\"\\nğŸ” Registering with Graphistry...\")\ntry:\n    user_secrets = UserSecretsClient()\n    graphistry_key_id = user_secrets.get_secret(\"Graphistry_Personal_Key_ID\")\n    graphistry_secret = user_secrets.get_secret(\"Graphistry_Personal_Secret_Key\")\n\n    graphistry.register(\n        api=3,\n        protocol=\"https\",\n        server=\"hub.graphistry.com\",\n        personal_key_id=graphistry_key_id,\n        personal_key_secret=graphistry_secret\n    )\n    print(\"âœ… Graphistry registered successfully\")\nexcept Exception as e:\n    print(f\"âš ï¸ Graphistry registration failed: {e}\")\n    print(\"   Add secrets: Graphistry_Personal_Key_ID, Graphistry_Personal_Secret_Key\")\n\n# --- 2. Prepare visualization data ---\nprint(\"\\nğŸ“Š Preparing document network data...\")\n\n# Ensure edges_pd exists\nif 'edges_pd' not in locals() and 'edges_pd' not in globals():\n    if 'edges_cudf' in locals() or 'edges_cudf' in globals():\n        edges_pd = edges_cudf.to_pandas()\n    else:\n        raise ValueError(\"No edges data found\")\n\nprint(f\"   Edge data shape: {edges_pd.shape}\")\n\n# Ensure nodes data with all metrics\nif 'pagerank_pd' not in locals():\n    pagerank_pd = pagerank.to_pandas()\nif 'bc_pd' not in locals():\n    bc_pd = bc.to_pandas()\nif 'communities_pd' not in locals():\n    communities_pd = communities.to_pandas()\n\n# Build comprehensive nodes DataFrame\nnodes_pd = pd.DataFrame({\n    'node_id': list(range(len(doc_topics))),\n    'doc_id': [doc['id'] for doc in doc_topics],\n    'summary': [doc['summary'] for doc in doc_topics],\n    'text_preview': [doc['text'][:100] + '...' if len(doc['text']) > 100 else doc['text'] for doc in doc_topics]\n})\n\n# Merge PageRank\nnodes_pd = nodes_pd.merge(\n    pagerank_pd.rename(columns={'vertex': 'node_id'}),\n    on='node_id',\n    how='left'\n)\n\n# Merge Betweenness Centrality\nnodes_pd = nodes_pd.merge(\n    bc_pd.rename(columns={'vertex': 'node_id'}),\n    on='node_id',\n    how='left'\n)\n\n# Merge Communities\nnodes_pd = nodes_pd.merge(\n    communities_pd.rename(columns={'vertex': 'node_id', 'partition': 'community'}),\n    on='node_id',\n    how='left'\n)\nnodes_pd['community'] = nodes_pd['community'].fillna(0).astype(int)\n\n# --- 3. Compute degree centrality ---\nprint(\"   Computing degree centrality...\")\ndegree_in = edges_pd.groupby('target').size().reset_index(name='degree_in').rename(columns={'target': 'node_id'})\ndegree_out = edges_pd.groupby('source').size().reset_index(name='degree_out').rename(columns={'source': 'node_id'})\n\nnodes_pd = nodes_pd.merge(degree_in, on='node_id', how='left')\nnodes_pd = nodes_pd.merge(degree_out, on='node_id', how='left')\nnodes_pd['degree_in'] = nodes_pd['degree_in'].fillna(0).astype(int)\nnodes_pd['degree_out'] = nodes_pd['degree_out'].fillna(0).astype(int)\nnodes_pd['total_degree'] = nodes_pd['degree_in'] + nodes_pd['degree_out']\n\n# --- 4. Role classification ---\nprint(\"   Classifying document roles...\")\n\ndef classify_doc_role(row):\n    \"\"\"Classify documents: Hub (high centrality), Bridge (high betweenness), Peripheral.\"\"\"\n    pr = row['pagerank']\n    bc = row['betweenness_centrality']\n    pr_threshold = nodes_pd['pagerank'].median()\n    bc_threshold = nodes_pd['betweenness_centrality'].median()\n\n    if pr > pr_threshold and bc > bc_threshold:\n        return 'Hub'\n    elif bc > bc_threshold:\n        return 'Bridge'\n    else:\n        return 'Peripheral'\n\nnodes_pd['role'] = nodes_pd.apply(classify_doc_role, axis=1)\n\n# --- 5. Size encoding (normalized PageRank) ---\npr_min = nodes_pd['pagerank'].min()\npr_max = nodes_pd['pagerank'].max()\nif pr_max > pr_min:\n    nodes_pd['node_size'] = 25 + (nodes_pd['pagerank'] - pr_min) / (pr_max - pr_min) * 75\nelse:\n    nodes_pd['node_size'] = 50\n\n# --- 6. Rich tooltips ---\nnodes_pd['point_title'] = nodes_pd.apply(\n    lambda row: f\"{row['doc_id']}: {row['summary']}\\n\" +\n                f\"Community: {row['community']}\\n\" +\n                f\"Role: {row['role']}\\n\" +\n                f\"PageRank: {row['pagerank']:.4f}\\n\" +\n                f\"Betweenness: {row['betweenness_centrality']:.4f}\\n\" +\n                f\"Degree: {int(row['total_degree'])}\",\n    axis=1\n)\n\nedges_pd['edge_title'] = edges_pd.apply(\n    lambda row: f\"Similarity: {row['weight']:.3f}\",\n    axis=1\n)\n\nprint(f\"\\nğŸ“Š Document Network Summary:\")\nprint(f\"   Documents: {len(nodes_pd)}\")\nprint(f\"   Similarity Edges: {len(edges_pd)}\")\nprint(f\"   Communities: {nodes_pd['community'].nunique()}\")\nprint(f\"   Avg similarity: {edges_pd['weight'].mean():.3f}\")\n\n# --- 7. Create Graphistry visualization ---\nprint(\"\\nğŸ¨ Creating Graphistry visualization...\")\n\n# Color palettes\ncommunity_colors = {\n    0: '#FF6B6B',  # Red - Deep Learning\n    1: '#4ECDC4',  # Teal - Data Science\n    2: '#45B7D1',  # Blue - Inference\n    3: '#FFA07A',  # Orange - Visualization\n    4: '#98D8C8',  # Mint\n}\n\nrole_icons = {\n    'Hub': 'star',\n    'Bridge': 'exchange-alt',\n    'Peripheral': 'circle'\n}\n\n# Bind and create visualization\ng = graphistry.bind(\n    source='source',\n    destination='target',\n    node='node_id',\n    point_title='point_title',\n    edge_title='edge_title'\n)\n\nplotter = (\n    g.edges(edges_pd)\n    .nodes(nodes_pd)\n    .encode_point_color('community', categorical_mapping=community_colors, default_mapping='#CCCCCC')\n    .encode_point_size('node_size')\n    .encode_point_icon('role', categorical_mapping=role_icons, default_mapping='circle')\n    .encode_edge_color('weight', ['#E8E8E8', '#6C7A89', '#2C3E50'], as_continuous=True)\n    .settings(url_params={\n        'play': 0,\n        'pointSize': 2.5,\n        'edgeOpacity': 0.4,\n        'bg': '%23FFFFFF',\n        'showArrows': 'false',\n        'showLabels': 'true'\n    })\n)\n\n# --- 8. Launch visualization ---\ntry:\n    url = plotter.plot(\n        render=False,\n        name=\"Document Similarity Network - llamatelemetry v0.1.0\",\n        description=f\"{len(nodes_pd)} documents clustered into {nodes_pd['community'].nunique()} communities\"\n    )\n\n    print(f\"\\nğŸš€ Visualization Created Successfully!\")\n    print(f\"\\nğŸ”— Graphistry URL:\")\n    print(f\"   {url}\")\n    print(f\"\\nğŸ“Œ Features:\")\n    print(f\"   âœ“ Color-coded by community (document clusters)\")\n    print(f\"   âœ“ Size scaled by PageRank (document importance)\")\n    print(f\"   âœ“ Icons show role (Hub â­, Bridge â†”ï¸, Peripheral â—‹)\")\n    print(f\"   âœ“ Edge color intensity = similarity strength\")\n    print(f\"   âœ“ Interactive tooltips with doc summaries\")\n\n    from IPython.display import display, HTML\n    display(HTML(\n        f'<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); '\n        f'border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\">'\n        f'<h3 style=\"margin:0 0 10px 0;\">ğŸ“„ Document Network Dashboard</h3>'\n        f'<p style=\"margin:5px 0;\">GPU computing topics clustered by similarity</p>'\n        f'<a href=\"{url}\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; '\n        f'background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; '\n        f'box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸš€ Open Interactive Visualization</a>'\n        f'</div>'\n    ))\n\nexcept Exception as e:\n    print(f\"\\nâŒ Visualization error: {e}\")\n    print(f\"   Data prepared successfully - {len(nodes_pd)} nodes, {len(edges_pd)} edges\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… Document network visualization complete\")\nprint(\"=\"*70)","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:50:09.108468Z","iopub.execute_input":"2026-02-05T02:50:09.109271Z","iopub.status.idle":"2026-02-05T02:50:11.214530Z","shell.execute_reply.started":"2026-02-05T02:50:09.109240Z","shell.execute_reply":"2026-02-05T02:50:11.213820Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ¨ GRAPHISTRY DOCUMENT NETWORK VISUALIZATION\n======================================================================\n\nğŸ” Registering with Graphistry...\nâœ… Graphistry registered successfully\n\nğŸ“Š Preparing document network data...\n   Edge data shape: (9, 3)\n   Computing degree centrality...\n   Classifying document roles...\n\nğŸ“Š Document Network Summary:\n   Documents: 11\n   Similarity Edges: 9\n   Communities: 3\n   Avg similarity: 0.210\n\nğŸ¨ Creating Graphistry visualization...\n\nğŸš€ Visualization Created Successfully!\n\nğŸ”— Graphistry URL:\n   https://hub.graphistry.com/graph/graph.html?dataset=0a9094fa142b4e14aa4d7261de672719&type=arrow&viztoken=fa51743b-5b89-4041-a866-fa51f9c12d28&usertag=aeceb811-pygraphistry-0.50.6&splashAfter=1770259826&info=true&play=0&pointSize=2.5&edgeOpacity=0.4&bg=%23FFFFFF&showArrows=false&showLabels=true\n\nğŸ“Œ Features:\n   âœ“ Color-coded by community (document clusters)\n   âœ“ Size scaled by PageRank (document importance)\n   âœ“ Icons show role (Hub â­, Bridge â†”ï¸, Peripheral â—‹)\n   âœ“ Edge color intensity = similarity strength\n   âœ“ Interactive tooltips with doc summaries\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div style=\"margin:20px; padding:20px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:12px; color:white; box-shadow:0 4px 6px rgba(0,0,0,0.1);\"><h3 style=\"margin:0 0 10px 0;\">ğŸ“„ Document Network Dashboard</h3><p style=\"margin:5px 0;\">GPU computing topics clustered by similarity</p><a href=\"https://hub.graphistry.com/graph/graph.html?dataset=0a9094fa142b4e14aa4d7261de672719&type=arrow&viztoken=fa51743b-5b89-4041-a866-fa51f9c12d28&usertag=aeceb811-pygraphistry-0.50.6&splashAfter=1770259826&info=true&play=0&pointSize=2.5&edgeOpacity=0.4&bg=%23FFFFFF&showArrows=false&showLabels=true\" target=\"_blank\" style=\"display:inline-block; margin-top:15px; padding:12px 24px; background:white; color:#667eea; text-decoration:none; border-radius:6px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.1);\">ğŸš€ Open Interactive Visualization</a></div>"},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nâœ… Document network visualization complete\n======================================================================\n","output_type":"stream"}],"execution_count":12},{"id":"step12_header","cell_type":"markdown","source":"## Step 12: Detailed Community Report","metadata":{}},{"id":"8e6091e8","cell_type":"markdown","source":"Computes network metrics (degree centrality, PageRank) on GPU 1 to identify most influential and central documents.","metadata":{}},{"id":"step12_code","cell_type":"code","source":"print(\"=\"*70)\nprint(\"ğŸ“‹ DETAILED COMMUNITY REPORT\")\nprint(\"=\"*70)\n\nfor community_id, doc_ids in sorted(community_groups.items()):\n    print(f\"\\nğŸ“Œ Community {community_id}:\")\n    print(f\"   Size: {len(doc_ids)} documents\")\n    \n    print(f\"\\n   Documents:\")\n    for doc_id in doc_ids:\n        doc = doc_topics[doc_id]\n        pr_score = pagerank_pd[pagerank_pd['vertex'] == doc_id]['pagerank'].values\n        pr_score = pr_score[0] if len(pr_score) > 0 else 0\n        print(f\"      â€¢ {doc['id']}: {doc['summary']} (PageRank: {pr_score:.4f})\")\n    \n    # Avg similarity within community\n    intra_edges = edges_cudf[\n        (edges_cudf['source'].isin(doc_ids)) & \n        (edges_cudf['target'].isin(doc_ids))\n    ]\n    if len(intra_edges) > 0:\n        avg_sim = intra_edges['weight'].mean()\n        print(f\"\\n   Avg intra-community similarity: {avg_sim:.3f}\")\n\nprint(\"\\nâœ… Community analysis complete\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:52:08.089701Z","iopub.execute_input":"2026-02-05T02:52:08.090378Z","iopub.status.idle":"2026-02-05T02:52:08.153514Z","shell.execute_reply.started":"2026-02-05T02:52:08.090348Z","shell.execute_reply":"2026-02-05T02:52:08.152915Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ“‹ DETAILED COMMUNITY REPORT\n======================================================================\n\nğŸ“Œ Community 0:\n   Size: 4 documents\n\n   Documents:\n      â€¢ doc1: PyTorch accelerates deep learning computations. (PageRank: 0.1802)\n      â€¢ doc3: Optimized GPU acceleration for NNS. (PageRank: 0.1392)\n      â€¢ doc2: Google's Deep Learning Framework TensorFlow (PageRank: 0.0980)\n      â€¢ doc8: TensorRT accelerates neural network inference. (PageRank: 0.0881)\n\n   Avg intra-community similarity: 0.220\n\nğŸ“Œ Community 1:\n   Size: 3 documents\n\n   Documents:\n      â€¢ doc11: cuGraph accelerates GPU-based graph processing. (PageRank: 0.1567)\n      â€¢ doc5: Machine Learning on GPU Acceleration (PageRank: 0.0639)\n      â€¢ doc10: GPU-accelerated graph visualization software. (PageRank: 0.0516)\n\n   Avg intra-community similarity: 0.192\n\nğŸ“Œ Community 2:\n   Size: 2 documents\n\n   Documents:\n      â€¢ doc4: GPU-accelerated data processing library. (PageRank: 0.1111)\n      â€¢ doc6: Spark uses GPUs for speed. (PageRank: 0.1111)\n\n   Avg intra-community similarity: 0.166\n\nâœ… Community analysis complete\n","output_type":"stream"}],"execution_count":13},{"id":"step13_header","cell_type":"markdown","source":"## Step 13: Monitor Both GPUs","metadata":{}},{"id":"ac8037c9","cell_type":"markdown","source":"Runs GPU-accelerated community detection (Louvain) on GPU 1 to discover document clusters and thematic groupings.","metadata":{}},{"id":"5dad540f","cell_type":"markdown","source":"Creates Graphistry visualization of document network with community colors, node sizes by centrality, and interactive filtering.","metadata":{}},{"id":"step13_code","cell_type":"code","source":"print(\"=\"*70)\nprint(\"ğŸ“Š DUAL GPU MONITORING\")\nprint(\"=\"*70)\n\n!nvidia-smi\n\nprint(\"\\nğŸ’¡ Split-GPU Operation:\")\nprint(\"   GPU 0: llama-server (document summarization)\")\nprint(\"   GPU 1: RAPIDS (community detection, graph analytics)\")","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:52:12.938934Z","iopub.execute_input":"2026-02-05T02:52:12.939644Z","iopub.status.idle":"2026-02-05T02:52:13.337355Z","shell.execute_reply.started":"2026-02-05T02:52:12.939617Z","shell.execute_reply":"2026-02-05T02:52:13.336595Z"},"trusted":true},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ“Š DUAL GPU MONITORING\n======================================================================\nThu Feb  5 02:52:13 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   56C    P0             29W /   70W |    2679MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   45C    P0             26W /   70W |     105MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A              55      C   /usr/bin/python3                        108MiB |\n|    0   N/A  N/A             237      C   .../binaries/cuda12/llama-server       2568MiB |\n|    1   N/A  N/A             237      C   .../binaries/cuda12/llama-server        102MiB |\n+-----------------------------------------------------------------------------------------+\n\nğŸ’¡ Split-GPU Operation:\n   GPU 0: llama-server (document summarization)\n   GPU 1: RAPIDS (community detection, graph analytics)\n","output_type":"stream"}],"execution_count":14},{"id":"step14_header","cell_type":"markdown","source":"## Step 14: Cleanup","metadata":{}},{"id":"3b1c7a96","cell_type":"markdown","source":"Verifies dual T4 GPU availability for document network analysis workflow combining LLM text processing with GPU-accelerated network analytics.","metadata":{}},{"id":"bf086c76","cell_type":"markdown","source":"Uses LLM on GPU 0 to generate natural language summaries of detected document communities and key themes.","metadata":{}},{"id":"step14_code","cell_type":"code","source":"print(\"ğŸ›‘ Stopping llama-server...\")\nserver.stop_server()\n\n# Clear RAPIDS memory\nimport gc\ndel G, edges_cudf, pagerank, bc, communities\ngc.collect()\n\nprint(\"\\nâœ… Resources cleaned up\")\nprint(\"\\nğŸ“Š Final GPU Status:\")\n!nvidia-smi --query-gpu=index,memory.used,memory.free --format=csv","metadata":{"execution":{"iopub.status.busy":"2026-02-05T02:52:17.403713Z","iopub.execute_input":"2026-02-05T02:52:17.404506Z","iopub.status.idle":"2026-02-05T02:52:17.979273Z","shell.execute_reply.started":"2026-02-05T02:52:17.404470Z","shell.execute_reply":"2026-02-05T02:52:17.978315Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ›‘ Stopping llama-server...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3610408392.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Clear RAPIDS memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_cudf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpagerank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'communities' is not defined"],"ename":"NameError","evalue":"name 'communities' is not defined","output_type":"error"}],"execution_count":15},{"id":"summary","cell_type":"markdown","source":"## ğŸ“š Summary\n\n### Document Network Analysis Workflow:\n1. **GPU 0**: LLM generates document summaries\n2. **CPU**: TF-IDF calculates document similarity\n3. **GPU 1**: cuGraph builds similarity network\n4. **GPU 1**: Louvain algorithm detects communities\n5. **GPU 0**: LLM interprets community themes\n6. **Graphistry**: Interactive visualization with communities\n\n### Key Integration Points:\n- âœ… LLM for document summarization and theme extraction\n- âœ… cuGraph for GPU-accelerated community detection (Louvain)\n- âœ… Graphistry for community-colored network visualization\n- âœ… PageRank & Betweenness for document importance ranking\n\n### Algorithms Used:\n- **Louvain**: Community detection (finds document clusters)\n- **PageRank**: Document importance (citation-like ranking)\n- **Betweenness Centrality**: Bridge documents (connect communities)\n- **TF-IDF + Cosine Similarity**: Document similarity metric\n\n### Split-GPU Architecture:\n```python\n# GPU 0: llama-server\ntensor_split=\"1.0,0.0\"  # 100% on GPU 0\n\n# GPU 1: RAPIDS\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nimport cudf, cugraph  # Uses GPU 1\n```\n\n---\n\n**Next:** [09-large-models-kaggle](09-large-models-kaggle-llamatelemetry-v0-1-0.ipynb)","metadata":{}}]}